Configuration Guides
Cisco Fabric Manager Interfaces Configuration Guide
Bias-Free Language
Book Contents
Download
Print
Updated:
February 22, 2010
Chapter: Configuring Interface Buffers
Chapter Contents

Fibre Channel interfaces use buffer credits to ensure all packets are delivered to their destination. This chapter describes the different buffer credits available on the Cisco MDS 9000 Family switches and modules, and includes the following topics:
•About Buffer-to-Buffer Credits
•Configuring Buffer-to-Buffer Credits
•About Performance Buffers
•Configuring Performance Buffers
•Buffer Pools
•BB_Credit Buffers for Switching Modules
•BB_Credit Buffers for Fabric Switches
•About Extended BB_Credits
•Configuring Extended BB_credits
•Enabling Buffer-to-Buffer Credit Recovery
•About Receive Data Field Size
•Configuring Receive Data Field Size
About Buffer-to-Buffer Credits
Buffer-to-buffer credits (BB_credits) are a flow-control mechanism to ensure that Fibre Channel switches do not run out of buffers, so that switches do not drop frames. BB_credits are negotiated on a per-hop basis.
The receive BB_credit (fcrxbbcredit) value may be configured for each Fibre Channel interface. In most cases, you do not need to modify the default configuration.
The receive BB_credit values depend on the module type and the port mode, as follows:
•For 16-port switching modules and full rate ports, the default value is 16 for Fx mode and 255 for E or TE modes. The maximum value is 255 in all modes. This value can be changed as required.
•For 32-port switching modules and host-optimized ports, the default value is 12 for Fx, E, and TE modes. These values cannot be changed.
•For Generation 2 and Generation 3 switching modules, see the "Buffer Pools" section.
Note In the Cisco MDS 9100 Series switches, the groups of ports on the left outlined in white are in dedicated rate mode. The other ports are host-optimized. Each group of 4 host-optimized ports have the same features as for the 32-port switching module.
Configuring Buffer-to-Buffer Credits
To configure BB_credits for a Fibre Channel interface using Fabric Manager, follow these steps:
Step 1 Expand Switches > Interfaces and then select FC Physical. You see the interface configuration in the Information pane.
Step 2 Click the Bb Credit tab.
You see the buffer credits.
Step 3 Set any of the buffer-to-buffer credits for an interface.
Step 4 Click Apply Changes.
About Performance Buffers
Regardless of the configured receive BB_credit value, additional buffers, called performance buffers, improve switch port performance. Instead of relying on the built-in switch algorithm, you can manually configure the performance buffer value for specific applications (for example, forwarding frames over FCIP interfaces).
Note Performance buffers are not supported on the Cisco MDS 9148 Fabric Switch, Cisco MDS 9124 Fabric Switch, the Cisco Fabric Switch for HP c-Class BladeSystem, and the Cisco Fabric Switch for IBM BladeCenter.
For each physical Fibre Channel interface in any switch in the Cisco MDS 9000 Family, you can specify the amount of performance buffers allocated in addition to the configured receive BB_credit value.
The default performance buffer value is 0. If you set the performance buffer value to 0, the built-in algorithm is used. If you do not specify the performance buffer value, 0 is automatically used.
Configuring Performance Buffers
To configure performance buffers for a Fibre Channel interface using Fabric Manager, follow these steps:
Step 1 Expand Switches > Interfaces and then select FC Physical.
You see the interface configuration in the Information pane.
Step 2 Click the BB Credit tab.
You see performance buffer information in the Perf Bufs Admin and Perf Bufs Oper columns.
Step 3 Set the performance buffers for an interface.
Step 4 Click Apply Changes.
Buffer Pools
In the architecture of Generation 2 and Generation 3 modules, receive buffers shared by a set of ports are called buffer groups. The receive buffer groups are organized into global and local buffer pools.
The receive buffers allocated from the global buffer pool to be shared by a port group are called a global recieve buffer pool. Global receive buffer pools include the following buffer groups:
•Reserved internal buffers
•Allocated BB_credit buffers for each Fibre Channel interface (user configured or assigned by default)
•Common unallocated buffer pool for BB_credits, if any, to be used for additional BB_credits as needed
•Performance buffers (only used on 12-port 4-Gbps and 4-port 10-Gbps switching modules)
Note The 48-port and 24-port 8-Gbps modules have dual global buffer pools. Each buffer pool in the 48-port modules support 24 ports and in the 24-port modules each buffer pool supports 12 ports.
Figure 6-1 shows the allocation of BB_credit buffers on line cards (24-port and 48-port 4-Gbps line cards).
Figure 6-1 Receive Buffers for Fibre Channel Ports in a Global Buffer Pool
Figure 6-2 shows the default BB_credit buffer allocation model for 48-port 8-Gbps switching modules. The minimum BB_credits required to bring up a port is two buffers.
Figure 6-2 BB_Credit Buffer Allocation in 48-Port 8-Gbps Switching Modules
Figure 6-3 shows the default BB_credit buffer allocation model for 24-port 8-Gbps switching modules. The minimum BB_credits required to bring up a port is two buffers.
Figure 6-3 BB_Credit Buffer Allocation in 24-Port 8-Gbps Switching Modules
Figure 6-4 shows the default BB_credit buffer allocation model for 4/44-port 8-Gbps host-optimized switching modules. The minimum BB_credits required to bring up a port is two buffers.
Figure 6-4 BB_Credit Buffer Allocation in 4/44-Port 8-Gbps Switching Modules
Figure 6-5 shows the default BB_credit buffer allocation model for 24-port 4-Gbps switching modules. The minimum BB_credits required to bring up a port is two buffers.
Figure 6-5 BB_Credit Buffer Allocation in 24-Port 4-Gbps Switching Modules
Note The default BB_credit buffer allocation is the same for all port speeds.
BB_Credit Buffers for Switching Modules
This section describes how buffer credits are allocated to Cisco MDS 9000 switching modules, and includes the following topics:
•48-Port 8-Gbps Fibre Channel Module BB_Credit Buffers
•24-Port 8-Gbps Fibre Channel Module BB_Credit Buffers
•4/44-Port 8-Gbps Host-Optimized Fibre Channel Module BB_Credit Buffers
•48-Port 4-Gbps Fibre Channel Module BB_Credit Buffers
•24-Port 4-Gbps Fibre Channel Module BB_Credit Buffers
•18-Port Fibre Channel/4-Port Gigabit Ethernet Multiservice Module BB_Credit Buffers
•4-Port 10-Gbps Switching Module BB_Credit Buffers
48-Port 8-Gbps Fibre Channel Module BB_Credit Buffers
Table 6-1 lists the BB_credit buffer allocation for the 48-port 8-Gbps Fibre Channel switching module.
Table 6-1 48-Port 8-Gbps Switching Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation
BB_Credit Buffers Per Port
Dedicated Rate Mode
8-Gbps Speed
Shared Rate Mode
8-Gbps Speed
ISL
Fx Port
Fx Port
Default BB_credit buffers
250
32
32
Maximum BB_credit buffers
500
500
32
Total Number of BB_Credit Buffers per Module
Ports 1 through 24
6000
Ports 25 through 48
6000

The following guidelines apply to BB_credit buffers on 48-port 8-Gbps Fibre Channel switching modules:
•BB_credit buffers allocated for ports 1 through 24 and 25 through 48 can be a maximum of 6000 each so that the load is distributed.
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 500 buffers for dedicated rate mode.
•BB_credit buffers for Fx port mode connections can be configured. The minimum is 2 buffers and the maximum of 500 buffers for dedicated rate mode or 32 buffers for shared rate mode.
•Performance buffers are not supported on this module.
Each port group on the 48-port 8-Gbps Fibre Channel switching module consists of six ports. The ports in shared rate mode in a port group can have a maximum bandwidth oversubscription of 10:1 considering that each port group has 12.8-Gbps bandwidth.
The following example configurations are supported by the 48-port 8-Gbps Fibre Channel switching modules:
•Six ports with shared rate mode and 8-Gbps speed (4:1 oversubscription) (default)
•One port with dedicated rate mode and 8-Gbps speed plus
five ports with shared rate mode and 8-Gbps speed (10:1 oversubscription)
•Two ports with dedicated rate mode and 4-Gbps speed plus
four ports with shared rate mode and 4-Gbps speed (4:1 oversubscription)
•One port with dedicated rate mode and 4-Gbps speed plus
three ports with dedicated rate mode and 2-Gbps speed plus
two ports with shared rate mode and 4-Gbps speed (4:1 oversubscription) 
•Six ports with dedicated rate mode and 2-Gbps speed
24-Port 8-Gbps Fibre Channel Module BB_Credit Buffers
Table 6-2 lists the BB_credit buffer allocation for the 24-port 8-Gbps Fibre Channel switching module.
Table 6-2 24-Port 8-Gbps Switching Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation
BB_Credit Buffers Per Port
Dedicated Rate Mode
8-Gbps Speed
Shared Rate Mode
8-Gbps Speed
ISL
Fx Port
Fx Port
Default BB_credit buffers
500
32
32
Maximum BB_credit buffers
5001
5001
32
Total Number of BB_Credit Buffers per Module
Ports 1 through 12
6000
Ports 13 through 24
6000
1 When connected to Generation 1 modules, reduce the maximum BB_credit allocation to 250.

The following guidelines apply to BB_credit buffers on 24-port 8-Gbps Fibre Channel switching modules:
•BB_credit buffers allocated for ports 1 through 12 and 13 through 24 can be a maximum of 6000 each so that the load is distributed.
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 500 buffers for dedicated rate mode.
•BB_credit buffers for Fx port mode connections can be configured. The minimum is 2 buffers and the maximum of 500 buffers for dedicated rate mode or 32 buffers for shared rate mode.
•Performance buffers are not supported on this module.
Each port group on the 24-port 8-Gbps Fibre Channel switching module consists of three ports. The ports in shared rate mode in a port group can have a maximum bandwidth oversubscription of 10:1 considering that each port group has 12.8-Gbps bandwidth.
The following example configurations are supported by the 24-port 8-Gbps Fibre Channel switching modules:
•Three ports with shared rate mode and 8-Gbps speed (2:1 oversubscription) (default)
•One port with dedicated rate mode and 8-Gbps speed plus
two ports with shared rate mode and 8-Gbps speed (4:1 oversubscription)
•One port with dedicated rate mode and 8-Gbps speed plus
one port with dedicated rate mode and 4-Gbps speed plus
one port with shared rate mode and 8-Gbps speed (10:1 oversubscription)
•Two ports with dedicated rate mode and 4-Gbps speed plus
one port with shared rate mode and 8-Gbps speed (2:1 oversubscription) 
•Three ports with dedicated rate mode and 4-Gbps speed
4/44-Port 8-Gbps Host-Optimized Fibre Channel Module BB_Credit Buffers
Table 6-3 lists the BB_credit buffer allocation for the 4/44-port 8-Gbps Fibre Channel switching module.
Table 6-3 4/44-Port 8-Gbps Switching Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation
BB_Credit Buffers Per Port
Dedicated Rate Mode
8-Gbps Speed
Shared Rate Mode
8-Gbps Speed
ISL
Fx Port
Fx Port
Default BB_credit buffers
125
32
32
Maximum BB_credit buffers
250
250
32
Total number of BB_credit buffers per module
6000

The following guidelines apply to BB_credit buffers on 4/44-port 8-Gbps Fibre Channel switching modules:
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 500 buffers for dedicated rate mode.
•BB_credit buffers for Fx port mode connections can be configured. The minimum is 2 buffers and the maximum of 250 buffers for dedicated rate mode or 32 buffers for shared rate mode.
•Performance buffers are not supported on this module.
Each port group on the 24-port 8-Gbps Fibre Channel switching module consists of 12 ports. The ports in shared rate mode in a port group can have a maximum bandwidth oversubscription of 10:1 considering that each port group has 12.8-Gbps bandwidth.
The following example configurations are supported by the 4/44-port 8-Gbps Fibre Channel switching modules:
•Twelve ports with shared rate mode and 4-Gbps speed (5:1 oversubscription) (default)
•One port with dedicated rate mode and 8-Gbps speed plus
eleven ports with shared rate mode and 4-Gbps speed (10:1 oversubscription)
•One port with dedicated rate mode and 4-Gbps speed plus
three ports with dedicated rate mode and 3-Gbps speed plus
eight ports with shared rate mode and 4-Gbps speed (2:1 oversubscription)
•Twelve ports with dedicated rate mode and 1-Gbps speed
48-Port 4-Gbps Fibre Channel Module BB_Credit Buffers
Table 6-4 lists the BB_credit buffer allocation for 48-port 4-Gbps Fibre Channel switching modules.
Table 6-4 48-Port 4-Gbps Switching Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation
BB_Credit Buffers Per Port
Dedicated Rate Mode
4-Gbps Speed
Shared Rate Mode
4-Gbps Speed
ISL 1
Fx Port
Fx Port
Default BB_credit buffers
125
16
16
Maximum BB_credit buffers
250
250
16
Total number of BB_credit buffers per module
6000
1 ISL = E port or TE port.

The following considerations apply to BB_credit buffers on 48-port 4-Gbps Fibre Channel switching modules:
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 250 buffers for dedicated rate mode or 16 buffers for shared rate mode.
•BB_credit buffers for Fx port mode connections can be configured. The minimum is 2 buffers and the maximum of 250 buffers for dedicated rate mode or 16 buffers for shared rate mode.
•Performance buffers are not supported on this module.
Each port group on the 48-port 4-Gbps Fibre Channel switching module consists of 12 ports. The ports in shared rate mode have bandwidth oversubscription of 2:1 by default. However, some configurations of the shared ports in a port group can have maximum bandwidth oversubscription of 4:1 (considering that each port group has 12.8-Gbps bandwidth).
The following example configurations are supported by the 48-port 4-Gbps Fibre Channel switching modules:
•Twelve ports with shared rate mode and 4-Gbps speed (4:1 oversubscription) (default)
•One port with dedicated rate mode and 4-Gbps speed plus
11 ports with shared rate mode and 4-Gbps speed (5:1 oversubscription)
•One port with dedicated rate mode and 4-Gbps speed plus
11 ports with shared rate mode and 2-Gbps speed (2.5:1 oversubscription)
•Two ports with dedicated rate mode and 2-Gbps speed plus
10 ports with shared rate mode and 4-Gbps speed (5:1 oversubscription) 
•Two ports with dedicated rate mode and 2-Gbps speed plus
10 ports with shared rate mode and 2-Gbps speed (2.5:1 oversubscription) 
•Twelve ports with dedicated rate mode and 1-Gbps speed
•Three ports with dedicated rate mode and 4-Gbps speed plus
four ports with shared rate mode and 1-Gbps speed plus
five ports put out-of-service (see Figure 6-6)
Figure 6-6 Example Speed and Rate Configuration on a 48-Port 4-Gbps Switching Module
•Six ports with dedicated rate mode and 2-Gbps speed plus
four ports with shared rate mode and 1-Gbps speed plus
two ports put out-of-service (see Figure 6-7)
Figure 6-7 Example Speed and Rate Configuration on a 48-Port 4-Gbps Switching Module
24-Port 4-Gbps Fibre Channel Module BB_Credit Buffers
Table 6-5 lists the BB_credit buffer allocation for 24-port 4-Gbps Fibre Channel switching modules.
Table 6-5 24-Port 4-Gbps Switching Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation
BB_Credit Buffers Per Port
Dedicated Rate Mode
4-Gbps Speed
Shared Rate Mode
4-Gbps Speed
ISL 1
Fx Port
Fx Port
Default BB_credit buffers
250
16
16
Maximum BB_credit buffers
250
250
16
Total number of BB_credits buffers per module
6000
1 ISL = E port or TE port.

The following considerations apply to BB_credit buffers on 24-port 4-Gbps Fibre Channel switching modules:
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 250 buffers for dedicated rate mode or 16 buffers for shared rate mode.
•BB_credit buffers for Fx port mode connections can be configured. The minimum is 2 buffers and the maximum of 250 buffers for dedicated rate mode or 16 buffers for shared rate mode.
•Performance buffers are not supported on this module.
Each port group on the 24-port 4-Gbps Fibre Channel switching module consists of six ports. The ports in shared rate mode have a bandwidth oversubscription of 2:1 by default. However, some configurations of the shared ports in a port group can have a maximum bandwidth oversubscription of 4:1 (considering that each port group has 12.8-Gbps bandwidth).
The following example configurations are supported by the 24-port 4-Gbps Fibre Channel switching modules:
•Six ports with shared rate mode and 4-Gbps speed (2:1 oversubscription) (default)
•Two ports with dedicated rate mode and 4-Gbps speed plus
four ports with shared rate mode and 4-Gbps speed (with 4:1 oversubscription)
•One port with dedicated rate mode and 4-Gbps speed plus
three ports with dedicated rate mode and 2-Gbps speed plus
two ports with shared rate mode and 4-Gbps speed (4:1 oversubscription)
•Six ports with dedicated rate mode and 2-Gbps speed
•Three ports with dedicated rate mode and 4-Gbps speed plus
three ports with shared rate mode and 1-Gbps speed (see Figure 6-8)
Figure 6-8 Example Speed and Rate Configuration on a 24-Port 4-Gbps Switching Module
18-Port Fibre Channel/4-Port Gigabit Ethernet Multiservice Module BB_Credit Buffers
Table 6-5 lists the BB_credit buffer allocation for 18-port 4-Gbps multiservice modules.
Table 6-6 18-Port 4-Gbps Multiservice Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation
BB_Credit Buffers Per Port
Dedicated Rate Mode
4-Gbps Speed
Shared Rate Mode
4-Gbps Speed
ISL 1
Fx Port
ISL 1
Fx Port
Default BB_credit buffers
250
16
16
16
Maximum BB_credit buffers
250
250
16
16
Total number of BB_credit buffers per module
4509
1 ISL = E port or TE port.

The following considerations apply to BB_credit buffers on18-port 4-Gbps Fibre Channel switching modules:
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 250 buffers for dedicated rate mode or 16 buffers for shared rate mode.
•BB_credit buffers for Fx port mode connections can be configured. The minimum is 2 buffers and the maximum of 250 buffers for dedicated rate mode or 16 buffers for shared rate mode.
•Performance buffers are not supported on this module.
12-Port 4-Gbps Switching Module BB_Credit Buffers
Table 6-7 lists the BB_credit buffer allocation for 12-port 4-Gbps switching modules.
Table 6-7 12-Port 4-Gbps Switching Module BB_Credit Buffer Allocation 
BB_Credit Buffer Allocation Type
BB_Credit Buffers Per Port
Dedicated Rate Mode
4-Gbps Speed
ISL 1
Fx Port
Default BB_credit buffers
250
16
Maximum BB_credit buffers
250
16
Default Performance buffers
145
12
Total number of BB_credit buffers per module
5488
Total number of performance buffers per module
512 (shared)
1 ISL = E port or TE port.

The following considerations apply to BB_credit buffers on 12-port 4-Gbps switching modules:
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 250 buffers.
•BB_credit buffers for Fx port mode connections can be configured from a minimum of 2 buffers to a maximum of 250 buffers.
•By default, 512 performance buffers are preallocated and are shared by all the ports. These buffers are configurable and the buffers are assigned to the port based on the availability of the buffers in the shared pool.
•There are 2488 extra buffers available as extended BB_credit buffers after allocating all the default BB_credit buffers for all the ports in ISL mode (5488 - (250 * 12)).
Note Extended BB_credits are allocated across all ports on the switch. That is, they are not allocated by port group.
Note By default, the ports in the 12-port 4-Gbps switching modules come up in 4-Gbps dedicated rate mode but can be configured as 1-Gbps and 2-Gbps dedicated rate mode. Shared mode is not supported.
4-Port 10-Gbps Switching Module BB_Credit Buffers
Table 6-8 lists the BB_credit buffer allocation for 4-port 10-Gbps switching modules.
Table 6-8 4-Port 10-Gbps Switching Module BB_Credit Buffer Allocation
BB_Credit Buffer Allocation Type
BB_Credit Buffers Per Port
Dedicated Rate Mode
10-Gbps Speed
ISL 1
F port 2
Default BB_credit buffers
250
16
Maximum BB_credit buffers
750
16
Maximum BB_credit buffers on one of the ports with Enterprise license
4095
  Total number of BB_credit buffers per module
5488
Default Performance buffers
145
12
Total number of performance buffers per module
512 (shared)
1 ISL = E port or TE port.
2 Ports on the 4-port 10-Gbps cannot operate in FL port mode.

Note The ports in the 4-port 10-Gbps switching module only support 10-Gbps dedicated rate mode. FL port mode and shared rate mode are not supported.
The following considerations apply to BB_credit buffers on 4-port 10-Gbps switching modules:
•BB_credit buffers for ISL connections can be configured from a minimum of 2 buffers to a maximum of 750 buffers.
•BB_credit buffers for Fx port mode connections can be configured from a minimum of 2 buffers to a maximum of 750 buffers.
•By default, 512 performance buffers are preallocated and are shared by all the ports. These buffers are configurable and the buffers are assigned to the port based on the availability of the buffers in the shared pool.
•There are 2488 extra buffers available as extended BB_credits after allocating all the default BB_credit buffers for all the ports in ISL mode (5488 - (750 * 4)).
Note Extended BB_credits are allocated across all ports on the switch. That is, they are not allocated by port group.
BB_Credit Buffers for Fabric Switches
This section describes how buffer credits are allocated to Cisco MDS 9000 Fabric switches, and includes the following topics:
•Cisco MDS 9148 Fabric Switch BB_Credit Buffers
•Cisco MDS 9148 Fabric Switch BB_Credit Buffers
•Cisco MDS 9124 Fabric Switch BB_Credit Buffers
•Cisco MDS 9222i Multiservice Modular Switch BB_Credit Buffers
Cisco MDS 9148 Fabric Switch BB_Credit Buffers
Table 6-9 lists the BB_credit buffer allocation for 48-port 8-Gbps Fibre Channel switches.
Table 6-9 48-Port 8-Gbps Fabric Switch BB_Credit Buffer Allocation
BB_Credit Buffer Allocation Type
BB_Credit Buffers Per Port Group
BB_Credit Buffers Per Port
  ISL 1
Fx Port
Default BB_credit buffers
128
32
32
Maximum configurable BB_credit buffers on 8-Gbps mode
128
125
125
1 ISL = E port or TE port.

The following considerations apply to BB_credit buffers on 48-port 8-Gbps Fabric Switches:
•BB_credit buffers can be configured from a minimum of 1 buffer to a maximum of 32 buffers per port when the ports are in F or FL mode.
•BB_credit buffers can be configured from a minimum of 2 buffers to a maximum of 32 buffers per port when the ports are in E or TE mode.
Cisco MDS 9134 Fabric Switch BB_Credit Buffers
Table 6-10 lists the BB_credit buffer allocation for 32-port 4-Gbps Fibre Channel switches.
Table 6-10 32-Port 4-Gbps Fabric Switch BB_Credit Buffer Allocation
BB_Credit Buffer Allocation Type
BB_Credit Buffers Per Port Group
BB_Credit Buffers Per Port
  ISL 1
Fx Port
User-configurable BB_credit buffers
64
64
64
Default BB_credit buffers on 10-Gbps mode
64
64
64
Default BB_credit buffers on 4-Gbps mode
64
16
16
1 ISL = E port or TE port.

The following considerations apply to BB_credit buffers on 32-port 4-Gbps switches:
•BB_credit buffers can be configured from a minimum of 1 buffer to a maximum of 61 buffers per port when the ports are in F mode and in 4-Gbps speed mode.
•BB_credit buffers can be configured from a minimum of 2 buffers to a maximum of 64 buffers per port when the ports are in auto or E mode and in 4-Gbps speed mode.
•BB_credit buffers can be configured from a minimum of 64 buffers to a maximum of 64 buffers per port when a port is in 10-Gbps speed mode. There can be only one port per port group configured in 10-Gbps mode. The rest of the three ports must be in down state.
•BB_credit buffers for Fx port mode connections can be configured from a minimum of 2 buffers to a maximum of 64 buffers.
Cisco MDS 9124 Fabric Switch BB_Credit Buffers
Table 6-11 lists the BB_credit buffer allocation for 24-port 4-Gbps Fibre Channel switches.
Table 6-11 24-Port 4-Gbps Fabric Switch BB_Credit Buffer Allocation Defaults 
BB_Credit Buffer Allocation Type
BB_Credit Buffers Per Port Group
BB_Credit Buffers Per Port Defaults
  ISL 1
Fx Port
User-configurable BB_credit buffers
64
16
16
1 ISL = E port or TE port.

Cisco MDS 9222i Multiservice Modular Switch BB_Credit Buffers
Table 6-12 lists the BB_credit buffer allocation for 18-port 4-Gbps Multiservice Modular switches.
Table 6-12 18-Port 4-Gbps Fabric Switch BB_Credit Buffer Allocation Defaults 
BB_Credit Buffer Allocation Type
BB_Credit Buffers Per Port Group
BB_Credit Buffers Per Port Defaults
  ISL 1
Fx Port
User-configurable BB_credit buffers
4509
250
16
1 ISL = E port or TE port.

About Extended BB_Credits
To facilitate BB_credits for long-haul links, the extended BB_credits feature allows you to configure the receive buffers above the maximum value on all Generation 2 and Generation 3 switching modules. When necessary, you can reduce the buffers on one port and assign them to another port, exceeding the default maximum. The minimum extended BB_credits per port is 256 and the maximum is 4095.
Note Extended BB_credits are not supported on the Cisco MDS 9148 Fabric Switch, Cisco MDS 9134 Fabric Switch, Cisco MDS 9124 Fabric Switch, the Cisco Fabric Switch for HP c-Class BladeSystem, and the Cisco Fabric Switch for IBM BladeCenter.
In general, you can configure any port in a port group to dedicated rate mode. To do this, you must first release the buffers from the other ports before configuring larger extended BB_credits for a port.
Note The ENTERPRISE_PKG license is required to use extended BB_credits on Generation 2 and Generation 3 switching modules. Also, extended BB_credits are not supported by ports in shared rate mode.

All ports on the Generation 2 and Generation 3 switching modules support extended BB_credits. There are no limitations for how many extended BB_credits you can assign to a port (except for the maximum and minimum limits). If necessary, you can take interfaces out of service to make more extended BB_credits available to other ports.
You can use the extended BB_credits flow control mechanism in addition to BB_credits for long-haul links.
This section includes the following topics:
•Extended BB_credits on Generation 1 Switching Modules
•Extended BB_credits on Generation 2 and Generation 3 Switching Modules
Extended BB_credits on Generation 1 Switching Modules
The BB_credits feature allows you to configure up to 255 receive buffers on Generation 1 switching modules. To facilitate BB_credits for long haul links, you can configure up to 3,500 receive BB_credits on a Fibre Channel port on a Generation 1 switching module.
To use this feature on Generation 1 switching modules, you must meet the following requirements:
•Obtain the ENTERPRISE_PKG license. See the Cisco MDS 9000 Family NX-OS Licensing Guide.
•Configure this feature in any port of the full-rate 4-port group in either the Cisco MDS 9216i Switch or in the MPS-14/2 module (see Figure 6-9).
Figure 6-9 Port Group Support for the Extended BB_Credits Feature
The port groups that support extended credit configurations are as follows:
–Any one port in ports 1 to 4 (identified as Group 1).
–Any one port in ports 5 to 8 (identified as Group 2).
–Any one port in ports 9 to 12 (identified as Group 3).
Note The last two Fibre Channel ports (port 13 and port 14) and the two Gigabit Ethernet ports do not support the extended BB_credits feature.
•Explicitly enable this feature in the required Cisco MDS switch.
•Disable the remaining three ports in the 4-port group if you need to assign more than 2,400 BB_credits to the first port in the port group.
–If you assign less than 2,400 extended BB_credits to any one port in a port group, the remaining three ports in that port group can retain up to 255 BB_credits based on the port mode.
Note The receive BB_credit value for the remaining three ports depends on the port mode. The default value is 16 for the Fx mode and 255 for E or TE modes. The maximum value is 255 in all modes. This value can be changed as required without exceeding the maximum value of 255 BB_credits.
–If you assign more than 2,400 (up to a maximum of 3,500) extended BB_credits to the port in a port group, you must disable the other three ports.
•Be aware that changing the BB_credit value results in the port being disabled and then reenabled.
•Disable (explicitly) this feature if you need to nondisruptively downgrade to Cisco SAN-OS Release 1.3 or earlier. When you disable this feature, the existing extended BB_credit configuration is completely erased.
Note The extended BB_credit configuration takes precedence over the receive BB_credit and performance buffer configurations.
Extended BB_credits on Generation 2 and Generation 3 Switching Modules
To use this feature on Generation 2 or Generation 3 switching modules, you must meet the following requirements:
•Display the interface configuration in the Information pane.
•Obtain the Enterprise package (ENTERPRISE_PKG) license (see the NX-OS Family Licensing Guide).
•Configure this feature in any port on a Generation 2 switch module. See the "About Extended BB_Credits" section for more information on extended BB_credits on Generation 2 switching modules.
Note Extended BB_credits are not supported on the Cisco MDS 9124 Fabric Switch, Cisco MDS 9134 Fabric Switch, the Cisco Fabric Switch for HP c-Class BladeSystem, and the Cisco Fabric Switch for IBM BladeCenter.
Configuring Extended BB_credits
To configure extended BB_credits for an MDS-14/2 interface, for a Generation 2 switching module interface, or for an interface in a Cisco MDS 9216i switch using Fabric Manager, follow these steps:
Step 1 Expand Switches > Interfaces and then select FC Physical. You see the interface configuration in the Information pane.
Step 2 Click the BB Credit tab.
Step 3 In the Extended column, set the extended BB_credits for the selected interface.
Step 4 Click Apply Changes.
Enabling Buffer-to-Buffer Credit Recovery
Although the Fibre Channel standards require low bit error rates, bit errors do occur. Over time, the corruption of receiver-ready messages, known as R_RDY primitives, can lead to a loss of credits, which can eventually cause a link to stop transmitting in one direction. The Fibre Channel standards provide a feature for two attached ports to detect and correct this situation. This feature is called buffer-to-buffer credit recovery.
Buffer-to-buffer credit recovery functions as follows: the sender and the receiver agree to send checkpoint primitives to each other, starting from the time that the link comes up. The sender sends a checkpoint every time it has sent the specified number of frames, and the receiver sends a checkpoint every time it has sent the specified number of R_RDY primitives. If the receiver detects lost credits, it can retransmit them and restore the credit count on the sender.
The buffer-to-buffer credit recovery feature can be used on any nonarbitrated loop link. This feature is most useful on unreliable links, such as MANs or WANs, but can also help on shorter, high-loss links, such as a link with a faulty fiber connection.
Note The buffer-to-buffer credit recovery feature is not compatible with distance extension (DE) feature, also known as buffer-to-buffer credit spoofing. If you use intermediate optical equipment, such as DWDM transceivers or Fibre Channel bridges, on ISLs between switches that use DE, then buffer-to-buffer credit recovery on both sides of the ISL needs to be disabled.
Buffer-to-buffer credit recovery on ISLs (E or TE ports) is enabled by default.
About Receive Data Field Size
You can also configure the receive data field size for Fibre Channel interfaces. If the default data field size is 2112 bytes, the frame length will be 2148 bytes.
Configuring Receive Data Field Size
You can also configure the receive data field size for Fibre Channel interfaces. If the default data field size is 2112 bytes, the frame length will be 2148 bytes.
To configure the receive data field size using Fabric Manager, follow these steps:
Step 1 Expand Switches > Interfaces and then select FC Physical.
You see the interface configuration in the Information pane.
Step 2 Click the Other tab and set the RxDataFieldSize field (see Figure 6-10).
Figure 6-10 Changing Rx Data Size
Step 3 (Optional) Set other configuration parameters using the other tabs.
Step 4 Click Apply Changes.
Was this Document Helpful?
Yes No
Feedback
Contact Cisco
Open a Support Case
(Requires a Cisco Service Contract)
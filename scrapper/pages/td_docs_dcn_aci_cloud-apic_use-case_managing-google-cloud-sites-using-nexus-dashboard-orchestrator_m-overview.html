Configuration Examples and TechNotes
Managing Google Cloud Sites Using Nexus Dashboard Orchestrator
Bias-Free Language
Book Contents
Translations
Download
Print
Updated:
December 19, 2021
Chapter: Overview
Chapter Contents
Prerequisites and Guidelines
Google Cloud Overview
Inter-Site Connectivity Using BGP-EVPN
External Network Connectivity
Configuring Routing and Security Policies Separately
Prerequisites and Guidelines
Before you follow the procedures described in this document, you must have the following:
Cisco Cloud Network Controller (formerly Cloud APIC) deployed in Google Cloud.

Note
For external connectivity and VRF leaking use case, you must deploy Cloud APIC release 25.0(2) or later.
For EVPN intersite connectivity, you must deploy Cloud Network Controller (formerly Cloud APIC) release 25.0(5) or later.
For more information, see the Cisco Cloud APIC for Google Cloud Installation Guide for your release.
Cisco Nexus Dashboard release 2.1(2) or later deployed and all sites onboarded.
Nexus Dashboard is required for hosting the Nexus Dashboard Orchestrator service, which you will use to configure the use cases.
For more information, see the Cisco Nexus Dashboard Deployment Guide for your release.
Cisco Nexus Dashboard Orchestrator service installed and enabled in Nexus Dashboard and all sites enabled for management in the Orchestrator UI.

Note
For external connectivity and VRF leaking use case, you must deploy Orchestrator release 3.7(1) or later.
For EVPN intersite connectivity, you must deploy Orchestrator release 4.0(2) or later.
For more information, see the Cisco Nexus Dashboard Orchestrator Deployment Guide
In addition to the requirement above, the following guidelines and limitations apply to configuring Google Cloud sites:
Google cloud does not support routing based on contracts. Routing must be configuring using route leaking between external VRFs or infra intersite connectivity.
If configuring the external connectivity use case, external connectivity between two Google cloud sites is not supported
If configuring the external connectivity use case, the external VRF can be configured only in the infra tenant
The tenant "common" cannot be associated with any Google cloud project
In Google cloud, the infra VPC and spoke VPCs are connected through VPC peering
In order configure connectivity between the on-premises data center and the public cloud, you must manually configure the remote device by downloading the external device configuration files and manually enabling connectivity between Google cloud and the external devices
The external device configuration files that you download are not final configurations. Instead, the external device configuration files are provided more as a guidance. You must manually modify the information in the configuration files to configure the Google Cloud Router with IPSec, which is used to create connectivity between the on-premises data center and the public cloud, where:
The Google Cloud Router and tunnels are deployed in the infra (hub) VPC
Google Cloud Overview
The following sections provide a brief overview of Google Cloud concepts as they relate to the Cisco Cloud APIC and Nexus Dashboard Orchestrator. For detailed information about Cloud APIC deployment and configuration, see the Cloud APIC documentation.
Locating Important Google Cloud Project Information
Understanding Google Cloud Deployments with Cloud APIC
Locating Important Google Cloud Project Information
The following information is required if you plan to create new tenants in your Google Cloud sites. If you plan to import existing tenants only, you can skip this section.
After you create a Google Cloud project, that project will be assigned three unique identifiers:
Project name
Project ID
Project number
You will need these three identifiers for your Google Cloud project at various points in the Google Cloud configuration process. To locate the Project Info pane with these Google Cloud project identifiers, log into your Google Cloud account and select your particular Google Cloud project in the Select a project window. The Dashboard for this project is displayed, which provides the Project Info pane with these three unique identifiers for your Google Cloud project.
Understanding Google Cloud Deployments with Cloud APIC
Google Cloud organizes resources in a way that resembles a file system, where:
The Organization at the top level can have multiple Folders.
Every Folder can contain other Folders, or can contain Projects, where every Project has a unique ID.
Cloud resources (such as VMs, VPCs, and subnets) are contained within a Project.
While the Organization and Folder levels are useful areas to understand from the Google Cloud perspective, the Project level is the most relevant from the Cloud APIC perspective.
Each Cloud APIC tenant is mapped one-to-one to a Google Cloud Project, which means that:
A Cloud APIC tenant cannot span multiple Google Cloud Projects
There cannot be more than one Cloud APIC tenant in a Google Cloud Project
With Cloud APIC, Google Cloud provides access to Projects using Service Accounts. These accounts are meant for applications that need to access Google Cloud services. They can be used to run and deploy Cloud APIC and to push policies for other tenants. Service accounts used in applications running within Google Cloud do not need credentials, whereas applications that are run external to Google Cloud need a pre-generated private key. Service Accounts reside in one Google Cloud Project, but they can also be given access to manage policies for other Projects (for Cloud APIC, other tenants).
User Tenants With Managed Credentials
This type of user tenant has the following characteristics:
This tenant account is managed by the Cisco Cloud APIC.
You will first choose Managed Identity in the Nexus Dashboard Orchestrator GUI as part of the tenant configuration process for this type of user tenant.
After you have configured the necessary parameters in the Nexus Dashbaord Orchestrator, you must then set the necessary roles for this tenant in Google Cloud. Add the service account created by the Cloud APIC as an IAM user with the following rules:
Cloud Functions Service Agent
Compute Instance Admin (v1)
Compute Network Admin
Compute Security Admin
Logging Admin
Pub/Sub Admin
Storage Admin
User Tenants With Unmanaged Credentials
This type of user tenant has the following characteristics:
This tenant account is not managed by the Cisco Cloud APIC.
Before configuring the necessary parameters in the Cisco Cloud APIC for this type of tenant, you must first download the JSON file that contains the necessary private key information from Google Cloud for the service account associated with this tenant.
You will then choose Unmanaged Identity in the Nexus Dashboard Orchestrator GUI as part of the tenant configuration process for this type of user tenant. As part of the configuration process for this type of tenant in Nexus Dashbaord Orchestrator, you will provide the following information from the downloaded JSON file:
Key ID
RSA Private Key
Client ID
Email
Inter-Site Connectivity Using BGP-EVPN
Beginning with Cloud Network Controller release 25.0(5), support is also available for configuring a BGP-EVPN connection for inter-site connectivity in these scenarios:
Cloud site to cloud site:
Google Cloud site to Google Cloud site
Google Cloud site to AWS site
Google Cloud site to Azure site
Google Cloud site to ACI on-premises site
In each of these scenarios, Cisco Catalyst 8000Vs are used for the BGP-EVPN connection.
Characteristics of Inter-Site Connectivity Using BGP-EVPN
Based on Google Cloud behavior, each network interface of a VM or instance must be associated with a different VPC. Because the Cisco Catalyst 8000V is also a VM, this means that each network interface for a given Cisco Catalyst 8000V has to be associated with a different VPC. Two gigabit network interfaces in the Cisco Catalyst 8000V are therefore used in the following ways:
The gig1 interface is associated with the overlay-1 secondary VPC. In addition, the gig1 interface is used as the management interface.
The gig2 interface is associated with the overlay-1 VPC. In addition, the gig2 interface is used as the routing interface.
VPC Peering
In order to have communication from the spoke VPC to an on-premises network, the spoke VPC must have peering enabled to the hub VPCs. The peering is automated by intent from Cisco Cloud Network Controller. VPC peering for Cisco Cloud Network Controller with Google Cloud employs a hub-spoke topology, as shown in the following figure.
Cisco Cloud Network Controller with Google Cloud uses three types of VPC peering:
Spoke-to-spoke VPC peering: This is used for spoke-to-spoke intra-site communication.
Hub-to-spoke VPC peering: This is used for inter-site communication that goes through the Cisco Catalyst 8000V routers using BGP-EVPN.
Hub-to-hub VPC peering: This is used for communication between the Cisco Cloud Network Controller in the overlay-1 VPC and the Cisco Catalyst 8000V routers management interfaces in the overlay-1 secondary VPC.
Note that the overlay-1 secondary VPC is not involved in the data path for either spoke-to-spoke or inter-site traffic.
Cisco Cloud Network Controller automates configurations to exchange the routes between cloud sites in the following situations:
Overlay-1 VPC to the destination in the same site: The overlay-1 VPC has the route to the spoke VPC in the same site through VPC peering.
Spoke VPCs to the destination in another site: The routes for the subnets in the other site are added to the overlay-1 VPC by Cisco Cloud Network Controller and the routes are exported to the spoke VPCs. In this way, the spoke VPCs have the routes to reach the destination subnets in the other site.
Between Cisco Catalyst 8000Vs in different sites: The static route for the spoke VPC CIDRs are added to the Cisco Catalyst 8000V routers in the same site. The static routes are redistributed to the Catalyst 8000V routers in the other site through BGP EVPN. In this way, the Catalyst 8000Vs have the routes to reach the destination subnets in the other site, as shown in the following figure.
In this scenario, a static route to the remote CIDR is programmed in the hub VPC with the next hop as the Cisco Catalyst 8000V. These routes are learned by the spoke VPC using peering.
External Network Connectivity
Support is available for external connectivity between a Google Cloud site and non-Google Cloud sites or an external device. You can have this IPv4 connection by creating a VPN connection between a Google Cloud router and an external device, including a CSR.
The following sections provide more information on the components that allow for the new external network connectivity provided in Cloud APIC release 25.0(2) and later.
External VRF
An external VRF is a unique VRF that does not have any presence in the cloud. This VRF is not referred to in any cloud context profile used by Nexus Dashboard Orchestrator.
An external VRF represents an external network that is connected to other cloud sites or to on-premises sites. Multiple cloud VRFs can leak routes to an external VRF or can get the routes from an external VRF. When an external network is created on an external VRF, inter-VRF routing is set up so that routes received and advertised on the external network are received or advertised on the external VRF.
Cloud Native Routers
When configuring Cisco Cloud APIC with Google Cloud, the infra VPC uses Google Cloud native routers (Cloud Router and Cloud VPN gateway) to create IPsec tunnels and BGP sessions to on-premises sites, other cloud sites, or any remote device. Only BGP-IPv4 connectivity is supported for this type of connectivity using cloud native routers, where BGP-IPv4 sessions are created on an external VRF.
Google Cloud supports VPN connections both with static routes and with BGP. To create a VPN connection with BGP, Cisco Cloud APIC needs both a Cloud Router and a VPN gateway. A VPC can have multiple Cloud Routers and VPN gateways. However, Google Cloud has a restriction that both the Cloud Routers and the VPN gateways must be in the same region and in the same VPC. In addition, Cisco Cloud APIC has a restriction where only one cloud router and one cloud VPN gateway is supported per region.
VPN Communication
When configuring Cisco Cloud APIC with Google Cloud, the infra VPC is used to host the Cisco Cloud APIC and to host the VPN connections to external devices and sites. However, the infra VPC is not used as a transit to implement spoke-to-spoke communication. Instead, when configuring Cisco Cloud APIC with Google Cloud, spoke-to-spoke communication is done though spoke-to-spoke VPC peering.
The infra VPC uses the Google Cloud Router and Google Cloud VPN Gateway to create IPsec tunnels and BGP sessions to on-premises sites or to other cloud sites. Spoke VPCs peer with the infra VPC to share the VPN connections to external sites, where:
Routes received on the VPN connections are leaked to the spoke VPCs
Spoke VPC routes are advertised on the VPN connections
Using inter-VRF routing, the route is leaked between the external VRF of the VPN connections and the cloud local spoke VRFs.
A VPN gateway has two interfaces, and Google Cloud allocates public IP addresses to each of the interfaces. While the Google Cloud VPN gateway could have one or two interfaces, Cisco Cloud APIC only supports VPN gateways with two interfaces because two interfaces are required to achieve high availability.
Configuring Routing and Security Policies Separately
To allow communication between two endpoints in different VRFs, you need to establish routing and security policies separately:
Routing policies: Policies used to define routes to establish traffic flow
Security policies: Rules used for security purposes, such as zoning rules, security-group rules, ACLs, and so on
For Google Cloud, routing must be configured independent of security. In other words, for Google Cloud, "contracts" are used only for security. To configure routing, you must configure VRF route leaking.
Configuring Routing Policies
Configuring Security Policies
Configuring Routing Policies
Using inter-VRF routing, you can configure an independent routing policy to specify which routes to leak between a pair of VRFs. To establish routing, you must configure route maps between a pair of VRFs.
For situations where you can use route maps to set which routes to leak between a pair of VRFs, the following types of VRFs are used for inter-VRF routing:
External VRF is a VRF that is associated with one or more external networks.
Internal VRF is a VRF that has one or more cloud context profiles or cloud subnets associated with it.
When configuring inter-VRF routing with these types of VRFs:
Between a pair of internal VRFs, you must always leak all routes.
From an internal VRF to an external VRF, you can leak specific routes or all routes.
From an external VRF to an internal VRF, you must leak all routes.
Guidelines and Restrictions
The following guidelines apply when using inter-VRF routing to leak routes between a pair of VRFs using route maps:
Routes are always leaked bi-directionally between two VRFs. For every route leak entry from one tenant/VRF under another tenant/VRF, there must be a corresponding route leak entry going in the opposite direction.
For example, assume there are two tenants (t1 and t2) and two corresponding VRFs (v1 and v2). For every route leak entry t1:v1 under the VRF t2:v2, there must be a corresponding route leak entry t2:v2 under the VRF t1:v1.
Once you associate an external VRF with an external network, if you want to change the external VRF, you need to delete the external network and then recreate the external network with the new external VRF.
You cannot configure "smaller" prefixes to be leaked while a "larger" prefix is already being leaked. For example, configuring the 10.10.10.0/24 prefix will be rejected if you already have the 10.10.0.0/16 prefix configured to be leaked. Similarly, if you configure the 0.0.0.0/0 (leak all) prefix, no other prefix will be allowed to be configured.
Configuring Security Policies
While an EPG in Cisco Cloud APIC corresponds to security groups in AWS and Azure, there is no equivalent corresponding component in Google Cloud for an EPG. The closest equivalent in Google Cloud is a combination of firewall rules and network tags.
The firewall resource in Google Cloud is global to the project (tenant). Firewall rules are associated with a single VPC and their scope applies to the entire VPC globally. The scope of the firewall rule is further defined by the Target parameter. In other words, the set of instances that a rule is applied to can be selected by one or more of the following Target types:
Network tags: Network tags are key strings that drive the VM’s firewall and routing configuration on Google Cloud. Instances (for example, VMs) can be tagged with unique strings. Firewall rules are applied to all instances with equal tags. Multiple tag values act as a logical ‘or’ operator, where the firewall rule is applied as long as at least one tag matches.
All instances in the network: The firewall rule applies to all instances in the VPC.
Firewall rules also identify the source and destination of the traffic. Depending on whether the rule is for ingress traffic (going to a VM) or egress traffic (leaving a VM), the source and destination fields accept different values. The following list provides more information on those values:
Ingress rules:
Source: Can be identified using:
Network tags
IP addresses
A combination of IP addresses and network tags with a logical ‘or’ operator
Destination: The Target parameter identifies the destination instances
Egress rules:
Source: The Target parameter identifies the source instances
Destination: Can be identified using only IP addresses (not network tags)
How Cisco Cloud APIC Implements Firewall Rules With Google Cloud
The following list describes how Cisco Cloud APIC implements firewall rules with Google Cloud :
Global resources: VPCs and firewalls in Google Cloud are global resources, so Cisco Cloud APIC does not have to program firewall rules for endpoints that span multiple regions. The same firewall rules apply for any region where the endpoint resides.
Firewall egress rules and network tags: Firewall egress rules do not support network tags as a destination field, so you must list individual IP addresses for endpoints.
Source tags in firewall ingress rules and alias IP ranges: Firewall ingress rules do not include the alias IP ranges of VMs matching the network tags used in the source field.
Priority fields in firewall rules: Google Cloud evaluates firewall rules following their priority values.
Given that Google Cloud firewall rules follow a priority list, Cisco Cloud APIC configures a pair of low-priority deny-all ingress and egress rules when the VPC is created. Afterwards, Cisco Cloud APIC configures rules that open traffic according to the EPG’s contracts with higher priority. Therefore, if there is no explicit rule that allows certain traffic as a result of an EPG contract, the low-priority rule matches and the default behavior is deny-all.
Endpoints and Endpoint Selectors
On the Cisco Cloud APIC, a cloud EPG is a collection of endpoints that share the same security policy. Cloud EPGs can have endpoints in one or more subnets and are tied to a VRF.
The Cisco Cloud APIC has a feature called endpoint selector, which is used to assign an endpoint to a Cloud EPG. The endpoint selector is essentially a set of rules run against the cloud instances assigned to the Google Cloud VPC managed by Cisco ACI. Any endpoint selector rules that match endpoint instances will assign that endpoint to the Cloud EPG. The endpoint selector is similar to the attribute-based microsegmentation available in Cisco ACI.
Following are the types of endpoint selectors available for the two types of cloud EPGs:
Application EPGs:
IP: Used to select by the IP address or subnet.
Region: Used to select by the region of the endpoint.
Custom: Used to select by a custom tag or label. For example, if you added a Location tag in Google Cloud, you might create the custom tag Location in this field to match the Location tag that you added in Google Cloud earlier.
External EPGs:
Subnet: The subnet selector is a type of endpoint selector where the match expression uses the IP address of a subnet, so an entire subnet is assigned as being part of the EPG. Essentially, when you use the subnet selector as the endpoint selector, all of the endpoints within that subnet belongs to the associated EPG.
When using Cisco Cloud APIC endpoint selectors with Google Cloud, a network tag is applied that associates the EPG to the matching VM in Google Cloud. Once the network tag is configured in the VM, Google Cloud applies the firewall rules for the VM’s traffic.
VMs on Google Cloud also support labels. Labels are key-value pairs that are meant to be an organizational tool. The custom endpoint selector in Cisco Cloud APIC recognizes the labels assigned to the VMs in Google Cloud.
Cisco Cloud APIC reserves a unique network tag string for each EPG. In Google Cloud, this value is used as the target field in the firewall rules created for the EPG. When a new VM matches an endpoint selector of the EPG, Cisco Cloud APIC appends this value to the existing VM’s network tags. In addition, the EPG’s network tag is used in the source field of the Google Cloud firewall rules.
Assuming there are three endpoints in the VPC with the following configuration, Cisco Cloud APIC configures the following network tags, where the Cisco Cloud APIC-configured network tags are in the following format:
capic-<app-profile-name>-<epg-name>
Endpoint
Application Profile
EPG
Primary IP
Labels
Cloud APIC-Configured Network Tags
EP1
First application profile (app01)
First EPG (epg01)
10.0.0.1
server:web
capic-app01-epg01
EP2
Second application profile (app02)
Second EPG (epg02)
20.0.0.1
server:backend
capic-app02-epg02
EP3
Second application profile (app02)
Third EPG (epg03)
30.0.0.1
server:database
capic-app02-epg03
Cisco Cloud APIC needs admin permission over the VMs in order to set their network tags. This permission is granted by the Compute Instance Admin role.
There might be cases where Cisco Cloud APIC does not have this permission and cannot manage the VM’s tags. In those scenarios, you can configure the network tags in your VMs first and then provide the proper endpoint selector configuration to Cisco Cloud APIC later on.
To see firewall rules:
In Google Cloud: In your Google Cloud account, navigate to VPC Network > Firewall.
If the VM is part of an EPG, you can find the endpoints by expanding a firewall rule and then viewing the multiple entries shown in the Filters column. which are the endpoints.
Use the entry in the Type column to determine if a particular firewall rule is an ingress or an egress firewall rule.
If the firewall rule is an ingress type, then traffic is being sent to these endpoints.
If the firewall rule is an egress type, then these entries show where it can receive the traffic.
In Cisco Cloud APIC: Firewall rules are associated with VPCs, so navigate to Cloud Resources > VPCs, then double-click on a VPC to get the detail screen. Then click on the Cloud Resources tab; there you will see the ingress and egress rules.
Was this Document Helpful?
Yes No
Feedback
Contact Cisco
Open a Support Case
(Requires a Cisco Service Contract)
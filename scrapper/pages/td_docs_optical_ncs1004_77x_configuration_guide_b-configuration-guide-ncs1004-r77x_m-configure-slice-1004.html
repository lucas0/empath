Configuration Guides
Configuration Guide for Cisco NCS 1004, IOS XR Release 7.7.x
Bias-Free Language
Book Contents
Download
Print
Updated:
July 30, 2022
Chapter: Configuring the Card Mode
Chapter Contents
This chapter lists the supported configurations and the procedures to configure the card mode on the line cards.

Note
Unless otherwise specified, “line cards” refers to 1.2T and 1.2TL line cards.
1.2T and 1.2TL Line Cards
OTN-XP Card
2-QDD-C Line Card
QXP Card
1.2T and 1.2TL Line Cards
The following section describes the supported configurations and procedures to configure the card modes on the line cards.
Card Modes
Sub 50G Configuration
Supported Data Rates
Configuring the Card Mode
Regeneration Mode
Configuring the BPS
Configuring the Trunk Rate for BPSK
Card Modes
The line cards support module and slice configurations.
The line cards have two trunk ports (0 and 1) and 12 client ports (2 through 13) each. You can configure the line card in two modes:
Muxponder—In this mode, both trunk ports are configured with the same trunk rate. The client-to-trunk mapping is in a sequence.
Muxponder slice—In this mode, each trunk port is configured independent of the other with different trunk rates. The client-to-trunk mapping is fixed. For Trunk 0, the client ports are 2 through 7. For Trunk 1, the client ports are 8 through 13.
Sub 50G Configuration
You can configure the sub 50G or coupled mode on the line card only in the muxponder mode. The following table displays the port configuration for the supported data rates.
Trunk Data Rate (per trunk)
Total Configured Data rate
Card Support
Trunk Ports
Client Ports for Trunk 0 (100G)
Shared Client Port (50G per trunk)
Client Ports for Trunk 1 (100G)
50G
100G
1.2T, 1.2TL
0, 1
-
2
-
150G
300G
1.2T, 1.2TL
0, 1
2
3
4
250G
500G
1.2T, 1.2TL
0, 1
2, 3
4
5, 6
350G
700G
1.2T, 1.2TL
0, 1
2, 3, 4
5
6, 7, 8
450G
900G
1.2T
0, 1
2, 3, 4, 5
6
7, 8, 9, 10
550G
1.1T
1.2T
0, 1
2, 3, 4, 5, 6
7
8, 9, 10, 11, 12
From Release 7.5.2, 1.2T and 1.2TL line cards support an alternate port configuration for Sub 50G (split client port mapping) that you configure using CLI. The following table displays the port configuration for the supported data rates.
Trunk Data Rate (per trunk)
Total Configured Data rate
Card Support
Trunk Ports
Client Ports for Trunk 0 (100G)
Shared Client Port (50G per trunk)
Client Ports for Trunk 1 (100G)
50G
100G
1.2T, 1.2TL
0, 1
-
7
-
150G
300G
1.2T, 1.2TL
0, 1
2
7
8
250G
500G
1.2T, 1.2TL
0, 1
2, 3
7
8, 9
350G
700G
1.2T, 1.2TL
0, 1
2, 3, 4
7
8, 9, 10
450G
900G
1.2T
0, 1
2, 3, 4, 5
7
8, 9, 10, 11
550G
1.1T
1.2T
0, 1
2, 3, 4, 5, 6
7
8, 9, 10, 11, 12

Note
In all x50G configurations, client traffic on the middle port is affected with ODUK-BDI and LF alarms after the power cycle or link flap on the trunk side. This issue is raised when the two network lanes work in coupled mode and move from low to high power. To solve this issue, create a new frame either at the near-end or far-end by performing shut or no shut of the trunk ports.
Coupled Mode Restrictions
The following restrictions apply to the coupled mode configuration:
Both trunk ports must be configured with the same bits-per-symbol or baud rate and must be sent over same fiber and direction.
The chromatic dispersion must be configured to the same value for both trunk ports.
When trunk internal loopback is configured, it must be done for both trunk ports. Configuring internal loopback on only one trunk results in traffic loss.
Fault on a trunk port of a coupled pair may cause errors on all clients including those running only on the unaffected trunk port.
Configure Split Client Port Mapping
Configure Split Client Port Mapping
Table 1. Feature History
Feature Name
Release Information
Description
Split Client Port Mapping
Cisco IOS XR Release 7.5.2
A new trunk port to client port mapping for sub 50G configurations is now available on the 1.2T C band, 1.2T L band, and 800G QSFP-DD Transponder line cards. In this mapping, the same shared client port is used for all Sub 50G trunk data rates, eliminating recabling while changing the data rates.
You can configure the trunk port to client port mapping for sub 50G data ratesin the default mode or in the split client port mapping mode.
In the default mode, consecutive client ports carry the information. For example, on a 2-QDD-C card, if the trunk data rate per trunk is 150G, client ports 2, 3, and 4 carry the data and client port 3 is the shared client port. For a trunk data rate of 250G, client ports 2, 3, 4, 5, and 6 carry the data and client port 4 is the shared client port. However, if you configure split client port mapping, trunk port to client port mapping is fixed. The shared client port is client port 5 for 2-QDD-C card and client port 7 for 1.2T and 1.2TL cards.
To configure the split client port mapping, use the following commands.
configure
hw-module location location mxponder
split-client-port-mapping
commit
The following is a sample in which split-client-port-mapping is configured with a 450G trunk payload.
RP/0/RP0/CPU0:ios#configure
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#split-client-port-mapping
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#end
To remove the split client port-mapping configuration and configure default client port mapping, use the following commands.
configure
hw-module location location mxponder
no split-client-port-mapping
commit
The following is a sample in which split client port-mapping configuration is removed.
RP/0/RP0/CPU0:ios#configure
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#no split-client-port-mapping
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#end
Verifying the Port Mapping Configuration
The following is a sample ouput of the split client port-mapping.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder

Location:             0/1
Client Bitrate:       100GE
Trunk  Bitrate:       450G
Status:               Provisioning In Progress
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/1/0/0   CoherentDSP0/1/0/1
                                Traffic Split Percentage

HundredGigECtrlr0/1/0/2         ODU40/1/0/0/1                         100                        0
HundredGigECtrlr0/1/0/3         ODU40/1/0/0/2                         100                        0
HundredGigECtrlr0/1/0/4         ODU40/1/0/0/3                         100                        0
HundredGigECtrlr0/1/0/5         ODU40/1/0/0/4                         100                        0
HundredGigECtrlr0/1/0/7         ODU40/1/0/0/5                          50                       50
HundredGigECtrlr0/1/0/8         ODU40/1/0/1/1                           0                      100
HundredGigECtrlr0/1/0/9         ODU40/1/0/1/2                           0                      100
HundredGigECtrlr0/1/0/10        ODU40/1/0/1/3                           0                      100
HundredGigECtrlr0/1/0/11        ODU40/1/0/1/4                           0                      100
The following is a sample ouput of the default client port mapping.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder

Location:             0/1
Client Bitrate:       100GE
Trunk  Bitrate:       450G
Status:               Provisioning In Progress
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/1/0/0   CoherentDSP0/1/0/1
                                Traffic Split Percentage

HundredGigECtrlr0/1/0/2         ODU40/1/0/0/1                         100                        0
HundredGigECtrlr0/1/0/3         ODU40/1/0/0/2                         100                        0
HundredGigECtrlr0/1/0/4         ODU40/1/0/0/3                         100                        0
HundredGigECtrlr0/1/0/5         ODU40/1/0/0/4                         100                        0
HundredGigECtrlr0/1/0/6         ODU40/1/0/0/5                          50                       50
HundredGigECtrlr0/1/0/7         ODU40/1/0/1/1                           0                      100
HundredGigECtrlr0/1/0/8         ODU40/1/0/1/2                           0                      100
HundredGigECtrlr0/1/0/9         ODU40/1/0/1/3                           0                      100
HundredGigECtrlr0/1/0/10        ODU40/1/0/1/4                           0                      100
Supported Data Rates
The following data rates are supported on the line card.
In R7.0.1, you can configure the client port to OTU4 only in the muxponder mode. In R7.1.1 and later releases, you can configure the client port to OTU4 in both the muxponder and muxponder slice modes. In muxponder slice mode, both the slices must be configured with either OTU4 or 100GE Ethernet client rates in R7.1.1. In R7.2.0, a mixed configuration of OTU4 and 100GE is supported in the muxponder slice mode. LLDP drop, L1 encryption, and AINS are not supported on the OTU4 configuration.
The following table displays the client and trunk ports that are enabled for the muxponder configuration.
Trunk Data Rate
Card Support
Client Data Rate (100GE, OTU4)
Trunk Ports
Client Ports
100
1.2T, 1.2TL
100GE, OTU4
0
2
200
1.2T, 1.2TL
100GE, OTU4
0, 1
2, 3, 4, 5
300
1.2T, 1.2TL
100GE, OTU4
0, 1
2, 3, 4, 5, 6, 7
400
1.2T, 1.2TL
100GE, OTU4
0, 1
2, 3, 4, 5, 6, 7, 8, 9
500
1.2T
100GE, OTU4
0, 1
2, 3, 4, 5, 6, 7, 8, 9, 10, 11
600
1.2T
100GE, OTU4
0, 1
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13
The following table displays the client and trunk ports that are enabled for the muxponder slice 0 configuration.
Trunk Data Rate
Card Support
Client Data Rate
Trunk Ports
Client Ports
100
1.2T, 1.2TL
100, OTU4
0
2
200
1.2T, 1.2TL
100, OTU4
0
2, 3
300
1.2T, 1.2TL
100, OTU4
0
2, 3, 4
400
1.2T, 1.2TL
100, OTU4
0
2, 3, 4, 5
500
1.2T
100, OTU4
0
2, 3, 4, 5, 6
600
1.2T
100, OTU4
0
2, 3, 4, 5, 6, 7
The following table displays the client and trunk ports that are enabled for the muxponder slice 1 configuration.
Trunk Data Rate
Card Support
Client Data Rate
Trunk Ports
Client Ports
100
1.2T, 1.2TL
100, OTU4
1
8
200
1.2T, 1.2TL
100, OTU4
1
8, 9
300
1.2T, 1.2TL
100, OTU4
1
8, 9, 10
400
1.2T, 1.2TL
100, OTU4
1
8, 9, 10, 11
500
1.2T
100, OTU4
1
8, 9, 10, 11, 12
600
1.2T
100, OTU4
1
8, 9, 10, 11, 12, 13
All configurations can be accomplished by using appropriate values for client bitrate and trunk bitrate parameters of the hw-module command.
The following table displays the trunk parameter ranges for the 1.2T card.
Trunk Payload
FEC
Min BPS
Max BPS
Min GBd
Max GBd
50G
15%
1
1.3125
24.0207911
31.5272884
50G
27%
1
1.4453125
24.0207911
34.7175497
100G
15%
1
2.625
24.0207911
63.0545768
100G
27%
1
2.890625
24.0207911
69.4350994
150G
15%
1.3203125
3.9375
24.0207911
71.6359689
150G
27%
1.453125
4.3359375
24.0207911
71.6749413
200G
15%
1.7578125
5.25
24.0207911
71.7420962
200G
27%
2
4.40625
31.51
69.43
250G
15%
2.1953125
6
26.2727403
71.8059237
250G
27%
2.4140625
6
28.9312914
71.9068991
300G
15%
2.6328125
6
31.5272884
71.8485385
300G
27%
2.8984375
6
34.7175497
71.8681352
350G
15%
3.0703125
6
36.7818364
71.8790086
350G
27%
3.3828125
6
40.503808
71.8404724
400G
15%
3.5078125
6
42.0363845
71.9018782
400G
27%
3.8671875
6
46.2900663
71.8197392
450G
15%
3.9453125
6
47.2909326
71.9196757
450G
27%
4.34375
6
52.0763245
71.9327648
500G
15%
4.3828125
6
52.5454806
71.93392
500G
27%
4.8281250
6
57.8625828
71.9068991
550G
15%
4.8203125
6
57.8000287
71.9455787
550G
27%
5.3125
6
63.6488411
71.88575
600G
15%
5.2578125
-
-
71.9552971
The following table displays the trunk parameter ranges for the 1.2TL card.
Trunk Payload
FEC
Min BPS
Max BPS
Min GBd
Max GBd
100G
15%
1
2.625
24.0207911
63.0545768
100G
27%
1
2.890625
24.0207911
69.4350994
150G
15%
1.3203125
3.9375
24.0207911
71.6359689
150G
27%
1.453125
4.3359375
24.0207911
71.6749413
200G
15%
2
4
31.5272884
63.0545768
200G
27%
2
4.40625
31.51664088
69.43509943
250G
15%
2.1953125
4.5
35.0303204
71.8059237
250G
27%
2.4140625
4.5
38.5750552
71.9068991
300G
15%
2.6328125
4.5
42.0363845
71.8485385
300G
27%
2.8984375‬
4.5
46.2900662857142
71.86813526
350G
15%
3.0703125
4.5
49.0424486
71.8790086
350G
27%
3.3828125
4.5
54.0050773
71.8404724
400G
15%
3.5078125
4.5
56.0485127
71.9018782
400G
27%
3.8671875
4.5
61.72008838
71.81973921
To configure the BPS, see Configuring the BPS.
Configuring the Card Mode
You can configure the line card in the module (muxponder) or slice configuration (muxponder slice).
To configure the card in the muxponder mode, use the following commands.
configure
hw-module location location mxponder client-rate {100GE | OTU4}
hw-module location location mxponder trunk-rate {50G | 100G150G | 200G | 250G | 300G | 350G | 400G | 450G | 500G | 550G | 600G }
commit
To configure the card in the muxponder slice mode, use the following commands.
configure
hw-module location location mxponder-slice mxponder-slice-number client-rate { 100GE|OTU4}
hw-module location location mxponder-slice trunk-rate { 100G | 200G | 300G | 400G | 500G | 600G }
commit
Examples
The following is a sample in which the card is configured in the muxponder mode with a 550G trunk payload.
RP/0/RP0/CPU0:ios#config
Tue Oct 15 01:24:56.355 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder client-rate 100GE
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder trunk-rate 550G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured in the muxponder mode with a 500G trunk payload.
RP/0/RP0/CPU0:ios#config
Sun Feb 24 14:09:33.989 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder client-rate OTU4
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder trunk-rate 500G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured in the muxponder slice 0 mode with a 500G trunk payload.
RP/0/RP0/CPU0:ios#config
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0 client-rate 100GE
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0 trunk-rate 500G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured in the muxponder slice 1 mode with a 400G trunk payload.
RP/0/RP0/CPU0:ios#config
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1 client-rate 100GE
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1 trunk-rate 400G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured with mixed client rates in the muxponder slice mode.
RP/0/RP0/CPU0:ios#configure
Mon Mar 23 06:10:22.227 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0 client-rate OTU4 trunk-rate 500G 
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1 client-rate 100GE trunk-rate 500G
RP/0/RP0/CPU0:ios(config)#commit
Verifying the Card Configuration
RP/0/RP0/CPU0:ios#show hw-module location 0/2 mxponder
Fri Mar 15 11:48:48.344 IST

Location:             0/2
Client Bitrate:       100GE
Trunk  Bitrate:       500G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
Client Port            Mapper/Trunk Port   CoherentDSP0/2/0/0  CoherentDSP0/2/0/1
                     Traffic Split Percentage

HundredGigECtrlr0/2/0/2  ODU40/2/0/0/1                100                   0
HundredGigECtrlr0/2/0/3  ODU40/2/0/0/2                100                   0
HundredGigECtrlr0/2/0/4  ODU40/2/0/0/3                100                   0
HundredGigECtrlr0/2/0/5  ODU40/2/0/0/4                100                   0
HundredGigECtrlr0/2/0/6  ODU40/2/0/0/5                100                   0
HundredGigECtrlr0/2/0/7  ODU40/2/0/1/1                  0                 100
HundredGigECtrlr0/2/0/8  ODU40/2/0/1/2                  0                 100
HundredGigECtrlr0/2/0/9  ODU40/2/0/1/3                  0                 100
HundredGigECtrlr0/2/0/10 ODU40/2/0/1/4                  0                 100
HundredGigECtrlr0/2/0/11 ODU40/2/0/1/5                  0                 100
The following is a sample ouput of the coupled mode configuration where the shared client port is highlighted.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Tue Oct 15 01:25:57.358 UTC

Location:             0/1
Client Bitrate:       100GE
Trunk  Bitrate:       550G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
Client Port           Mapper/Trunk Port    CoherentDSP0/1/0/0 CoherentDSP0/1/0/1
                   Traffic Split Percentage

HundredGigECtrlr0/1/0/2    ODU40/1/0/0/1             100                   0
HundredGigECtrlr0/1/0/3    ODU40/1/0/0/2             100                   0
HundredGigECtrlr0/1/0/4    ODU40/1/0/0/3             100                   0
HundredGigECtrlr0/1/0/5    ODU40/1/0/0/4             100                   0
HundredGigECtrlr0/1/0/6    ODU40/1/0/0/5             100                   0
HundredGigECtrlr0/1/0/7    ODU40/1/0/0/6              50                  50
HundredGigECtrlr0/1/0/8    ODU40/1/0/1/1               0                 100
HundredGigECtrlr0/1/0/9    ODU40/1/0/1/2               0                 100
HundredGigECtrlr0/1/0/10   ODU40/1/0/1/3               0                 100
HundredGigECtrlr0/1/0/11   ODU40/1/0/1/4               0                 100
HundredGigECtrlr0/1/0/12   ODU40/1/0/1/5               0                 100
The following is a sample ouput of all the muxponder slice 0 configurations.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder-slice  0
Fri Mar 15 06:04:18.348 UTC

Location:             0/1
Slice ID:             0
Client Bitrate:       100GE
Trunk  Bitrate:       500G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/1/0/0
                                Traffic Split Percentage

HundredGigECtrlr0/1/0/2         ODU40/1/0/0/1                      100
HundredGigECtrlr0/1/0/3         ODU40/1/0/0/2                      100
HundredGigECtrlr0/1/0/4         ODU40/1/0/0/3                      100
HundredGigECtrlr0/1/0/5         ODU40/1/0/0/4                      100
HundredGigECtrlr0/1/0/6         ODU40/1/0/0/5                      100
The following is a sample ouput of all the muxponder slice 1 configurations.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder-slice 1
Fri Mar 15 06:11:50.020 UTC

Location:             0/1
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    TRUE
Client Port                     Mapper/Trunk Port          CoherentDSP0/1/0/1
                                Traffic Split Percentage

HundredGigECtrlr0/1/0/8         ODU40/1/0/1/1                      100
HundredGigECtrlr0/1/0/9         ODU40/1/0/1/2                      100
HundredGigECtrlr0/1/0/10        ODU40/1/0/1/3                      100
HundredGigECtrlr0/1/0/11        ODU40/1/0/1/4                      100
The following is a sample ouput of the muxponder slice 1 configuration with client configured as OTU4.
RP/0/RP0/CPU0:ios#sh hw-module location 0/0 mxponder-slice 1                                                            
Wed Mar 11 13:59:11.073 UTC 

Location:             0/0
Slice ID:             1  
Client Bitrate:       OTU4
Trunk  Bitrate:       200G
Status:               Provisioned
Client Port                     Peer/Trunk Port            CoherentDSP0/0/0/1  
                              Traffic Split Percentage
OTU40/0/0/8                     ODU40/0/0/1/1                      100
OTU40/0/0/9                     ODU40/0/0/1/2                      100
The following is a sample to verify the mixed client rate configuration in the muxponder slice mode.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Mon Mar 23 06:20:22.227 UTC

Location:             0/1
Slice ID:             0
Client Bitrate:       OTU4
Trunk  Bitrate:       500G
Status:               Provisioned
Client Port                     Peer/Trunk Port            CoherentDSP0/1/0/0   
                                Traffic Split Percentage

OTU40/1/0/2                     ODU40/1/0/0/1                      100
OTU40/1/0/3                     ODU40/1/0/0/2                      100
OTU40/1/0/4                     ODU40/1/0/0/3                      100
OTU40/1/0/5                     ODU40/1/0/0/4                      100
OTU40/1/0/6                     ODU40/1/0/0/5                      100


Location:             0/1
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       500G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/1/0/1   
                                Traffic Split Percentage

HundredGigECtrlr0/1/0/8         ODU40/1/0/1/1                         100
HundredGigECtrlr0/1/0/9         ODU40/1/0/1/2                         100
HundredGigECtrlr0/1/0/10        ODU40/1/0/1/3                         100
HundredGigECtrlr0/1/0/11        ODU40/1/0/1/4                         100
HundredGigECtrlr0/1/0/12        ODU40/1/0/1/5                         100
Use the following command to clear alarm statistics on the optics or coherent DSP controller.
clear counters controller controllertype R/S/I/P
The following is a sample in which the alarm statistics are cleared on the coherent DSP controller.
RP/0/RP0/CPU0:ios#show controller coherentDSP 0/1/0/0
Tue Jun 11 05:15:12.540 UTC

Port                                            : CoherentDSP 0/1/0/0
Controller State                                : Up
Inherited Secondary State                       : Normal
Configured Secondary State                      : Normal
Derived State                                   : In Service
Loopback mode                                   : None
BER Thresholds                                  : SF = 1.0E-5  SD = 1.0E-7
Performance Monitoring                          : Enable

Alarm Information:
LOS = 1 LOF = 1 LOM = 0
OOF = 1 OOM = 1 AIS = 0
IAE = 0 BIAE = 0        SF_BER = 0
SD_BER = 2      BDI = 2 TIM = 0
FECMISMATCH = 0 FEC-UNC = 0
Detected Alarms                                 : None

Bit Error Rate Information
PREFEC  BER                                     : 8.8E-03
POSTFEC BER                                     : 0.0E+00

TTI :
        Remote hostname                         : P2B8
        Remote interface                        : CoherentDSP 0/1/0/0
        Remote IP addr                          : 0.0.0.0

FEC mode                                        : Soft-Decision 15

AINS Soak                                       : None
AINS Timer                                      : 0h, 0m
AINS remaining time                             : 0 seconds
RP/0/RP0/CPU0:ios#clear counters controller coherentDSP 0/1/0/0
Tue Jun 11 05:17:07.271 UTC
All counters are cleared
RP/0/RP0/CPU0:ios#show controllers coherentDSP 0/1/0/1
Tue Jun 11 05:20:55.199 UTC

Port                                            : CoherentDSP 0/1/0/1
Controller State                                : Up
Inherited Secondary State                       : Normal
Configured Secondary State                      : Normal
Derived State                                   : In Service
Loopback mode                                   : None
BER Thresholds                                  : SF = 1.0E-5  SD = 1.0E-7
Performance Monitoring                          : Enable

Alarm Information:
LOS = 0 LOF = 0 LOM = 0
OOF = 0 OOM = 0 AIS = 0
IAE = 0 BIAE = 0        SF_BER = 0
SD_BER = 0      BDI = 0 TIM = 0
FECMISMATCH = 0 FEC-UNC = 0
Detected Alarms                                 : None

Bit Error Rate Information
PREFEC  BER                                     : 1.2E-02
POSTFEC BER                                     : 0.0E+00

TTI :
        Remote hostname                         : P2B8
        Remote interface                        : CoherentDSP 0/1/0/1
        Remote IP addr                          : 0.0.0.0

FEC mode                                        : Soft-Decision 15

AINS Soak                                       : None
AINS Timer                                      : 0h, 0m
AINS remaining time                             : 0 seconds
Regeneration Mode
In an optical transmission system, 3R regeneration helps extend the reach of the optical communication links by reamplifying, reshaping, and retiming the data pulses. Regeneration helps to correct any distortion of optical signals by converting it to an electrical signal, processing that electrical signal, and then retransmitting it again as an optical signal.
In Regeneration (Regen) mode, the OTN signal is received on a trunk port and the regenerated OTN signal is sent on the other trunk port of the line card and the other way round. In this mode, only the trunk optics controller and coherentDSP controllers are created.
Configuring the Card in Regen Mode
Verifying the Regen Mode
Configuring the Card in Regen Mode
The supported trunk rates for the different cards are:
1.2T card—100G to 600G in multiples of 100G
1.2TL card—200G to 400G in multiples of 100G
2-QDD-C card—200G to 400G in multiples of 100G
To configure regen mode on 1.2T, 1.2TL, and 2-QDD-C cards, use the following commands:
configure
hw-module location location
regen
trunk-rate trunk-rate
commit
exit
Example
The following is a sample to configure the regen mode on 1.2T, 1.2TL, and 2-QDD-C line cards with the trunk-rate 300.
RP/0/RP0/CPU0:ios#configure
RP/0/RP0/CPU0:ios(config)#hw-module location 0/0 
RP/0/RP0/CPU0:ios(config-hwmod)#regen
RP/0/RP0/CPU0:ios(config-regen)#trunk-rate 300
RP/0/RP0/CPU0:ios(config-regen)#commit
RP/0/RP0/CPU0:ios(config-regen)#exit
Verifying the Regen Mode
The following is a sample to verify the regen mode.
show hw-module location location regen
RP/0/RP0/CPU0:ios#show hw-module location 0/0 regen
Mon Mar 25 09:50:42.936 UTC

Location:             0/0
Trunk  Bitrate:       400G
Status:               Provisioned
East Port              West Port
CoherentDSP0/0/0/0      CoherentDSP0/0/0/1
The terms, East Port and West Port are used to represent OTN signal regeneration at the same layer.
Configuring the BPS
You can configure the Bits per Symbol (BPS) to 3.4375 to support 300G trunk configurations on 75 GHz networks using the following commands:
configure
controller optics R/S/I/P bits-per-symbol 3.4375
commit
The following is a sample in which the BPS is configured to 3.4375.
RP/0/RP0/CPU0:ios#configure
Wed Mar 27 14:12:49.932 UTC
RP/0/RP0/CPU0:ios(config)#controller optics 0/3/0/0 bits-per-symbol 3.4375
RP/0/RP0/CPU0:ios(config)#commit
Viewing BPS and Baud Rate Ranges
To view the the BPS for a specific range use the following command:
show controller optics R/S/I/P bps-range bps-range | include data-rate | include fec-type
RP/0/RP0/CPU0:ios#show controllers optics 0/3/0/0 bps-range 3 3.05 | include 300G | include SD27
Thu Mar 28 03:01:39.751 UTC
300G            SD27            3.0000000       69.4350994
300G            SD27            3.0078125       69.2547485
300G            SD27            3.0156250       69.0753320
300G            SD27            3.0234375       68.8968428
300G            SD27            3.0312500       68.7192736
300G            SD27            3.0390625       68.5426174
300G            SD27            3.0468750       68.3668671
To view the baud for a specific range use the following command:
show controller optics R/S/I/P baud-rate-range baud-range | include data-rate | include fec-type
RP/0/RP0/CPU0:ios#show controllers optics 0/3/0/0 baud-rate-range 43 43.4 | include 300G | include SD27
Thu Mar 28 03:12:36.521 UTC
300G            SD27            4.8046875       43.3545986
300G            SD27            4.8125000       43.2842178
300G            SD27            4.8203125       43.2140651
300G            SD27            4.8281250       43.1441394
300G            SD27            4.8359375       43.0744397
300G            SD27            4.8437500       43.0049648
Configuring the Trunk Rate for BPSK
From R7.2.1 onwards, you can configure trunk rates of 50G, 100G, and 150G to support Binary Phase-Shift Keying (BPSK) modulation. The BPSK modulation enables information to be carried over radio signals more efficiently.
You can configure trunk rates for BPSK using CLI, NetConf YANG, and OC models.
The following table list the 50G, 100G, and 150G trunk rates with the supported BPSK modulation:
Trunk Rate
BPSK Modulation
50G
1 to 1.4453125
100G
1 to 2.890625
150G
1.453125 to 4.3359375
To configure the trunk rate for BPSK modulation, enter the following commands:
configure
hw-module location location mxponder
trunk-rate {50G | 100G | 150G}
commit
The following example shows how to configure trunk rate to 50G:
RP/0/RP0/CPU0:(config)#hw-module location 0/0 mxponder
RP/0/RP0/CPU0:(config-hwmod-mxp)#trunk-rate 50G 
RP/0/RP0/CPU0:(config-hwmod-mxp)#commit    
Viewing the BPSK Trunk Rate Ranges
Viewing the BPSK Trunk Rate Ranges
To view the trunk rate configured for the BPSK modulation, use the following show commands:
RP/0/RP0/CPU0:ios(hwmod-mxp)#show hw-module location 0/0 mxponder                                                                                
Tue Feb 25 11:13:41.934 UTC                                                                                                                                    

Location:             0/0
Client Bitrate:       100GE
Trunk  Bitrate:       50G  
Status:               Provisioned
LLDP Drop Enabled:    FALSE                   
ARP Snoop Enabled:    FALSE                   
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/0   CoherentDSP0/0/0/1      
                                Traffic Split Percentage                                                

HundredGigECtrlr0/0/0/2         ODU40/0/0/0                            50                       50
RP/0/RP0/CPU0:ios#show controllers optics 0/0/0/0
Thu Mar  5 07:12:55.681 UTC                          

Controller State: Up 

Transport Admin State: In Service 

Laser State: On 

LED State: Green 
                  
 Optics Status    

         Optics Type:  DWDM optics
         DWDM carrier Info: C BAND, MSA ITU Channel=61, Frequency=193.10THz,
         Wavelength=1552.524nm                                              

         Alarm Status:
         -------------
         Detected Alarms: None


         LOS/LOL/Fault Status:

         Alarm Statistics:

         -------------
         HIGH-RX-PWR = 0            LOW-RX-PWR = 2          
         HIGH-TX-PWR = 0            LOW-TX-PWR = 0          
         HIGH-LBC = 0               HIGH-DGD = 0            
         OOR-CD = 0                 OSNR = 0                
         WVL-OOL = 0                MEA  = 0                
         IMPROPER-REM = 0                                   
         TX-POWER-PROV-MISMATCH = 0                         
         Laser Bias Current = 0.0 %                         
         Actual TX Power = 1.97 dBm                         
         RX Power = 1.58 dBm                                
         RX Signal Power = 0.60 dBm                         
         Frequency Offset = 386 MHz                         

         Performance Monitoring: Enable 

         THRESHOLD VALUES
         ----------------

         Parameter                 High Alarm  Low Alarm  High Warning  Low Warning
         ------------------------  ----------  ---------  ------------  -----------
         Rx Power Threshold(dBm)          4.9      -12.0           0.0          0.0
         Tx Power Threshold(dBm)          3.5      -10.1           0.0          0.0
         LBC Threshold(mA)                N/A        N/A          0.00         0.00

         Configured Tx Power = 2.00 dBm
         Configured CD High Threshold = 180000 ps/nm
         Configured CD lower Threshold = -180000 ps/nm
         Configured OSNR lower Threshold = 0.00 dB
         Configured DGD Higher Threshold = 180.00 ps
         Baud Rate =  34.7175521851 GBd
         Bits per Symbol = 1.0000000000  bits/symbol
         Modulation Type: BPSK
         Chromatic Dispersion -9 ps/nm
         Configured CD-MIN -180000 ps/nm  CD-MAX 180000 ps/nm
         Polarization Mode Dispersion = 0.0 ps
         Second Order Polarization Mode Dispersion = 125.00 ps^2
         Optical Signal to Noise Ratio = 34.60 dB
         SNR = 20.30 dB
         Polarization Dependent Loss = 0.20 dB
         Polarization Change Rate = 0.00 rad/s
         Differential Group Delay = 2.00 ps
         Filter Roll Off Factor : 0.100
         Rx VOA Fixed Ratio : 15.00 dB
         Enhanced Colorless Mode : 0
         Enhanced SOP Tolerance Mode : 0
         NLEQ Compensation Mode : 0
         Cross Polarization Gain Mode : 0
         Cross Polarization Weight Mode : 0
         Carrier Phase Recovery Window : 0
         Carrier Phase Recovery Extended Window : 0


AINS Soak                : None
AINS Timer               : 0h, 0m
AINS remaining time      : 0 seconds
OTN-XP Card
The following section describes the supported configurations and procedures to configure the card modes on the line card.
LC Mode on OTN-XP Card
Regeneration Mode on OTN-XP Card
FC-MXP Mode on OTN-XP Card
Supported Pluggables for OTN-XP Card
Muxponder Configuration on OTN-XP Card
Configuring Inverse Muxponder on OTN-XP Card for 400GE Client
LC Mode on OTN-XP Card
When you install the OTN-XP card in the Cisco NCS 1004 chassis, it is in the POWERED_ON state. The LCMODE is not configured for line card alarm is present on the card and the LED status is AMBER.
sysadmin-vm:0_RP0# show platform
Thu Mar  26 21:38:07.305 UTC+00:00
Location  Card Type               HW State      SW State      Config State  
----------------------------------------------------------------------------
0/0       NCS1K4-LC-FILLER        PRESENT       N/A           NSHUT         
0/1       NCS1K4-OTN-XP           POWERED_ON    N/A           NSHUT         
0/RP0     NCS1K4-CNTLR-K9         OPERATIONAL   OPERATIONAL   NSHUT         
0/FT0     NCS1K4-FAN              OPERATIONAL   N/A           NSHUT         
0/FT1     NCS1K4-FAN              OPERATIONAL   N/A           NSHUT         
0/FT2     NCS1K4-FAN              OPERATIONAL   N/A           NSHUT         
0/PM0     NCS1K4-AC-PSU           OPERATIONAL   N/A           NSHUT         
0/SC0     NCS1004                 OPERATIONAL   N/A           NSHUT         
sysadmin-vm:0_RP0# show alarms brief system active 
Thu Mar  26 21:38:34.394 UTC+00:00

-------------------------------------------------------------------------------
Active Alarms
-------------------------------------------------------------------------------
Location          Severity      Group           Set time            Description
-------------------------------------------------------------------------------
0                 major         environ         03/26/20 20:23:11   Power Module redundancy lost.
0                 critical      environ         03/26/20 20:23:29   Fan: One or more LCs missing, running fans at max speed.
0/1               not_alarmed   shelf           03/26/20 21:38:26   LCMODE is not configured for line card
sysadmin-vm:0_RP0# 
sysadmin-vm:0_RP0# show led location 0/1 
Thu Mar  26 21:39:05.101 UTC+00:00
=============================================================
Location  LED Name                      Mode         Color  
=============================================================
0/1        
          0/1-Status LED                WORKING     AMBER     
sysadmin-vm:0_RP0# 
You must select a datapath mode by configuring the LC mode. OTN-XP does not have a default LC mode. After the LC mode is configured using the CLI,the card transitions to the OPERATIONAL state, the alarm clears, and the LED status turns to GREEN.
The LC modes supported on the OTN-XP card are:
10G-GREY-MXP
4x100G-MXP-400G-TXP
40x10G-4x100G-MXP
4x100GE-MXP-DD
400GE-TXP-DD
FC-MXP
OTUCn-REGEN

Note
100G-TXP LC mode is not supported.
Only one LC mode can be configured on the OTN-XP card at a time. When the LC mode is changed using the CLI, the LCMODE changed, delete the datapath config and reload line card alarm is present on the card and the DP FPD is in disabled state. To clear the alarm and enable the DP FPD, delete the the existing datapath configuration and reload the line card to apply the new LC mode to make the card operational.
If a LC mode requires a different FPGA configuration, and the package is not available, the OTN_XP_DP_FPD_PKG is missing, please install the package to proceed alarm is present on the card. To clear the alarm, install the OTN_XP_DP_FPD_PKG file. After the package installation is complete, the required FPGA image is copied from the OTN_XP_DP_FPD_PKG file to the card, the card is automatically reloaded, and the card becomes operational.

Note
The LC mode configuration is a shared plane configuration. The configuration does not enter the preconfigured state when the line card is not available.
Configuring the LC Mode
Configuring the LC Mode

Note
Ensure the OTN_XP_DP_FPD_PKG file is installed before configuring the LC mode.
When you insert an OTN-XP line card having a lower FPD version, you must configure a LC mode which is supported on the software release that the line card is loaded with. You cannot upgrade the FPD of a line card if you configure a LC mode supported only in a higher software release.
The LC_CPU_MOD_FW version on a new OTN-XP line card is 7.3.1. Support for new LC modes or features from version 7.5.1 or higher, such as OTUCn-REGEN mode in 7.5.2, is not available in this line card software. When you install an OTN-XP card for the first time in an NCS 1004 chassis with the controller card software version of 7.5.1 or higher, you must upgrade LC_CPU_MOD_FW, to ensure the availability and support for the LC modes or features that are supported supported in the XR software version. You must configure an LC mode which is supported in the 7.3.1 XR software, such as 4x100G-MXP-400G-TXP, and bring the card to OPERATIONAL state to upgrade the line card software.
To configure the LC mode on the OTN-XP card, use the following commands:
configure
lc-module location location lcmode mode
commit
Example
To view the LC modes available on the OTN-XP card, use the following command:
RP/0/RP0/CPU0:ios#sh lc-module location 0/0 lcmode all 
Wed Sep 29 14:41:51.487 UTC
States: A-Available     R-Running       C-Configured

Node    Lcmode_Supported    Owner    Options(State)                HW_Ver
--------------------------------------------------------------------------------
0/0     Yes                 None     10G-GREY-MXP (A)               3.0 
                                     4x100G-MXP-400G-TXP (A)        2.0 
From Release 7.3.2 onwards, you can view the hybrid mode options that are supported on the OTN-XP card. To view the LC modes supported on the OTN-XP card, use the following command:
RP/0/RP0/CPU0:ios#show lc-module location 0/3 lcmode all 
Wed Aug 11 17:06:29.538 UTC
States: A-Available     R-Running       C-Configured

Node    Lcmode_Supported    Owner    Options(State)                HW_Ver
--------------------------------------------------------------------------------
0/3     Yes                 CLI      10G-GREY-MXP (A)               3.0 
                                     4x100G-MXP-400G-TXP (A)        2.0 
                                     40x10G-4x100G-MXP (A)          3.0
                                     4x100GE-MXP-DD (R/C)           7.0

Note
The 100G-TXP mode is listed when using the show lc-module location lcmode all command, but the configuration on 100G-TXP mode is not supported.
The following is a sample in which the OTN-XP card is configured in the 10G-GREY-MXP mode.
RP/0/RP0/CPU0:ios#configure
Thu Mar 26 21:40:51.495 UTC
RP/0/RP0/CPU0:ios(config)#lc-module location 0/1 lcmode 10G-GREY-MXP 
RP/0/RP0/CPU0:ios(config)#commit
Verifying the LC Mode Configuration
The following is a sample output of a successful 10G-GREY-MXP LC mode configuration after which the card transitions to the OPERATIONAL state, the alarm clears, and the LED status turns to GREEN.
RP/0/RP0/CPU0:ios(config)#do show platform
Thu Mar 26 21:41:17.206 UTC
Node              Type                       State             Config state
--------------------------------------------------------------------------------
0/0               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/1               NCS1K4-OTN-XP              OPERATIONAL       NSHUT
0/RP0/CPU0        NCS1K4-CNTLR-K9(Active)    IOS XR RUN        NSHUT
0/FT0             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT1             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT2             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/PM0             NCS1K4-AC-PSU              OPERATIONAL       NSHUT
0/SC0             NCS1004                    OPERATIONAL       NSHUT
RP/0/RP0/CPU0:ios(config)#do show alarms brief system active 
Thu Mar 26 21:41:29.641 UTC

------------------------------------------------------------------------------------
Active Alarms 
------------------------------------------------------------------------------------
Location        Severity     Group            Set Time                   Description                                                                                                                                                                                                                                                
------------------------------------------------------------------------------------
0               Major        Environ          03/26/2020 20:23:11 UTC    Power Module redundancy lost.                                                                                                                                                                                                                              
0               Critical     Environ          03/26/2020 20:23:29 UTC    Fan: One or more LCs missing, running fans at max speed.                                                                                                                          
RP/0/RP0/CPU0:ios(config)#end
RP/0/RP0/CPU0:ios#show lc-module location 0/1 lcmode all 
Thu Mar 26 21:41:58.780 UTC
States: A-Available     R-Running       C-Configured

Node    Lcmode_Supported    Owner    Options(State)                HW_Ver
--------------------------------------------------------------------------------
0/1     Yes                 CLI      10G-GREY-MXP (R/C)             3.0 
                                     4x100G-MXP-400G-TXP (A)        2.0 
RP/0/RP0/CPU0:ios#show lc-module location 0/1 lcmode     
Thu Mar 26 21:42:18.997 UTC

Node    Lcmode_Supported    Owner    Running                Configured
--------------------------------------------------------------------------------
0/1     Yes                 CLI      10G-GREY-MXP          10G-GREY-MXP 
RP/0/RP0/CPU0:ios#admin
Thu Mar 26 21:42:38.525 UTC

root connected from 192.0.0.4 using ssh on sysadmin-vm:0_RP0
sysadmin-vm:0_RP0# show led location 0/1
Thu Mar  26 21:42:45.337 UTC+00:00
=============================================================
Location  LED Name                      Mode         Color  
=============================================================
0/1        
          0/1-Status LED                WORKING     GREEN     

 
Example
The following is a sample in which the LC mode is changed from 10G-GREY-MXP to the 4x100G-MXP-400G-TXP mode. In this sample, the datapath configuration is deleted and the card is reloaded to apply the new LC mode.
RP/0/RP0/CPU0:ios#show lc-module location all lcmode 
Thu Sep 30 10:19:29.853 UTC

Node    Lcmode_Supported    Owner    Running                Configured
--------------------------------------------------------------------------------
0/0     Yes                 CLI      10G-GREY-MXP           10G-GREY-MXP 
0/1     No                  N/A      N/A                    N/A
0/2     No                  N/A      N/A                    N/A
0/3     No                  N/A      N/A                    N/A
RP/0/RP0/CPU0:ios#configure 
Thu Sep 30 10:19:32.818 UTC
Current Configuration Session  Line       User     Date                     Lock
00001000-000051f7-00000000     vty1       root     Wed Sep 29 15:26:00 2021 
RP/0/RP0/CPU0:ios(config)#no lc-module location 0/0 lcmode 10g-GREY-MXP 
RP/0/RP0/CPU0:ios(config)#commit 
Thu Sep 30 10:20:34.086 UTC
RP/0/RP0/CPU0:ios(config)#do show alarms brief system active 
Thu Sep 30 10:20:52.950 UTC

------------------------------------------------------------------------------------
Active Alarms 
------------------------------------------------------------------------------------
Location        Severity     Group            Set Time                   Description                                                                                                                                                                                                                                                
------------------------------------------------------------------------------------
0/PM0           Major        Environ          09/29/2021 14:41:59 UTC    Power Module Output Disabled                                                                                                                                                                                                                               
0               Major        Environ          09/29/2021 14:42:15 UTC    Power Module redundancy lost.                                                                                                                                                                                                                              
0               Critical     Environ          09/29/2021 14:42:25 UTC    Fan: One or more LCs missing, running fans at max speed.                                                                                                                                                                                                   
0/0             NotAlarmed   Shelf            09/30/2021 10:20:34 UTC    LCMODE changed, delete the datapath config and reload line card                                                                                                                                                                                            
RP/0/RP0/CPU0:ios#configure 
Thu Sep 30 10:21:41.281 UTC
Current Configuration Session  Line       User     Date                     Lock
00001000-000051f7-00000000     vty1       root     Wed Sep 29 15:26:00 2021 
RP/0/RP0/CPU0:ios(config)#no hw-module location 0/0
RP/0/RP0/CPU0:ios(config)#commit 
Thu Sep 30 10:21:49.982 UTC
RP/0/RP0/CPU0:ios(config)#

RP/0/RP0/CPU0:ios#show platform
Thu Sep 30 10:22:08.482 UTC
Node              Type                       State             Config state
--------------------------------------------------------------------------------
0/0               NCS1K4-OTN-XP              OPERATIONAL       NSHUT
0/2               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/3               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/RP0/CPU0        NCS1K4-CNTLR-K9(Active)    IOS XR RUN        NSHUT
0/FT0             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT1             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT2             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/PM0             NCS1K4-AC-PSU              OPERATIONAL       NSHUT
0/SC0             NCS1004                    OPERATIONAL       NSHUT
RP/0/RP0/CPU0:ios#
RP/0/RP0/CPU0:ios#admin
Thu Sep 30 10:23:55.937 UTC
Last login: Thu Sep 30 04:32:57 2021 from 192.0.0.4
root connected from 192.0.0.4 using ssh on sysadmin-vm:0_RP0
sysadmin-vm:0_RP0# hw-module location 0/0 reload 
Thu Sep  30 10:24:17.938 UTC+00:00
Reloading the module will be traffic impacting if not properly drained. Continue to Reload hardware module ? [no,yes] yes
result Card graceful reload request on 0/0 succeeded.
sysadmin-vm:0_RP0#show platform 
Thu Sep  30 10:25:16.876 UTC+00:00
Location  Card Type               HW State      SW State      Config State  
----------------------------------------------------------------------------
0/0       NCS1K4-OTN-XP           POWERED_ON    N/A           NSHUT         
0/2       NCS1K4-LC-FILLER        PRESENT       N/A           NSHUT         
0/3       NCS1K4-LC-FILLER        PRESENT       N/A           NSHUT         
0/RP0     NCS1K4-CNTLR-K9         OPERATIONAL   OPERATIONAL   NSHUT         
0/FT0     NCS1K4-FAN              OPERATIONAL   N/A           NSHUT         
0/FT1     NCS1K4-FAN              OPERATIONAL   N/A           NSHUT         
0/FT2     NCS1K4-FAN              OPERATIONAL   N/A           NSHUT         
0/PM0     NCS1K4-2KW-AC           OPERATIONAL   N/A           NSHUT         
0/SC0     NCS1004-K9              OPERATIONAL   N/A           NSHUT         

sysadmin-vm:0_RP0#exit
RP/0/RP0/CPU0:ios#show lc-module location all lcmode 
Thu Sep 30 10:29:08.183 UTC

Node    Lcmode_Supported    Owner    Running                Configured
--------------------------------------------------------------------------------
0/0     Yes                 None     Not running            Not configured
0/1     No                  N/A      N/A                    N/A
0/2     No                  N/A      N/A                    N/A
0/3     No                  N/A      N/A                    N/A

RP/0/RP0/CPU0:ios#show platform
Thu Sep 30 10:29:36.075 UTC
Node              Type                       State             Config state
--------------------------------------------------------------------------------
0/0               NCS1K4-OTN-XP              POWERED_ON        NSHUT
0/2               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/3               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/RP0/CPU0        NCS1K4-CNTLR-K9(Active)    IOS XR RUN        NSHUT
0/FT0             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT1             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT2             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/PM0             NCS1K4-AC-PSU              OPERATIONAL       NSHUT
0/SC0             NCS1004                    OPERATIONAL       NSHUT
RP/0/RP0/CPU0:ios#
RP/0/RP0/CPU0:ios#configure 
Thu Sep 30 10:29:57.997 UTC
Current Configuration Session  Line       User     Date                     Lock
00001000-000051f7-00000000     vty1       root     Wed Sep 29 15:26:00 2021 
RP/0/RP0/CPU0:ios(config)#lc-module location 0/0 lcmode 4x100G-MXP-400G-TXP 
RP/0/RP0/CPU0:ios(config)#commit 
Thu Sep 30 10:30:11.312 UTC
RP/0/RP0/CPU0:ios(config)#end
RP/0/RP0/CPU0:ios#show lc-module location all lcmode 
Thu Sep 30 10:40:56.480 UTC

Node    Lcmode_Supported    Owner    Running                Configured
--------------------------------------------------------------------------------
0/0     Yes                 CLI      4x100G-MXP-400G-TXP    4x100G-MXP-400G-TXP 
0/1     No                  N/A      N/A                    N/A
0/2     No                  N/A      N/A                    N/A
0/3     No                  N/A      N/A                    N/A

RP/0/RP0/CPU0:ios# RP/0/RP0/CPU0:ios#show  platform
Thu Sep 30 10:41:25.093 UTC
Node              Type                       State             Config state
--------------------------------------------------------------------------------
0/0               NCS1K4-OTN-XP              OPERATIONAL       NSHUT
0/2               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/3               NCS1K4-LC-FILLER           PRESENT           NSHUT
0/RP0/CPU0        NCS1K4-CNTLR-K9(Active)    IOS XR RUN        NSHUT
0/FT0             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT1             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/FT2             NCS1K4-FAN                 OPERATIONAL       NSHUT
0/PM0             NCS1K4-AC-PSU              OPERATIONAL       NSHUT
0/SC0             NCS1004                    OPERATIONAL       NSHUT
RP/0/RP0/CPU0:ios#
Example: 4x100GE-MXP-DD LC Mode
To view the LC modes available on the OTN-XP card, use the following command: The following is a sample in which the OTN-XP card is configured in the 4x100GE-MXP-DD mode.
RP/0/RP0/CPU0:ios#show lc-module location all lcmode all 
Thu Sep 30 10:43:47.536 UTC
States: A-Available     R-Running       C-Configured

Node    Lcmode_Supported    Owner    Options(State)                HW_Ver
--------------------------------------------------------------------------------
0/0     Yes                 CLI      100G-TXP (A)                   3.0 
                                     10G-GREY-MXP (A)               3.0 
                                     4x100G-MXP-400G-TXP (A)        2.0 
                                     40x10G-4x100G-MXP (A)          3.0 
                                     4x100GE-MXP-DD (R/C)           7.0 
                                     400GE-TXP-DD (A)               1.0 
                                     FC-MXP (A)                     4.0 
                                     OTUCn-REGEN (A)                8.0 
                                      
0/1     No                  N/A      N/A                            N/A
0/2     No                  N/A      N/A                            N/A
0/3     No                  N/A      N/A                            N/A
Example: OTUCn-REGEN Mode
The following is a sample to configure the OTUCn-REGEN mode:
RP/0/RP0/CPU0:ios#configure 
Fri Feb  4 16:52:18.021 UTC
RP/0/RP0/CPU0:ios(config)#lc-module location 0/2 lcmode OTUCn-REGEN
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample to verify the OTUCn-REGEN LC mode.
RP/0/RP0/CPU0:ios#sh lc-module location 0/2 lcmode    
Fri Feb  4 17:00:09.842 UTC

Node    Lcmode_Supported    Owner      Running          Configured
------------------------------------------------------------------------------------------------
0/2       Yes                CLI       OTUCn-REGEN       OTUCn-REGEN 
Example: FC-MXP Mode
The following is a sample to configure the OTN-XP card in FC-MXP mode:
RP/0/RP0/CPU0:ios#configure 
Fri Feb  5 15:53:17.023 UTC
RP/0/RP0/CPU0:ios(config)#lc-module location 0/2 lcmode FC-MXP
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample to verify the FC-MXP mode configured on the OTN-XP card:
RP/0/RP0/CPU0:ios#show lc-module location 0/2 lcmode
Fri Feb  4 16:13:32.745 UTC

Node    Lcmode_Supported    Owner    Running     Configured
------------------------------------------------------------------------------------------
0/2          Yes             CLI     FC-MXP       FC-MXP 

RP/0/RP0/CPU0:ios#
Regeneration Mode on OTN-XP Card
Table 2. Feature History Table
Feature
Release Information
Description
Regeneration Mode Support on the OTN-XP Card
Cisco IOS XR Release 7.5.2
The OTN-XP card now supports the OTUCn-REGEN LC mode for regeneration. This mode allows regeneration of the DWDM channels across trunk ports of the OTN-XP card and significantly extends the reach of the service. You can configure 200G and 400G trunk rates on the card.
The OTN-XP card supports the OTUCn-REGEN mode as a part of the LC mode for regeneration.
The OTUCn-REGEN mode supports the following features:
Trunk rate―400G and 200G
Modulation type:
16-QAM for 400G
8-QAM, 16-QAM, and QPSK for 200G
Trunk optics―ONS-CFP2D-400G-C
Supported features―Loopbacks, TTI, AINS
Limitations
GCC0 is not supported on the REGEN trunks.
Configuring Regen Mode on OTN-XP Card
Configuring Regen Mode on OTN-XP Card

Note
You must configure the OTUCn-REGEN LC mode on the OTN-XP card before performing this configuration. See Example: OTUCn-REGEN Mode.
The following is a sample for configuring regen mode with 400G trunk rate:
RP/0/RP0/CPU0:ios#configure 
Fri Feb  4 16:53:48.018 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 regen 
RP/0/RP0/CPU0:ios(config-regen)#trunk-rate 400G 
RP/0/RP0/CPU0:ios(config-regen)#commit
Fri Feb  4 16:54:05.920 UTC
The following is a sample to verify the 400G trunk rate configured in the regen mode.
RP/0/RP0/CPU0:ios#show hw-module location 0/2 regen 
Fri Feb  4 16:58:51.716 UTC

Location:             0/2
Trunk  Bitrate:       400G
Status:               Provisioned
East Port                   West Port
---------                   ---------
CoherentDSP0/2/0/12         CoherentDSP0/2/0/13
The following is a sample for configuring regen mode with 200G trunk rate:
RP/0/RP0/CPU0:ios#configure 
Fri Feb  4 16:53:48.018 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 regen 
RP/0/RP0/CPU0:ios(config-regen)#trunk-rate 200G 
RP/0/RP0/CPU0:ios(config-regen)#commit
Fri Feb  4 16:54:05.920 UTC
If you want to change the modulation format for the 200G trunk rate, see Configuring 8QAM Modulation for 200G Muxponder Mode.
The following is a sample to verify the 200G trunk rate configured in the regen mode.
RP/0/RP0/CPU0:ios#show hw-module location 0/2 regen 
Fri Feb  4 16:58:51.716 UTC

Location:             0/2
Trunk  Bitrate:       200G
Status:               Provisioned
East Port                   West Port
---------                   ---------
CoherentDSP0/2/0/12         CoherentDSP0/2/0/13
FC-MXP Mode on OTN-XP Card
Table 3. Feature History Table
Feature
Release Information
Description
FC-MXP Mode Support on the OTN-XP Card
Cisco IOS XR Release 7.5.2
The OTN-XP card now supports FC-MXP LC mode for Fiber Channel (FC) support. You can configure 16G FC with 400G trunk rate.
Table 4. Feature History Table
Feature
Release Information
Description
32G FC-MXP Mode Support on the OTN-XP Card
Cisco IOS XR Release 7.7.1
The OTN-XP card now supports 32G FC-MXP LC mode for Fiber Channel (FC) support, in addition to the 16G FC-MXP mode that was supported already. You can configure 32G FC with 400G trunk rate on slice 0.
From Release 7.5.2 onwards, the OTN-XP card supports FC-MXP LC mode for Fiber Channel (FC) support. You can configure 16G FC with 400G trunk rate on both the slices.
From Release 7.7.1, 32GFC can be configured on slice 0.
FC Mode
Supported Slices
Slice 0 Ports
Slice 1 Ports
Client Payloads
Trunk Rate
Client Optics
Trunk Optics
Modulation Type
16G FC-MXP
Slice 0 and Slice 1
Clients: 1, 6, 7, 9, 10, 11 and Trunk: 12
Clients: 0, 2, 3, 4, 5, 8 and Trunk: 13
16G FC
400G (OTUC4) on both the slices
ONS-QC-16GFC-SW
ONS-CFP2D-400G-C
DP04CFP2-M25-K9
16-QAM
32G FC-MXP
Slice 0
Clients: 9, 10, 11 and Trunk: 12
NA
32G FC
400G (OTUC4) on slice 0
DS-SFP-4X32G-SW
ONS-CFP2D-400G-C
DP04CFP2-M25-K9
16-QAM
The FC-MXP mode supports the following features:
Loopback
PRBS
AINS
Laser squelch
The FC-MXP mode supports the following alarms:
SIGLOSS―Signal Loss
SYNCLOSS―Loss of Synchronization
NOS―Not-Operational Primitive Sequence
Limitations:
The combination of 16G FC and 32G FC configurations is not supported on the same slice.
GCC0 and GCC1 are not supported.
Local Fault and Remote Fault Ethernet alarms are not supported.
FC32 only supports SIGLOSS alarm.
FC32 does not support statistics counters.
Configuring the OTN-XP Card in 16G FC Muxponder Mode
Configuring the OTN-XP Card in 32G FC Muxponder Mode
Configuring the OTN-XP Card in 16G FC Muxponder Mode

Note
You must configure the FC-MXP LC mode on the OTN-XP card before performing this configuration. See Example: FC-MXP Mode.
To configure the OTN-XP card in 16G FC-MXP mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number lane lane-number client-type fc16
commit
Example:
The following is a sample to configure 16G FC muxponder mode on slice 0 of the OTN-XP card:
RP/0/RP0/CPU0:ios#configure 
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Fri Feb  4 16:06:59.967 UTC
RP/0/RP0/CPU0:ios(config-hwmod-mxp)# 
The following is a sample to verify the 16G FC muxponder mode configured on slice 0 of the OTN-XP card:
RP/0/RP0/CPU0:ios#show hw-module location 0/2 mxponder-slice 0
Fri Feb  4 16:15:10.984 UTC

Location:             0/2
Slice ID:             0
Client Bitrate:       FC16G
Trunk  Bitrate:       400G
Status:               Provisioned
Client Port                     Mapper/Trunk Port          CoherentDSP0/2/0/12  
                                Traffic Split Percentage

SixteenGigFibreChanCtrlr0/2/0/1/1       ODU-FLEX0/2/0/12/1/1                          100
SixteenGigFibreChanCtrlr0/2/0/1/2       ODU-FLEX0/2/0/12/1/2                          100
SixteenGigFibreChanCtrlr0/2/0/1/3       ODU-FLEX0/2/0/12/1/3                          100
SixteenGigFibreChanCtrlr0/2/0/1/4       ODU-FLEX0/2/0/12/1/4                          100
SixteenGigFibreChanCtrlr0/2/0/6/1       ODU-FLEX0/2/0/12/6/1                          100
SixteenGigFibreChanCtrlr0/2/0/6/2       ODU-FLEX0/2/0/12/6/2                          100
SixteenGigFibreChanCtrlr0/2/0/6/3       ODU-FLEX0/2/0/12/6/3                          100
SixteenGigFibreChanCtrlr0/2/0/6/4       ODU-FLEX0/2/0/12/6/4                          100
SixteenGigFibreChanCtrlr0/2/0/7/1       ODU-FLEX0/2/0/12/7/1                          100
SixteenGigFibreChanCtrlr0/2/0/7/2       ODU-FLEX0/2/0/12/7/2                          100
SixteenGigFibreChanCtrlr0/2/0/7/3       ODU-FLEX0/2/0/12/7/3                          100
SixteenGigFibreChanCtrlr0/2/0/7/4       ODU-FLEX0/2/0/12/7/4                          100
SixteenGigFibreChanCtrlr0/2/0/9/1       ODU-FLEX0/2/0/12/9/1                          100
SixteenGigFibreChanCtrlr0/2/0/9/2       ODU-FLEX0/2/0/12/9/2                          100
SixteenGigFibreChanCtrlr0/2/0/9/3       ODU-FLEX0/2/0/12/9/3                          100
SixteenGigFibreChanCtrlr0/2/0/9/4       ODU-FLEX0/2/0/12/9/4                          100
SixteenGigFibreChanCtrlr0/2/0/10/1      ODU-FLEX0/2/0/12/10/1                         100
SixteenGigFibreChanCtrlr0/2/0/10/2      ODU-FLEX0/2/0/12/10/2                         100
SixteenGigFibreChanCtrlr0/2/0/10/3      ODU-FLEX0/2/0/12/10/3                         100
SixteenGigFibreChanCtrlr0/2/0/10/4      ODU-FLEX0/2/0/12/10/4                         100
SixteenGigFibreChanCtrlr0/2/0/11/1      ODU-FLEX0/2/0/12/11/1                         100
SixteenGigFibreChanCtrlr0/2/0/11/2      ODU-FLEX0/2/0/12/11/2                         100
SixteenGigFibreChanCtrlr0/2/0/11/3      ODU-FLEX0/2/0/12/11/3                         100
SixteenGigFibreChanCtrlr0/2/0/11/4      ODU-FLEX0/2/0/12/11/4                         100

RP/0/RP0/CPU0:ios#
The following is a sample to configure 16G FC muxponder mode on slice 1 of the OTN-XP card:
RP/0/RP0/CPU0:ios#configure 
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 lane 1 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 lane 2 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 lane 3 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 lane 4 client-type fc16 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Fri Feb  4 16:06:59.967 UTC
RP/0/RP0/CPU0:ios(config-hwmod-mxp)# 
The following is a sample to verify the 16G FC muxponder mode configured on slice 1 of the OTN-XP card:
RP/0/RP0/CPU0:ios#show hw-module location 0/2 mxponder-slice 1
Fri Feb  4 16:15:10.984 UTC

Location:             0/2
Slice ID:             1
Client Bitrate:       FC16G
Trunk  Bitrate:       400G
Status:               Provisioned
Client Port                     Mapper/Trunk Port          CoherentDSP0/2/0/13  
                                Traffic Split Percentage

SixteenGigFibreChanCtrlr0/2/0/0/1       ODU-FLEX0/2/0/13/0/1                          100
SixteenGigFibreChanCtrlr0/2/0/0/2       ODU-FLEX0/2/0/13/0/2                          100
SixteenGigFibreChanCtrlr0/2/0/0/3       ODU-FLEX0/2/0/13/0/3                          100
SixteenGigFibreChanCtrlr0/2/0/0/4       ODU-FLEX0/2/0/13/0/4                          100
SixteenGigFibreChanCtrlr0/2/0/2/1       ODU-FLEX0/2/0/13/2/1                          100
SixteenGigFibreChanCtrlr0/2/0/2/2       ODU-FLEX0/2/0/13/2/2                          100
SixteenGigFibreChanCtrlr0/2/0/2/3       ODU-FLEX0/2/0/13/2/3                          100
SixteenGigFibreChanCtrlr0/2/0/2/4       ODU-FLEX0/2/0/13/2/4                          100
SixteenGigFibreChanCtrlr0/2/0/3/1       ODU-FLEX0/2/0/13/3/1                          100
SixteenGigFibreChanCtrlr0/2/0/3/2       ODU-FLEX0/2/0/13/3/2                          100
SixteenGigFibreChanCtrlr0/2/0/3/3       ODU-FLEX0/2/0/13/3/3                          100
SixteenGigFibreChanCtrlr0/2/0/3/4       ODU-FLEX0/2/0/13/3/4                          100
SixteenGigFibreChanCtrlr0/2/0/4/1       ODU-FLEX0/2/0/13/4/1                          100
SixteenGigFibreChanCtrlr0/2/0/4/2       ODU-FLEX0/2/0/13/4/2                          100
SixteenGigFibreChanCtrlr0/2/0/4/3       ODU-FLEX0/2/0/13/4/3                          100
SixteenGigFibreChanCtrlr0/2/0/4/4       ODU-FLEX0/2/0/13/4/4                          100
SixteenGigFibreChanCtrlr0/2/0/5/1       ODU-FLEX0/2/0/13/5/1                         100
SixteenGigFibreChanCtrlr0/2/0/5/2       ODU-FLEX0/2/0/13/5/2                         100
SixteenGigFibreChanCtrlr0/2/0/5/3       ODU-FLEX0/2/0/13/5/3                         100
SixteenGigFibreChanCtrlr0/2/0/5/4       ODU-FLEX0/2/0/13/5/4                         100
SixteenGigFibreChanCtrlr0/2/0/8/1       ODU-FLEX0/2/0/13/8/1                         100
SixteenGigFibreChanCtrlr0/2/0/8/2       ODU-FLEX0/2/0/13/8/2                         100
SixteenGigFibreChanCtrlr0/2/0/8/3       ODU-FLEX0/2/0/13/8/3                         100
SixteenGigFibreChanCtrlr0/2/0/8/4       ODU-FLEX0/2/0/13/8/4                         100

RP/0/RP0/CPU0:ios#
Configuring the OTN-XP Card in 32G FC Muxponder Mode

Note
You must configure the FC-MXP LC mode on the OTN-XP card before performing this configuration. See Example: FC-MXP Mode.

Note
The Production Software Maintenance Updates (SMU) for the Cisco IOS-XR Release 7.7.1 (ncs1004-sysadmin-7.7.1.CSCwb01852.tar) is mandatory to configure the latest port configurations for the 32G FC muxponder mode.
To configure the OTN-XP card in 32G FC-MXP mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number lane lane-number client-type fc32
commit
Example:
The following is a sample to configure 32G FC muxponder mode on slice 0 of the OTN-XP card:
RP/0/RP0/CPU0:ios#configure 
Fri Feb  4 16:24:53.964 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 1 client-type fc32  
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 2 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 3 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 4 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 1 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 2 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 3 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 lane 4 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 1 client-type fc32 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 2 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 3 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 4 client-type fc32
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Fri Feb  4 16:26:46.550 UTC
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#
The following is a sample to verify the 32G FC muxponder mode configured on slice 0 of the OTN-XP card:
RP/0/RP0/CPU0:ios#show hw-module location 0/2 mxponder-slice 0
Fri Feb  4 16:31:37.494 UTC

Location:             0/2
Slice ID:             0
Client Bitrate:       FC32G
Trunk  Bitrate:       400G
Status:               Provisioned
Client Port                     Mapper/Trunk Port          CoherentDSP0/2/0/12  
                                Traffic Split Percentage

ThirtyTwoGigFibreChanCtrlr0/2/0/9/1     ODU-FLEX0/2/0/12/9/1                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/9/2     ODU-FLEX0/2/0/12/9/2                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/9/3     ODU-FLEX0/2/0/12/9/3                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/9/4     ODU-FLEX0/2/0/12/9/4                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/10/1     ODU-FLEX0/2/0/12/10/1                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/10/2     ODU-FLEX0/2/0/12/10/2                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/10/3     ODU-FLEX0/2/0/12/10/3                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/10/4     ODU-FLEX0/2/0/12/10/4                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/11/1     ODU-FLEX0/2/0/12/11/1                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/11/2     ODU-FLEX0/2/0/12/11/2                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/11/3     ODU-FLEX0/2/0/12/11/3                          100
ThirtyTwoGigFibreChanCtrlr0/2/0/11/4     ODU-FLEX0/2/0/12/11/4                          100

RP/0/RP0/CPU0:ios#
Supported Pluggables for OTN-XP Card
Table 5. Feature History
Feature Name
Release Information
Description
FC Mode Support on DP04CFP2-M25-K9 Pluggable
Cisco IOS XR Release 7.7.1
The 16G FC and 32G FC muxponder modes support is added to the trunk pluggable DP04CFP2-M25-K9 on the OTN-XP card. This is in addition to the 4x100 muxponder and 400G-TXP modes that were supported previously.
The OTN-XP card supports the following trunk and client pluggables:
Client Pluggables
Trunk Pluggables
ONS-CFP2D-400G-C
QDD-400G-ZRP-S
DP04CFP2-M25-K9

Note
Starting from the Release 7.5.2, DP04CFP2-M25-K9 supports 4x100 muxponder and 400G-TXP modes.
Starting from the Release 7.7.1, DP04CFP2-M25-K9 supports 16G FC and 32G FC muxponder modes.
Client Pluggables
QSFP-100G-LR4
QSFP-100G-FR-S
QSFP-100G-SR4-S
QSFP-100G-CWDM4-S
QSFP-100G-LR4-S
QSFP-100G-AOC
QSFP-100G-PSM4
QSFP-100G-DR-S
QSFP-4x10-MLR
QSFP-40G-SR4=
QDD-400G-FR4-S
QDD-400G-DR4-S
QDD-400G-LR8-S
ONS-QC-16GFC-SW
DS-SFP-4X32G-SW
QSFP-100G-LR-S
ONS-QSFP28-LR4
Muxponder Configuration on OTN-XP Card
The OTN-XP card has two trunk ports and 12 client ports. The muxponder configuration supports two slices, 0 and 1. You can configure mxponder-slice 0, mxponder-slice 1, or both. Each mxponder-slice supports 10 client interfaces.
From Release 7.3.1 onwards, the OTN-XP card supports two trunk ports for CFP2 DCO on port 12 and port 13, and 8 client ports. For configuration, see Configuring the Muxponder Mode for 4x100G MXP.
From Release 7.3.2 onwards, the OTN-XP card supports two trunk ports for QDD ZRP on port 9 and port 11, and 8 client ports. For configuration, see Configuring the Muxponder Mode for 4x100GE-MXP-DD.
From Release 7.5.1 onwards, the OTN-XP card supports two trunk ports for QDD ZRP on port 9 and port 11, and the supported operating modes are 400G-TXP-DD, 3X100GE MXP, and 2X100GE MXP. For configuration, see Configuring the Transponder Mode for 400GE-TXP-DD. The client rates 2x100GE and 3x100G are supported as part of the 4x100GE-MXP-DD mode. For configurations, see Configuring the Muxponder Mode for 2x100GE-MXP-DD and Configuring the Muxponder Mode for 3x100GE-MXP-DD.
Table 6. Feature History
Feature Name
Release Information
Description
400 TXP or MXP modes with CFP2 DCO for OTN-XP Card
Cisco IOS XR Release 7.3.1
On the OTN-XP card, you can configure a single 400GE or 4x100G payload that is received over the client port as a 400G signal over DWDM on the line side.
The card improves efficiency, performance, and flexibility for customer networks allowing 400GE or 4x100G client transport over 400G WDM wavelength.
Commands modified:
controller coherentDSP
show controller coherentDSP
Table 7. Hardware Module Configuration with Client to Trunk Mapping
Hardware Module Configuration
Line Card Mode
Client Port Rate
Client to Trunk Mapping
Trunk Rate
10G Grey Muxponder
10G-GREY-MXP
OTU2, OTU2e, or 10 GE
Mxponder-slice 0—Client ports 4, 5, and 2 are mapped to the trunk port 0.
Mxponder-slice 1—Client ports 7, 6, and 11 are mapped to the trunk port 1.
Each client port consists of four lanes, 1, 2, 3, and 4. The lanes 3 and 4 can only be configured for ports 2 and 11. It is not mandatory to configure all 10 client lanes for a slice.
100G
400G-MXP
4x100G-MXP -400G-TXP
100GE, OTU4
Mxponder-slice 0—Client ports 1, 6, 7, and 10 are mapped to the trunk port 12.
Mxponder-slice 1—Client ports 0, 4, 5, and 8 are mapped to the trunk port 13.
400G
400G-TXP
4x100G-MXP -400G-TXP
400GE
Mxponder-slice 0—Client port 10 is mapped to the trunk port 12.
Mxponder-slice 1—Client port 8 is mapped to the trunk port 13.
400G
40x10G
40x10G-4x100G-MXP
OTU2, OTU2e, or 10 GE
Mxponder-slice 0—10G Client ports 0, 1, 2, 3, 4, 5, 6, 7, 9, and 11 mapped to the trunk port 12.
Each client port consists of four lanes, 1, 2, 3, and 4.
400G CFP2
30x10G
40x10G-4x100G-MXP
OTU2, OTU2e, or 10 GE
Mxponder-slice 0—10G Client ports 0, 1, 2, 3, 4, 5, 9, and 11 are mapped to the trunk port 12.
The client ports 0, 1, 2, 3, 4, 5, and 9 are configured for all four lanes, 1, 2, 3, and 4.
The client port 11 is configured for lanes 1 and 2.
300G CFP2
20x10G + 2x100G
40x10G-4x100G-MXP
10 GE, 100 GE, OTU2, OTU2e, or OTU4
Mxponder-slice 0—The following 100G and 10G client ports are mapped to trunk port 12.
100G client port—0 and 1
10G client port—4, 5, 6, and 7 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—11 and 2 are configured for lanes 3 and 4.
300G CFP2
10x10G + 3 x 100G
40x10G-4x100G-MXP
10GE, 100GE, OTU4, OTU2, or OTU2e
Mxponder-slice 0—The following 100G and 10G client ports are mapped to a trunk port 12.
100G client port—0, 1, and 6
10G client port—4 and 5 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—2 are configured for lanes 3 and 4.
400G CFP2
20x10G + 1 x 100G
40x10G-4x100G-MXP
10 GE, 100 GE, OTU2, OTU2e, or OTU4
Mxponder-slice 0—The following 100G and 10G client ports are mapped to trunk port 12.
100G client port—0
10G client port—1, 4,5 and 9 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—2 is configured for lanes 3 and 4 and 11 is configured for lanes 1 and 2.
300G CFP2
30x10G + 1 x 100G
40x10G-4x100G-MXP
10 GE, 100 GE, OTU2, OTU2e, or OTU4
Mxponder-slice 0—The following 100G and 10G client ports are mapped to trunk port 12.
100G client port—6
10G client port—0, 1, 2, 3, 4, 5, and 9 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—11 is configured for lanes 1 and 2.
400G CFP2
10x10G + 2 x 100G
40x10G-4x100G-MXP
10 GE, 100 GE, OTU2, OTU2e, or OTU4
Mxponder-slice 0—The following 100G and 10G client ports are mapped to trunk port 12.
100G client port—0 and 1
10G client port—4, and 5 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—2 is configured for lanes 3 and 4.
300G CFP2
10x10G + 1 x 100G
40x10G-4x100G-MXP
10 GE and 100 GE
Mxponder-slice 0—The following 100G and 10G client ports are mapped to trunk port 12.
100G client port—0
10G client port—4, and 5 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—2 is configured for lanes 3 and 4.
Mxponder-slice 1—The following 100G and 10G client ports are mapped to trunk port 13.
100G client port—1
10G client port—6, and 7 are configured for all four lanes, 1, 2, 3, and 4.
10G client port—11 is configured for lanes 3 and 4.
200G CFP2
200G Muxponder
200G-FOIC2-oFEC-QPSK-1-S
200G-FOIC2-oFEC-8QAM-1-E
OTU4, 100GE
Mxponder-slice 0—Client ports 7 and 10 mapped to the trunk port 12.
Mxponder-slice1—Client ports 5 and 8 mapped to the trunk port 13.
200G CFP2
QDD ZRP
4x100GE-MXP-DD
100GE
Mxponder-slice 0—Client ports 1, 6, 7, and 10 are mapped to the trunk port 11.
Mxponder-slice 1—Client ports 0, 4, 5, and 8 are mapped to the trunk port 9.
400G
QDD ZRP
400GE-TXP-DD
400GE
Mxponder-slice 0—Client port 10 is mapped to the trunk port 11.
Mxponder-slice 1—Client port 8 is mapped to the trunk port 9.
400G
4x100GE-MXP-DD
100GE
Mxponder-slice 0—Client ports 1, 7, and 10 are mapped to the trunk port 11.
Mxponder-slice 1—Client ports 4, 5, and 8 are mapped to the trunk port 9.
300G
4x100GE-MXP-DD
100GE
Mxponder-slice 0—Client ports 7, and 10 are mapped to the trunk port 11.
Mxponder-slice 1—Client ports 4 and 5 are mapped to the trunk port 9.
200G
QDD ZRP Limitations
Hold of timer and Idle insertion are not supported on 400GE Client for 400G-TXP mode.
Local Fault and Remote Fault ethernet alarms are not supported on 400GE Client for 400G-TXP mode.
Far-end PM counters on Coherent DSP controllers are not supported for 400G-TXP and 4x100G MXP modes.
QDD ZRP alarms appear with Flexo label due to absence of a separate ZRP layer.
Configuring the Muxponder Mode for 10G Grey Muxponder
Configuring DAC Rate for 400G Muxponder Modes
Configuring the Muxponder Mode for 4x100G MXP
Configuring the Muxponder Mode for 400G TXP
Static TPN and TS Allocation for TXP-MXP-Grey Muxponder Modes
Configuring the Muxponder Mode for 40x10G Muxponder
Configuring the Muxponder Mode for 30x10G
Configuring Hybrid Modes Using 40x10G-4x100G-MXP
Configuring the Muxponder Mode for 200G on OTN-XP Card
Configuring the Muxponder Mode for 300G on OTN-XP Card
Configuring the Muxponder Mode for 4x100GE-MXP-DD
Configuring the Muxponder Mode for 2x100GE-MXP-DD
Configuring the Muxponder Mode for 3x100GE-MXP-DD
Configuring the Transponder Mode for 400GE-TXP-DD
Configuring the Muxponder Mode for 10G Grey Muxponder

Note
The LC mode must be configured to 10G-GREY-MXP on the OTN-XP card before you perform this configuration.
To configure the OTN-XP card in the muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 100G
client-port-rate client-port-number lane lane-number client-type { 10GE | OTU2 | OTU2e}
commit
Example
The following is a sample in which the OTN-XP card is configured with mixed client rates in the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 100G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Tue Apr 21 09:26:12.308 UTC

Location:             0/1
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       100G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port   Mapper/Trunk Port    Peer/Trunk Port    OTU40/0/0/0
              Traffic Split Percentage
OTU20/0/0/2/3            NONE          ODU20/0/0/0/2/3       100
OTU20/0/0/2/4            NONE          ODU20/0/0/0/2/4       100
TenGigECtrlr0/0/0/4/1 ODU2E0/0/0/0/4/1       NONE            100
             
Configuring DAC Rate for 400G Muxponder Modes
Table 8. Feature History
Feature Name
Release
Description
DAC Configuration Support for 400GE, 4x100G, or 400G Regen modes
Cisco IOS XR Release 7.5.2
On the OTN-XP card, you can configure the Digital-to-Analog (DAC) rate for the 400GE, 4x100G, or 400G Regen modes with CFP2 DCO pluggable. Based on the DAC rate configured, pulse shaping and modem setting is set on the CFP2 DCO trunk pluggable.
From Release 7.5.2 onwards, you can configure DAC rate to set the bookended mode for the 400GE, 4x100G, or 400G Regen modes on the OTN-XP card.
DAC Supported Modes
The following operating modes are supported on the CFP2 coherent pluggable module for the OTN-XP card:
Table 9. DAC Supported Modes
Network Configuration Mode
Trunk Rate
Data Path
Line Framing
FEC Type
Modulation Format
BPS
Baud Rate (GBd)
Pulse Shaping
Mode Type
400G
400G
400G TXP, 4x100G MXP, 400G Regen
FlexO-4
oFEC
16 QAM
4
63.1
1
Enhanced
The following table provides the pulse shaping and modem setting values for the respective DAC rates.

Note
The default pulse shaping is 1.5 and mode type is Standard for the supported modes.
Table 10. DAC Rate
DAC Rate
Pulse Shape
Modem Setting
1
0
Standard
1.25
1
Enhanced
1.5
1
Standard
2
0
Enhanced
To configure the DAC rate for OTN-XP card in the 400G TXP, 4x100G MXP, and 400G Regen modes, use the following commands:
configure
controller optics Rack/Slot/Instance/Port dac-rate 1x1.25
commit
The following is a sample in which DAC rate is configured.
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#controller optics 0/0/0/12 dac-Rate 1x1.25
RP/0/RP0/CPU0:ios(config-Optics)#commit
Verifying the DAC Rate Configuration
The following is a sample to verify the DAC rate configuration for the 400G TXP, 4x100G MXP, and 400G Regen modes in the OTN-XP card.
RP/0/RP0/CPU0:ios#show controllers optics 0/2/0/12
Wed Apr 13 15:00:10.044 UTC

Controller State: Up

Transport Admin State: In Service

Laser State: On

LED State: Red

DAC RATE: 1x1.25

Configured DAC RATE: 1x1.25
Configuring the Muxponder Mode for 4x100G MXP

Note
The LC mode must be configured to 4x100G-MXP-400G-TXP on the OTN-XP card before you perform this configuration. See Configuring the LC Mode.
To configure the OTN-XP card in the 4x100 muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type {100GE | OTU4}
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type OTU4
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Mon Nov 30 01:32:57.338 UTC

Location: 0/1
Slice ID: 0
Client Bitrate: 100GE
Trunk Bitrate: 400G
Status: Provisioned
LLDP Drop Enabled: FALSE
ARP Snoop Enabled: FALSE
Client Port Mapper/Trunk Port CoherentDSP0/1/0/12
Traffic Split Percentage

HundredGigECtrlr0/1/0/1 ODU40/1/0/12/1 100


Location: 0/1
Slice ID: 1
Client Bitrate: OTU4
Trunk Bitrate: 400G
Status: Provisioned
Client Port Peer/Trunk Port CoherentDSP0/1/0/13
Traffic Split Percentage

OTU40/1/0/8 ODUC40/1/0/13 100
Configuring the Muxponder Mode for 400G TXP

Note
The LC mode must be configured to 4x100G-MXP-400G-TXP on the OTN-XP card before you perform this configuration.
To configure the OTN-XP card in the 400G TXP mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type 400GE
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 client-type 400GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type 400GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Mon Nov 30 01:36:14.514 UTC

Location: 0/1
Slice ID: 0
Client Bitrate: 400GE
Trunk Bitrate: 400G
Status: Provisioned
LLDP Drop Enabled: FALSE
ARP Snoop Enabled: FALSE
Client Port Mapper/Trunk Port CoherentDSP0/1/0/12
Traffic Split Percentage

FourHundredGigECtrlr0/1/0/10 ODU-FLEX0/1/0/12/10 100


Location: 0/1
Slice ID: 1
Client Bitrate: 400GE
Trunk Bitrate: 400G
Status: Provisioned
LLDP Drop Enabled: FALSE
ARP Snoop Enabled: FALSE
Client Port Mapper/Trunk Port CoherentDSP0/1/0/13
Traffic Split Percentage

FourHundredGigECtrlr0/1/0/8 ODU-FLEX0/1/0/13/8 100
Static TPN and TS Allocation for TXP-MXP-Grey Muxponder Modes
The OTN-XP card uses the following mapping of tributary port numbers, tributary slots, and clients for the various TXP and MXP configurations.
Table 11. TPN-TS Mapping in 400GE TXP Configuration
Slice
Client Port
Client Rate
Trunk Port
Trunk Rate
TPN
TS
0
10
400GE
12
400G
1
1.1 to 4.20
1
8
400GE
13
400G
1
1.1 to 4.20
Table 12. TPN-TS Mapping in 4 X 100G MXP Configuration
Slice
Client Port
Client Rate
Trunk Port
Trunk Rate
TPN
TS
0
10
100GE/OTU4
12
400G
1
1.1 to 1.20
7
100GE/OTU4
2
2.1 to 2.20
6
100GE/OTU4
3
3.1 to 3.20
1
100GE/OTU4
4
4.1 to 4.20
1
8
100GE/OTU4
13
400G
1
1.1 to 1.20
5
100GE/OTU4
2
2.1 to 2.20
4
100GE/OTU4
3
3.1 to 3.20
0
100GE/OTU4
4
4.1 to 4.20
Table 13. TPN-TS Mapping in 10 X 10G Grey Muxponder Configuration
Slice
Client Port
Client Lane
Client Rate
Trunk Port
Trunk Rate
TPN
TS
0
4
1
10GE/OTU2/OTU2e
0
100G
1
1–8
2
10GE/OTU2/OTU2e
2
9–16
3
10GE/OTU2/OTU2e
3
17–24
4
10GE/OTU2/OTU2e
4
25–32
5
1
10GE/OTU2/OTU2e
5
33–40
2
10GE/OTU2/OTU2e
6
41–48
3
10GE/OTU2/OTU2e
7
49–56
4
10GE/OTU2/OTU2e
8
57–64
2
3
10GE/OTU2/OTU2e
9
65–72
4
10GE/OTU2/OTU2e
10
73–80
1
7
1
10GE/OTU2/OTU2e
1
100G
1
1–8
2
10GE/OTU2/OTU2e
2
9–16
3
10GE/OTU2/OTU2e
3
17–24
4
10GE/OTU2/OTU2e
4
25–32
6
1
10GE/OTU2/OTU2e
5
33–40
2
10GE/OTU2/OTU2e
6
41–48
3
10GE/OTU2/OTU2e
7
49–56
4
10GE/OTU2/OTU2e
8
57–64
11
3
10GE/OTU2/OTU2e
9
65–72
4
10GE/OTU2/OTU2e
10
73–80
Configuring the Muxponder Mode for 40x10G Muxponder
To configure the OTN-XP card in the 40x10G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2 | OTU2E}
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/3 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the 40x10G muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/3 mxponder
Wed Jun  2 17:57:36.647 UTC

Location:             0/3
Slice ID:             0
Client Bitrate:       10GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/3/0/12  
                                Traffic Split Percentage

TenGigECtrlr0/3/0/0/1           ODU2E0/3/0/12/0/1                             100
TenGigECtrlr0/3/0/0/2           ODU2E0/3/0/12/0/2                             100
TenGigECtrlr0/3/0/0/3           ODU2E0/3/0/12/0/3                             100
TenGigECtrlr0/3/0/0/4           ODU2E0/3/0/12/0/4                             100
TenGigECtrlr0/3/0/1/1           ODU2E0/3/0/12/1/1                             100
TenGigECtrlr0/3/0/1/2           ODU2E0/3/0/12/1/2                             100
TenGigECtrlr0/3/0/1/3           ODU2E0/3/0/12/1/3                             100
TenGigECtrlr0/3/0/1/4           ODU2E0/3/0/12/1/4                             100
TenGigECtrlr0/3/0/2/1           ODU2E0/3/0/12/2/1                             100
TenGigECtrlr0/3/0/2/2           ODU2E0/3/0/12/2/2                             100
TenGigECtrlr0/3/0/2/3           ODU2E0/3/0/12/2/3                             100
TenGigECtrlr0/3/0/2/4           ODU2E0/3/0/12/2/4                             100
TenGigECtrlr0/3/0/3/1           ODU2E0/3/0/12/3/1                             100
TenGigECtrlr0/3/0/3/2           ODU2E0/3/0/12/3/2                             100
TenGigECtrlr0/3/0/3/3           ODU2E0/3/0/12/3/3                             100
TenGigECtrlr0/3/0/3/4           ODU2E0/3/0/12/3/4                             100
TenGigECtrlr0/3/0/4/1           ODU2E0/3/0/12/4/1                             100
TenGigECtrlr0/3/0/4/2           ODU2E0/3/0/12/4/2                             100
TenGigECtrlr0/3/0/4/3           ODU2E0/3/0/12/4/3                             100
TenGigECtrlr0/3/0/4/4           ODU2E0/3/0/12/4/4                             100
TenGigECtrlr0/3/0/5/1           ODU2E0/3/0/12/5/1                             100
TenGigECtrlr0/3/0/5/2           ODU2E0/3/0/12/5/2                             100
TenGigECtrlr0/3/0/5/3           ODU2E0/3/0/12/5/3                             100
TenGigECtrlr0/3/0/5/4           ODU2E0/3/0/12/5/4                             100
TenGigECtrlr0/3/0/6/1           ODU2E0/3/0/12/6/1                             100
TenGigECtrlr0/3/0/6/2           ODU2E0/3/0/12/6/2                             100
TenGigECtrlr0/3/0/6/3           ODU2E0/3/0/12/6/3                             100
TenGigECtrlr0/3/0/6/4           ODU2E0/3/0/12/6/4                             100
TenGigECtrlr0/3/0/7/1           ODU2E0/3/0/12/7/1                             100
TenGigECtrlr0/3/0/7/2           ODU2E0/3/0/12/7/2                             100
TenGigECtrlr0/3/0/7/3           ODU2E0/3/0/12/7/3                             100
TenGigECtrlr0/3/0/7/4           ODU2E0/3/0/12/7/4                             100
TenGigECtrlr0/3/0/9/1           ODU2E0/3/0/12/9/1                             100
TenGigECtrlr0/3/0/9/2           ODU2E0/3/0/12/9/2                             100
TenGigECtrlr0/3/0/9/3           ODU2E0/3/0/12/9/3                             100
TenGigECtrlr0/3/0/9/4           ODU2E0/3/0/12/9/4                             100
TenGigECtrlr0/3/0/11/1          ODU2E0/3/0/12/11/1                            100
TenGigECtrlr0/3/0/11/2          ODU2E0/3/0/12/11/2                            100
TenGigECtrlr0/3/0/11/3          ODU2E0/3/0/12/11/3                            100
TenGigECtrlr0/3/0/11/4          ODU2E0/3/0/12/11/4                            100
Configuring the Muxponder Mode for 30x10G
To configure the OTN-XP card in the 30x10G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 300G
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2E | OTU2}
commit
Example
The following is a sample in which the OTN-XP card is configured with 300G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the 30x10G muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Wed Jun  2 17:56:40.574 UTC

Location:             0/1
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       300G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port   Peer/Trunk Port        CoherentDSP0/1/0/12  
                                Traffic Split Percentage

OTU20/1/0/0/3                         NONE      ODU20/1/0/12/0/3                              100
OTU20/1/0/1/3                         NONE      ODU20/1/0/12/1/3                              100
OTU20/1/0/2/3                         NONE      ODU20/1/0/12/2/3                              100
OTU20/1/0/3/3                         NONE      ODU20/1/0/12/3/3                              100
OTU20/1/0/4/3                         NONE      ODU20/1/0/12/4/3                              100
OTU20/1/0/5/3                         NONE      ODU20/1/0/12/5/3                              100
OTU20/1/0/9/3                         NONE      ODU20/1/0/12/9/3                              100
OTU2E0/1/0/0/2                        NONE      ODU2E0/1/0/12/0/2                             100
OTU2E0/1/0/1/2                        NONE      ODU2E0/1/0/12/1/2                             100
OTU2E0/1/0/2/2                        NONE      ODU2E0/1/0/12/2/2                             100
OTU2E0/1/0/3/2                        NONE      ODU2E0/1/0/12/3/2                             100
OTU2E0/1/0/4/2                        NONE      ODU2E0/1/0/12/4/2                             100
OTU2E0/1/0/5/2                        NONE      ODU2E0/1/0/12/5/2                             100
OTU2E0/1/0/9/2                        NONE      ODU2E0/1/0/12/9/2                             100
TenGigECtrlr0/1/0/0/1           ODU2E0/1/0/12/0/1             NONE                            100
TenGigECtrlr0/1/0/0/4           ODU2E0/1/0/12/0/4             NONE                            100
TenGigECtrlr0/1/0/1/1           ODU2E0/1/0/12/1/1             NONE                            100
TenGigECtrlr0/1/0/1/4           ODU2E0/1/0/12/1/4             NONE                            100
TenGigECtrlr0/1/0/2/1           ODU2E0/1/0/12/2/1             NONE                            100
TenGigECtrlr0/1/0/2/4           ODU2E0/1/0/12/2/4             NONE                            100
TenGigECtrlr0/1/0/3/1           ODU2E0/1/0/12/3/1             NONE                            100
TenGigECtrlr0/1/0/3/4           ODU2E0/1/0/12/3/4             NONE                            100
TenGigECtrlr0/1/0/4/1           ODU2E0/1/0/12/4/1             NONE                            100
TenGigECtrlr0/1/0/4/4           ODU2E0/1/0/12/4/4             NONE                            100
TenGigECtrlr0/1/0/5/1           ODU2E0/1/0/12/5/1             NONE                            100
TenGigECtrlr0/1/0/5/4           ODU2E0/1/0/12/5/4             NONE                            100
TenGigECtrlr0/1/0/9/1           ODU2E0/1/0/12/9/1             NONE                            100
TenGigECtrlr0/1/0/9/4           ODU2E0/1/0/12/9/4             NONE                            100
Configuring Hybrid Modes Using 40x10G-4x100G-MXP
Table 14. Feature History
Feature Name
Release Information
Description
Hybrid Modes Using 40x10G-4x100G-MXP
Cisco IOS XR Release 7.3.2
With the 40x10G-4x100G-MXP muxponder mode support, you can configure the following hybrid modes:
20x10G + 2x100G
10x10G + 3 x 100G
With the 40x10G-4x100G-MXP muxponder mode support, you have flexibility to choose a combination of 10G and 100G client rates across different OTN and Ethernet client rates.
Table 15. Feature History
Feature Name
Release Information
Description
Support for 10x10G + 2 x 100G, 20x10G + 1 x 100G, and 30x10G + 1 x 100G Hybrid Modes
Cisco IOS XR Release 7.5.1
You can configure different client rates across the ports depending on the bandwidth requirement, using the following hybrid modes:
30x10G + 1 x 100G
10x10G + 2 x 100G
20x10G + 1 x 100G
With the 40x10G-4x100G-MXP muxponder mode support, you can configure the following hybrid modes:
20x10G + 2x100G
10x10G + 3 x 100G
30x10G + 1 x 100G
10x10G + 2 x 100G
20x10G + 1 x 100G
For more information on the client to trunk mapping for each of the mode, see Table 2.
Configuring the Muxponder Mode for 20x10G-2x100G
Configuring the Muxponder Mode for 10 x 10G-3 x 100G
Configuring Hybrid Modes for 20x10G + 1 x 100G Over 300G
Configuring Hybrid Modes for 30x10G + 1 x 100G Over 400G
Configuring Hybrid Modes for 10x10G + 2 x 100G Over 300G
Configuring Hybrid Mode for 10x10G + 1x100G Over 200G
Configuring the Muxponder Mode for 20x10G-2x100G
To configure the OTN-XP card in the 20x10G-2x100G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type {100GE | OTU4}
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2 | OTU2E}
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 client-type OTU4
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the 20x10G-2x100G muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Wed Jun  2 18:00:58.201 UTC

Location:             0/1
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port   Peer/Trunk Port        CoherentDSP0/1/0/12
                                Traffic Split Percentage

OTU40/1/0/1                           NONE      ODU40/1/0/12/1                        100
OTU2E0/1/0/2/3                        NONE      ODU2E0/1/0/12/2/3                             100
OTU2E0/1/0/2/4                        NONE      ODU2E0/1/0/12/2/4                             100
OTU2E0/1/0/4/1                        NONE      ODU2E0/1/0/12/4/1                             100
OTU2E0/1/0/4/2                        NONE      ODU2E0/1/0/12/4/2                             100
OTU2E0/1/0/4/3                        NONE      ODU2E0/1/0/12/4/3                             100
OTU2E0/1/0/4/4                        NONE      ODU2E0/1/0/12/4/4                             100
OTU2E0/1/0/5/1                        NONE      ODU2E0/1/0/12/5/1                             100
OTU2E0/1/0/5/2                        NONE      ODU2E0/1/0/12/5/2                             100
OTU2E0/1/0/5/3                        NONE      ODU2E0/1/0/12/5/3                             100
OTU2E0/1/0/5/4                        NONE      ODU2E0/1/0/12/5/4                             100
TenGigECtrlr0/1/0/6/1           ODU2E0/1/0/12/6/1                             100
TenGigECtrlr0/1/0/6/2           ODU2E0/1/0/12/6/2                             100
TenGigECtrlr0/1/0/6/3           ODU2E0/1/0/12/6/3                             100
TenGigECtrlr0/1/0/6/4           ODU2E0/1/0/12/6/4                             100
TenGigECtrlr0/1/0/7/1           ODU2E0/1/0/12/7/1                             100
TenGigECtrlr0/1/0/7/2           ODU2E0/1/0/12/7/2                             100
TenGigECtrlr0/1/0/7/3           ODU2E0/1/0/12/7/3                             100
TenGigECtrlr0/1/0/7/4           ODU2E0/1/0/12/7/4                             100
TenGigECtrlr0/1/0/11/3           ODU2E0/1/0/12/11/3                             100
TenGigECtrlr0/1/0/11/4           ODU2E0/1/0/12/11/4                             100
HundredGigECtrlr0/1/0/0         ODU40/1/0/12/0        NONE                            100
Configuring the Muxponder Mode for 10 x 10G-3 x 100G
To configure the OTN-XP card in the 10 x 10G and 3 x 100G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type {100GE | OTU4}
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2 | OTU2E}
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 21 09:21:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 client-type OTU4
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type OTU2E
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the 10 x 10G and 3 x 100G muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder
Wed Jun  2 18:00:58.201 UTC

Location:             0/1
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port   Peer/Trunk Port        CoherentDSP0/1/0/12
                                Traffic Split Percentage

OTU40/1/0/1                           NONE      ODU40/1/0/12/1                        100
OTU2E0/1/0/2/3                        NONE      ODU2E0/1/0/12/2/3                             100
OTU2E0/1/0/2/4                        NONE      ODU2E0/1/0/12/2/4                             100
OTU2E0/1/0/4/1                        NONE      ODU2E0/1/0/12/4/1                             100
OTU2E0/1/0/4/2                        NONE      ODU2E0/1/0/12/4/2                             100
OTU2E0/1/0/4/3                        NONE      ODU2E0/1/0/12/4/3                             100
OTU2E0/1/0/4/4                        NONE      ODU2E0/1/0/12/4/4                             100
OTU2E0/1/0/5/1                        NONE      ODU2E0/1/0/12/5/1                             100
OTU2E0/1/0/5/2                        NONE      ODU2E0/1/0/12/5/2                             100
OTU2E0/1/0/5/3                        NONE      ODU2E0/1/0/12/5/3                             100
OTU2E0/1/0/5/4                        NONE      ODU2E0/1/0/12/5/4                             100
HundredGigECtrlr0/1/0/0         ODU40/1/0/12/0        NONE                            100
HundredGigECtrlr0/1/0/6         ODU40/1/0/12/6        NONE                            100
Configuring Hybrid Modes for 20x10G + 1 x 100G Over 300G
To configure the OTN-XP card in the 20x10G + 1x100G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 300G
client-port-rate client-port-number client-type {100GE | OTU4}
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2 | OTU2E}
commit
The following is a sample in which the OTN-XP card is configured with the 20x10G + 1x100G mode on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#configure 
Sun Jul 25 12:43:00.399 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G 
RP/0/RP0/CPU0:ios#configure 
Sun Jul 25 12:43:00.399 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G 
/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 3 client-type otu2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 4 client-type otu2e
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type otu2 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample to verify the 20x10G + 1x100G muxponder configuration in the OTN-XP card:
RP/0/RP0/CPU0:ios#sh hw-module location 0/2 mxponder-slice 0
Sun Jul 25 13:11:01.829 UTC

Location:             0/2
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       300G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port   Peer/Trunk Port        CoherentDSP0/2/0/12  
                                Traffic Split Percentage

OTU20/2/0/1/3                         NONE      ODU20/2/0/12/1/3                              100
OTU20/2/0/2/3                         NONE      ODU20/2/0/12/2/3                              100
OTU20/2/0/4/3                         NONE      ODU20/2/0/12/4/3                              100
OTU20/2/0/4/4                         NONE      ODU20/2/0/12/4/4                              100
OTU2E0/2/0/1/4                        NONE      ODU2E0/2/0/12/1/4                             100
OTU2E0/2/0/2/1                        NONE      ODU2E0/2/0/12/2/1                             100
OTU2E0/2/0/2/2                        NONE      ODU2E0/2/0/12/2/2                             100
TenGigECtrlr0/2/0/1/1           ODU2E0/2/0/12/1/1             NONE                            100
TenGigECtrlr0/2/0/1/2           ODU2E0/2/0/12/1/2             NONE                            100
TenGigECtrlr0/2/0/2/4           ODU2E0/2/0/12/2/4             NONE                            100
TenGigECtrlr0/2/0/4/1           ODU2E0/2/0/12/4/1             NONE                            100
TenGigECtrlr0/2/0/4/2           ODU2E0/2/0/12/4/2             NONE                            100
TenGigECtrlr0/2/0/5/1           ODU2E0/2/0/12/5/1             NONE                            100
TenGigECtrlr0/2/0/5/2           ODU2E0/2/0/12/5/2             NONE                            100
TenGigECtrlr0/2/0/5/3           ODU2E0/2/0/12/5/3             NONE                            100
TenGigECtrlr0/2/0/5/4           ODU2E0/2/0/12/5/4             NONE                            100
TenGigECtrlr0/2/0/9/1           ODU2E0/2/0/12/9/1             NONE                            100
TenGigECtrlr0/2/0/9/2           ODU2E0/2/0/12/9/2             NONE                            100
TenGigECtrlr0/2/0/9/3           ODU2E0/2/0/12/9/3             NONE                            100
TenGigECtrlr0/2/0/9/4           ODU2E0/2/0/12/9/4             NONE                            100
TenGigECtrlr0/2/0/11/1          ODU2E0/2/0/12/11/1            NONE                            100
TenGigECtrlr0/2/0/11/2          ODU2E0/2/0/12/11/2            NONE                            100
HundredGigECtrlr0/2/0/0        ODU40/2/0/12/0        NONE                            100 
                          100 
RP/0/RP0/CPU0:ios#show lc-module location 0/2 lcmode 
Sun Jul 25 15:28:16.324 UTC

Node    Lcmode_Supported    Owner    Running                         Configured
--------------------------------------------------------------------------------
0/2                      Yes                 CLI      40x10G-4x100G-MXP      40x10G-4x100G-MXP 
Configuring Hybrid Modes for 30x10G + 1 x 100G Over 400G
To configure the OTN-XP card in the 30x10G + 1x100G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type {100GE | OTU4}
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2 | OTU2E}
commit
The following is a sample in which the OTN-XP card is configured with 300G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#configure 
Sun Jul 25 12:43:00.399 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
RP/0/RP0/CPU0:ios#configure 
Sun Jul 25 12:43:00.399 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 1 client-type 10GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 2 client-type otu2 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 3 client-type otu2e
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 lane 4 client-type 10GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 3 client-type otu2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 lane 4 client-type otu2e
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 1 client-type otu2e
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 2 client-type otu2e
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type otu2 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 1 client-type 10GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 3 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 9 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample to verify the 30x10G + 1x100G muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#sh hw-module location 0/2 mxponder-slice 0
Sun Jul 25 13:11:01.829 UTC

Location:             0/2
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port   Peer/Trunk Port        CoherentDSP0/2/0/12  
                                Traffic Split Percentage

OTU20/2/0/0/2                         NONE      ODU20/2/0/12/0/2                              100
OTU20/2/0/1/3                         NONE      ODU20/2/0/12/1/3                              100
OTU20/2/0/2/3                         NONE      ODU20/2/0/12/2/3                              100
OTU20/2/0/4/3                         NONE      ODU20/2/0/12/4/3                              100
OTU20/2/0/4/4                         NONE      ODU20/2/0/12/4/4                              100
OTU2E0/2/0/0/3                        NONE      ODU2E0/2/0/12/0/3                             100
OTU2E0/2/0/1/4                        NONE      ODU2E0/2/0/12/1/4                             100
OTU2E0/2/0/2/1                        NONE      ODU2E0/2/0/12/2/1                             100
OTU2E0/2/0/2/2                        NONE      ODU2E0/2/0/12/2/2                             100
TenGigECtrlr0/2/0/0/1           ODU2E0/2/0/12/0/1             NONE                            100
TenGigECtrlr0/2/0/0/4           ODU2E0/2/0/12/0/4             NONE                            100
TenGigECtrlr0/2/0/1/1           ODU2E0/2/0/12/1/1             NONE                            100
TenGigECtrlr0/2/0/1/2           ODU2E0/2/0/12/1/2             NONE                            100
TenGigECtrlr0/2/0/2/4           ODU2E0/2/0/12/2/4             NONE                            100
TenGigECtrlr0/2/0/3/1           ODU2E0/2/0/12/3/1             NONE                            100
TenGigECtrlr0/2/0/3/2           ODU2E0/2/0/12/3/2             NONE                            100
TenGigECtrlr0/2/0/3/3           ODU2E0/2/0/12/3/3             NONE                            100
TenGigECtrlr0/2/0/3/4           ODU2E0/2/0/12/3/4             NONE                            100
TenGigECtrlr0/2/0/4/1           ODU2E0/2/0/12/4/1             NONE                            100
TenGigECtrlr0/2/0/4/2           ODU2E0/2/0/12/4/2             NONE                            100
TenGigECtrlr0/2/0/5/1           ODU2E0/2/0/12/5/1             NONE                            100
TenGigECtrlr0/2/0/5/2           ODU2E0/2/0/12/5/2             NONE                            100
TenGigECtrlr0/2/0/5/3           ODU2E0/2/0/12/5/3             NONE                            100
TenGigECtrlr0/2/0/5/4           ODU2E0/2/0/12/5/4             NONE                            100
TenGigECtrlr0/2/0/9/1           ODU2E0/2/0/12/9/1             NONE                            100
TenGigECtrlr0/2/0/9/2           ODU2E0/2/0/12/9/2             NONE                            100
TenGigECtrlr0/2/0/9/3           ODU2E0/2/0/12/9/3             NONE                            100
TenGigECtrlr0/2/0/9/4           ODU2E0/2/0/12/9/4             NONE                            100
TenGigECtrlr0/2/0/11/1          ODU2E0/2/0/12/11/1            NONE                            100
TenGigECtrlr0/2/0/11/2          ODU2E0/2/0/12/11/2            NONE                            100
HundredGigECtrlr0/2/0/6         ODU40/2/0/12/0        NONE                            100 
                       100 
RP/0/RP0/CPU0:ios#show lc-module location 0/2 lcmode 
Sun Jul 25 15:28:16.324 UTC

Node    Lcmode_Supported    Owner    Running                         Configured
--------------------------------------------------------------------------------
0/2                      Yes                 CLI      40x10G-4x100G-MXP      40x10G-4x100G-MXP 
Configuring Hybrid Modes for 10x10G + 2 x 100G Over 300G
To configure the OTN-XP card in the 10x10G + 2x100G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 300G
client-port-rate client-port-number client-type {100GE | OTU4}
client-port-rate client-port-number lane lane-number client-type {10GE | OTU2 | OTU2E}
commit
The following is a sample in which the OTN-XP card is configured with 300G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#configure 
Sun Jul 25 12:43:00.399 UTC
RP/0/RP0/CPU0:ios(config)#
RP/0/RP0/CPU0:ios(config)#hw-module location 0/2 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 client-type otu4
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type 10GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type OTU2e
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type OTU2
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample to verify the 10x10G + 2x100G muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/2 mxponder-slice 0
Sun Jul 25 14:57:40.806 UTC

Location:             0/2
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       300G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port   Peer/Trunk Port        CoherentDSP0/2/0/12  
                                Traffic Split Percentage

OTU40/2/0/1                           NONE      ODU40/2/0/12/1                        100
OTU2e0/2/0/2/4                         NONE      ODU2e0/2/0/12/2/4                              100
OTU20/2/0/4/3                         NONE      ODU20/2/0/12/4/3                              100
OTU20/2/0/4/4                         NONE      ODU20/2/0/12/4/4                              100
TenGigECtrlr0/2/0/2/3           ODU2E0/2/0/12/2/3             NONE                            100
TenGigECtrlr0/2/0/4/1           ODU2E0/2/0/12/4/1             NONE                            100
TenGigECtrlr0/2/0/4/2           ODU2E0/2/0/12/4/2             NONE                            100
TenGigECtrlr0/2/0/5/1           ODU2E0/2/0/12/5/1             NONE                            100
TenGigECtrlr0/2/0/5/2           ODU2E0/2/0/12/5/2             NONE                            100
TenGigECtrlr0/2/0/5/3           ODU2E0/2/0/12/5/3             NONE                            100
TenGigECtrlr0/2/0/5/4           ODU2E0/2/0/12/5/4             NONE                            100
HundredGigECtrlr0/2/0/0         ODU40/2/0/12/0        NONE                            100 
RP/0/RP0/CPU0:ios#show lc-module location 0/2 lcmode 
Sun Jul 25 15:28:16.324 UTC

Node    Lcmode_Supported    Owner    Running                         Configured
--------------------------------------------------------------------------------
0/2                      Yes                 CLI      40x10G-4x100G-MXP      40x10G-4x100G-MXP 
Configuring Hybrid Mode for 10x10G + 1x100G Over 200G
Table 16. Feature History
Feature Name
Release Information
Description
10x10G + 1x100G Hybrid Mode for OTN-XP Card
Cisco IOS XR Release 7.7.1
A new hybrid mode 10x10G + 1x100G over 200G trunk rate is introduced for OTN-XP card. This mode is configurable on both slice 1 and slice 0. This feature provides you the flexibility to choose a combination of 10G and 100G client rates simultaneously on both slices of the OTN-XP card.
To configure the OTN-XP card in the 10 x 10G and 1 x 100G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 200G
client-port-rate client-port-number client-type {100GE | OTU4}
client-port-rate client-port-number lane lane-number client-type {10GE | 100GE}
commit
Example
The following is a sample in which the OTN-XP card is configured with 200G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 22 10:51:44.460 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 200G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 2 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Example
The following is a sample in which the OTN-XP card is configured with 200G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#config
Tue Apr 22 11:01:44:55.250 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 200G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 1 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 2 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 3 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 11 lane 4 client-type 10GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the 10 x 10G and 1 x 100G muxponder configuration in the OTN-XP card.
RRP/0/RP0/CPU0:ios#sh hw-module location 0/2 mxponder-slice 0
Fri Jun 17 15:55:43.520 UTC

Location:             0/2
Slice ID:             0
Client Bitrate:       MIXED
Trunk  Bitrate:       200G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/2/0/12  
                                Traffic Split Percentage

TenGigECtrlr0/2/0/2/3           ODU2E0/2/0/12/2/3                             100
TenGigECtrlr0/2/0/2/4           ODU2E0/2/0/12/2/4                             100
TenGigECtrlr0/2/0/4/1           ODU2E0/2/0/12/4/1                             100
TenGigECtrlr0/2/0/4/2           ODU2E0/2/0/12/4/2                             100
TenGigECtrlr0/2/0/4/3           ODU2E0/2/0/12/4/3                             100
TenGigECtrlr0/2/0/4/4           ODU2E0/2/0/12/4/4                             100
TenGigECtrlr0/2/0/5/1           ODU2E0/2/0/12/5/1                             100
TenGigECtrlr0/2/0/5/2           ODU2E0/2/0/12/5/2                             100
TenGigECtrlr0/2/0/5/3           ODU2E0/2/0/12/5/3                             100
TenGigECtrlr0/2/0/5/4           ODU2E0/2/0/12/5/4                             100
HundredGigECtrlr0/2/0/0         ODU40/2/0/12/0                        100

RP/0/RP0/CPU0:ios# 
Configuring the Muxponder Mode for 200G on OTN-XP Card
Table 17. Feature History
Feature Name
Release Information
Description
Muxponder Configuration for 200G Trunk with QPSK and 8QAM Modulation
Cisco IOS XR Release 7.3.2
The OTN-XP card supports up to 200G trunk rate with QPSK and 8QAM modulation using CFP2. This feature enhances the signal reachability with reduced noise and can support the 50GHz network.
Commands modified:
hw-module (OTN-XP Card)
To configure the OTN-XP card in the 200G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 200G
commit
The following is a sample configuration of 200G trunk rate on the mxponder-slice 0 mode for OTN-XP card:
RP/0/RP0/CPU0:ios#config
Wed Jun  2 17:17:59.409 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 200G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample configuration of 200G trunk rate on the mxponder-slice 1 mode for OTN-XP card:
RP/0/RP0/CPU0:ios#config
Wed Jun  2 17:17:59.409 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 200G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 0:
RP/0/RP0/CPU0:ios#show hw-module location 0/1 xponder-capabilities mxponder-slice 0
Wed Jun  2 17:02:33.088 UTC

Location: 0/1

Trunk-Port(s): 12

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          1, 6, 7, 10

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     1                             OTU4, 100GE
     6                             OTU4, 100GE
     7                             OTU4, 100GE
     10                            OTU4, 100GE, 400GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     6                             OTU4, 100GE
     7                             OTU4, 100GE
     10                            OTU4, 100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     7                             OTU4, 100GE
     10                            OTU4, 100GE
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 1:
RP/0/RP0/CPU0:ios#show hw-module location 0/1 xponder-capabilities mxponder-slice 1
Wed Jun  2 17:02:50.133 UTC

Location: 0/1

Trunk-Port(s): 13

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          0, 4, 5, 8

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     0                             OTU4, 100GE
     4                             OTU4, 100GE
     5                             OTU4, 100GE
     8                             OTU4, 100GE, 400GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     4                             OTU4, 100GE
     5                             OTU4, 100GE
     8                             OTU4, 100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     5                             OTU4, 100GE
     8                             OTU4, 100GE
Configuring 8QAM Modulation for 200G Muxponder Mode
Configuring 8QAM Modulation for 200G Muxponder Mode
By default, QPSK is the modulation format, when you configure 200G trunk rate.
The following operating modes are supported on the DP04CFP2 coherent pluggable module:
Table 18. DP04CFP2 Supported Modes
Network Configuration Mode
Client Type
Trunk Rate
Data Path
Line Framing
FEC Type
Modulation Format
BPS
Baud Rate (GBd)
Pulse Shaping
Mode Type
200G-FOIC2-oFEC-QPSK-1-S (Default mode)
2xFOIC1.2
200G
FlexO Str
FlexO-2
oFEC
QPSK
2
63.1
1
Standard
200G-FOIC2-oFEC-8QAM-1-E
2xFOIC1.2
200G
FlexO Str
FlexO-2
oFEC
8QAM
3
42.1
1
Enhanced
Use the following commands to change the modulation format to 8QAM:
configure
controller optics Rack/Slot/Instance/Port bits-per-symbol 3
commit
The following is a sample in which 8QAM modulation is configured.
RP/0/RP0/CPU0:ios#config
Wed Jun  2 17:21:59.409 UTC
RP/0/RP0/CPU0:ios(config)#controller optics0/1/0/12 bits-per-symbol 3
RP/0/RP0/CPU0:ios(config-optics)#commit
Verifying the 8QAM Modulation Configuration
RP/0/RP0/CPU0:ios#show controllers optics 0/1/0/12 
Wed Jun  2 17:17:29.652 UTC

 Controller State: Up 

 Transport Admin State: In Service 

 Laser State: On 

 LED State: Green 
 
 Optics Status 

         Optics Type:  <Unknown> DWDM
         DWDM carrier Info: C BAND, MSA ITU Channel=61, Frequency=193.10THz,
         Wavelength=1552.524nm 

         Alarm Status:
         -------------
         Detected Alarms: None


         LOS/LOL/Fault Status:

         Alarm Statistics:
          
         -------------
         HIGH-RX-PWR = 0            LOW-RX-PWR = 1          
         HIGH-TX-PWR = 0            LOW-TX-PWR = 1          
         HIGH-LBC = 0               HIGH-DGD = 0          
         OOR-CD = 0                 OSNR = 1          
         WVL-OOL = 0                MEA  = 0          
         IMPROPER-REM = 0          
         TX-POWER-PROV-MISMATCH = 0          
         Laser Bias Current = 0.0 %
         Actual TX Power = 0.97 dBm 
         RX Power = 1.47 dBm 
         RX Signal Power = 17.67 dBm 
         Frequency Offset = 82 MHz 

         Performance Monitoring: Enable 

         THRESHOLD VALUES
         ----------------

         Parameter                 High Alarm  Low Alarm  High Warning  Low Warning
         ------------------------  ----------  ---------  ------------  -----------
         Rx Power Threshold(dBm)          3.0      -31.5           0.0          0.0
         Tx Power Threshold(dBm)          3.0      -12.0           0.0          0.0
         LBC Threshold(mA)                N/A        N/A          0.00         0.00

         LBC High Threshold = 90 % 
         Configured Tx Power = 1.00 dBm 
         Configured CD High Threshold = 96000 ps/nm 
         Configured CD lower Threshold = -96000 ps/nm 
         Configured OSNR lower Threshold = 13.70 dB 
         Configured DGD Higher Threshold = 67.00 ps 
         Baud Rate =  42.2082633972 GBd
         Bits per Symbol = 3.0000000000  bits/symbol 
         Modulation Type: 8QAM 
         Chromatic Dispersion 2 ps/nm 
         Configured CD-MIN -48000 ps/nm  CD-MAX 48000 ps/nm 
         Polarization Mode Dispersion = 0.0 ps 
         Second Order Polarization Mode Dispersion = 72.00 ps^2 
         Optical Signal to Noise Ratio = 34.10 dB 
         SNR = 18.40 dB 
         Polarization Dependent Loss = 1.20 dB 
         Polarization Change Rate = 0.00 rad/s 
         Differential Group Delay = 2.00 ps 

 Transceiver Vendor Details
          
         Form Factor            : Not set
         Fiber Connector Type: Not Set 
         Otn Application Code: Not Set 
         Sonet Application Code: Not Set 
         Ethernet Compliance Code: Not set 

 Transceiver Temperature : 46 Celsius
 


 AINS Soak                : None 
 AINS Timer               : 0h, 0m
 AINS remaining time      : 0 seconds
Configuring the Muxponder Mode for 300G on OTN-XP Card
Table 19. Feature History
Feature Name
Release Information
Description
Muxponder Configuration for 300G Trunk with 8QAM Modulation
Cisco IOS XR Release 7.3.2
The OTN-XP card supports up to 300G trunk rate with 8QAM modulation using CFP2. This feature improves the signal reachability with decreased noise.
Commands modified:
hw-module (OTN-XP Card)
To configure the OTN-XP card in the 300G muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 300G
commit
The following is a sample configuration of 300G trunk rate on the mxponder-slice 0 mode for OTN-XP card:
RP/0/RP0/CPU0:ios#config
Wed Jun  2 17:17:59.409 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is a sample configuration of 300G trunk rate on the mxponder-slice 1 mode for OTN-XP card:
RP/0/RP0/CPU0:ios#config
Wed Jun  2 17:17:59.409 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 0:
RP/0/RP0/CPU0:ios#show hw-module location 0/1 xponder-capabilities mxponder-slice 0
Wed Jun  2 17:02:33.088 UTC

Location: 0/1

Trunk-Port(s): 12

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          1, 6, 7, 10

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     1                             OTU4, 100GE
     6                             OTU4, 100GE
     7                             OTU4, 100GE
     10                            OTU4, 100GE, 400GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     6                             OTU4, 100GE
     7                             OTU4, 100GE
     10                            OTU4, 100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     7                             OTU4, 100GE
     10                            OTU4, 100GE
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 1:
RP/0/RP0/CPU0:ios#show hw-module location 0/1 xponder-capabilities mxponder-slice 1
Wed Jun  2 17:02:50.133 UTC

Location: 0/1

Trunk-Port(s): 13

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          0, 4, 5, 8

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     0                             OTU4, 100GE
     4                             OTU4, 100GE
     5                             OTU4, 100GE
     8                             OTU4, 100GE, 400GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     4                             OTU4, 100GE
     5                             OTU4, 100GE
     8                             OTU4, 100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     5                             OTU4, 100GE
     8                             OTU4, 100GE
By default, 8QAM is the modulation format, when you configure 300G trunk rate.
The following operating mode is supported on the DP04CFP2 coherent pluggable module:
Table 20. DP04CFP2 Supported Modes
Network Configuration Mode
Client Type
Trunk Rate
Data Path
Line Framing
FEC Type
Modulation Format
BPS
Baud Rate (GBd)
Pulse Shaping
Mode Type
300G-FOIC3-oFEC-8QAM-1-S (Default mode)
3xFOIC1.2
300G
FlexO Str
FlexO-3
oFEC
8QAM
3
63.1
1
Standard
The following sample shows the supported client rates for 300G trunk rate and the provisioning status of slice 1:
RP/0/RP0/CPU0:ios#show hw-module location 0/1 mxponder-slice 1
Fri Jul 23 16:04:42.279 UTC

Location:             0/1
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       300G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/1/0/13  
                                Traffic Split Percentage
HundredGigECtrlr0/1/0/4         ODU40/1/0/13/8                 100
HundredGigECtrlr0/1/0/5         ODU40/1/0/13/5                 100 
HundredGigECtrlr0/1/0/8         ODU40/1/0/13/8                 100
The following sample shows the default 8QAM modulation format for the 300G trunk rate:
RP/0/RP0/CPU0:ios#show controllers optics 0/1/0/12 
Wed Jun  2 17:17:29.652 UTC

 Controller State: Up 

 Transport Admin State: In Service 

 Laser State: On 

 LED State: Green 
 
 Optics Status 

         Optics Type:  <Unknown> DWDM
         DWDM carrier Info: C BAND, MSA ITU Channel=61, Frequency=193.10THz,
         Wavelength=1552.524nm 

         Alarm Status:
         -------------
         Detected Alarms: None


         LOS/LOL/Fault Status:

         Alarm Statistics:
          
         -------------
         HIGH-RX-PWR = 0            LOW-RX-PWR = 1          
         HIGH-TX-PWR = 0            LOW-TX-PWR = 1          
         HIGH-LBC = 0               HIGH-DGD = 0          
         OOR-CD = 0                 OSNR = 1          
         WVL-OOL = 0                MEA  = 0          
         IMPROPER-REM = 0          
         TX-POWER-PROV-MISMATCH = 0          
         Laser Bias Current = 0.0 %
         Actual TX Power = 0.97 dBm 
         RX Power = 1.47 dBm 
         RX Signal Power = 17.67 dBm 
         Frequency Offset = 82 MHz 

         Performance Monitoring: Enable 

         THRESHOLD VALUES
         ----------------

         Parameter                 High Alarm  Low Alarm  High Warning  Low Warning
         ------------------------  ----------  ---------  ------------  -----------
         Rx Power Threshold(dBm)          3.0      -31.5           0.0          0.0
         Tx Power Threshold(dBm)          3.0      -12.0           0.0          0.0
         LBC Threshold(mA)                N/A        N/A          0.00         0.00

         LBC High Threshold = 90 % 
         Configured Tx Power = 1.00 dBm 
         Configured CD High Threshold = 96000 ps/nm 
         Configured CD lower Threshold = -96000 ps/nm 
         Configured OSNR lower Threshold = 13.70 dB 
         Configured DGD Higher Threshold = 67.00 ps 
         Baud Rate =  42.2082633972 GBd
         Bits per Symbol = 3.0000000000  bits/symbol 
         Modulation Type: 8QAM 
         Chromatic Dispersion 2 ps/nm 
         Configured CD-MIN -48000 ps/nm  CD-MAX 48000 ps/nm 
         Polarization Mode Dispersion = 0.0 ps 
         Second Order Polarization Mode Dispersion = 72.00 ps^2 
         Optical Signal to Noise Ratio = 34.10 dB 
         SNR = 18.40 dB 
         Polarization Dependent Loss = 1.20 dB 
         Polarization Change Rate = 0.00 rad/s 
         Differential Group Delay = 2.00 ps 

 Transceiver Vendor Details
          
         Form Factor            : Not set
         Fiber Connector Type: Not Set 
         Otn Application Code: Not Set 
         Sonet Application Code: Not Set 
         Ethernet Compliance Code: Not set 

 Transceiver Temperature : 46 Celsius
 


 AINS Soak                : None 
 AINS Timer               : 0h, 0m
 AINS remaining time      : 0 seconds
Configuring the Muxponder Mode for 4x100GE-MXP-DD
Table 21. Feature History
Feature Name
Release Information
Description
4X100GE MXP modes with QDD ZRP for OTN-XP Card
Cisco IOS XR Release 7.3.2
On the OTN-XP card, you can configure a single 4x100GE payload that isreceived over the client port as a 400GE signal over DWDM on the line side.
The card improves efficiency, performance, and flexibility for customer networksallowing 4x100GE client transport over 400GE WDM wavelength.
From Release 7.3.2 onwards, you can configure the 4x100GE-MXP-DD muxponder mode on the OTN-XP card.
Restrictions for Port Group Mapping
Configuring the Muxponder Mode for 4x100GE-MXP-DD
Restrictions for Port Group Mapping
The following table explains about the port mapping when the mxponder-slice 0 is at the near end and is connected to the mxponder-slice 1 at the far end:
Table 22. Port Group Mapping for Shared-Client-Group-Bandwidth
Slice Configuration - Client Port
Shared-Client-Group-Bandwidth
Shared-Group-Client-Ports
Slice 0
400G
1, 6, 7, 10
Slice 1
400G
8, 0, 4, 5
Table 23. Port Group Mapping for Trunk-Bandwidth
Trunk-Bandwidth
Slice Configuration - Client Port
Supported Client Rates
Client-Ports
400G
Slice 0
100G
1, 6, 7, 10
Slice 1
100G
8, 0, 4, 5
300G
Slice 0
100G
6, 7, 10
Slice 1
100G
8, 4, 5
200G
Slice 0
100G
7, 10
Slice 1
100G
4, 5
The traffic flows from the near-end slice-0 to the far-end slice-1 client ports:
The port 1 traffic reaches port 8
The port 6 traffic reaches port 0
The port 7 traffic reaches port 4
The port 10 traffic reaches port 5
The following table describes the QSFP DD trunk port to the slice-0 client port and slice-1 client port mapping:
Table 24. QSFP DD Trunk Port to the Slice-0 and Slice-1 Client Port Mapping
QSFP-DD Trunk Port
Slice 0 - Client Port
Slice 1 - Client Port
0
Port 10
Port 5
1
Port 7
Port 4
2
Port 6
Port 0
3
Port 1
Port 8
Configuring the Muxponder Mode for 4x100GE-MXP-DD
To configure the OTN-XP card in the 4x100GE-MXP-DD muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type 100GE
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 0 mode.
RP/0/RP0/CPU0:ios#configure 
Tue Jun 15 20:20:17.227 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/0 mxponder-slice 0
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 1 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 6 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 7 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Tue Jun 15 20:20:57.532 UTC
Verifying the Muxponder Configuration
The following is a sample to verify the 4x100GE-MXP-DD muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder
Tue Jun 15 20:21:46.587 UTC

Location:             0/0
Slice ID:             0
Client Bitrate:       100GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/1                  -                            100
HundredGigECtrlr0/0/0/6                  -                            100
HundredGigECtrlr0/0/0/7                  -                            100
HundredGigECtrlr0/0/0/10                 -                            100
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#configure 
Tue Jun 15 20:22:13.981 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/0 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 0 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Verifying the Muxponder Configuration
The following is a sample to verify the 4x100GE-MXP-DD muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 1
Tue Jun 15 20:23:06.217 UTC

Location:             0/0
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/9   
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/0                  -                            100
HundredGigECtrlr0/0/0/4                  -                            100
HundredGigECtrlr0/0/0/5                  -                            100
HundredGigECtrlr0/0/0/8                  -                            100
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder
Tue Jun 15 20:23:46.650 UTC

Location:             0/0
Slice ID:             0
Client Bitrate:       100GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/1                  -                            100
HundredGigECtrlr0/0/0/6                  -                            100
HundredGigECtrlr0/0/0/7                  -                            100
HundredGigECtrlr0/0/0/10                 -                            100


Location:             0/0
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/9   
                                Traffic Split Percentage
          
HundredGigECtrlr0/0/0/0                  -                            100
HundredGigECtrlr0/0/0/4                  -                            100
HundredGigECtrlr0/0/0/5                  -                            100
HundredGigECtrlr0/0/0/8                  -                            100
Configuring the Muxponder Mode for 2x100GE-MXP-DD
Table 25. Feature History
Feature Name
Release Information
Description
2X100GE MXP modes with QDD ZRP for OTN-XP Card
Cisco IOS XR Release 7.5.1
On the OTN-XP card, you can configure two 2x100GE payloads that are received over the client port as a 200GE signal over DWDM on the line side.
The 2x100GE-MXP-DD muxponder mode improves efficiency, performance, and flexibility for customer networks allowing 2x100GE client transport over 200GE WDM wavelength.
From Release 7.5.1 onwards, you can configure the 2x100GE-MXP-DD muxponder mode on the OTN-XP card.

Note
The LC mode must be configured to 4x100GE-MXP-DD on the OTN-XP card before you perform this configuration.
Two slices of 2x100GE-MXP-DD can be configured with the same LC mode on the OTN-XP card.
Restrictions on the port group mapping exist when the mxponder-slice 0 is at the near end and is connected to the mxponder-slice 1 at the far end. For more details, see Restrictions for Port Group Mapping.
To configure the OTN-XP card in the 2x100GE-MXP-DD muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 200G
client-port-rate client-port-number client-type 100GE
commit
Example
The following is a sample in which the OTN-XP card is configured with 200G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#configure 
Tue Jun 15 20:20:17.227 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 200G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 client-type 100GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Tue Jun 15 20:20:57.532 UTC
Verifying the Supported Client Rates for each Trunk Rate
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 0.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 xponder-capabilities mxponder-slice 0
Fri Jul 23 15:35:43.059 UTC

Location: 0/0

Trunk-Port(s): 11

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          1, 6, 7, 10

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     1                             100GE
     6                             100GE
     7                             100GE
     10                            100GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     6                             100GE
     7                             100GE
     10                            100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     7                             100GE
     10                            100GE
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 1.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 xponder-capabilities mxponder-slice 1
Wed Sep 15 00:30:47.433 UTC

Location: 0/0

Trunk-Port(s): 9

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          8, 0, 4, 5

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     8                             100GE
     0                             100GE
     4                             100GE
     5                             100GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     8                             100GE
     4                             100GE
     5                             100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     4                             100GE
     5                             100GE
Verifying the Running Configuration
The following is a sample to verify the provisioned slice and client port information for 2x100GE-MXP-DD muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show running config
hw-module location 0/2
 mxponder-slice 0
  trunk-rate 200G
  client-port-rate 1 client-type 100GE
  client-port-rate 7 client-type 100GE
 !
hw-module location  0/1
 mxponder-slice 1
  trunk-rate 200G
  client-port-rate 4 client-type 100GE
  client-port-rate 5 client-type 100GE
 !
!
Verifying the Muxponder Configuration
The following is a sample to verify the 2x100GE-MXP-DD muxponder configuration in the OTN-XP card for mxponder-slice 0.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 0
Fri Jul 23 16:04:42.279 UTC

Location:             0/0
Slice ID:             0
Client Bitrate:       100GE
Trunk  Bitrate:       200G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/7                  -                            100
HundredGigECtrlr0/0/0/10                 -                            100
The following is a sample to verify the 2x100GE-MXP-DD muxponder configuration in the OTN-XP card for mxponder-slice 1.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 1
Tue Jun 15 20:21:46.587 UTC

Location:             0/0
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       200G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/4                  -                            100
HundredGigECtrlr0/0/0/5                  -                            100
Configuring the Muxponder Mode for 3x100GE-MXP-DD
Table 26. Feature History
Feature Name
Release Information
Description
3x100GE MXP modes with QDD ZRP for OTN-XP Card
Cisco IOS XR Release 7.5.1
On the OTN-XP card, you can configure two 3x100GE payloads that are received over the client port as a 300GE signal over DWDM on the line side.
The 3x100GE-MXP-DD muxponder mode improves efficiency, performance, and flexibility for customer networks allowing 3x100GE client transport over 300GE WDM wavelength.
From Release 7.5.1 onwards, you can configure the 3x100GE-MXP-DD muxponder mode on the OTN-XP card.

Note
The LC mode must be configured to 4x100GE-MXP-DD on the OTN-XP card before you perform this configuration.
Two slices of 3x100GE-MXP-DD can be configured with the same LC mode on the OTN-XP card.
Restrictions on the port group mapping exist when the mxponder-slice 0 is at the near end and is connected to the mxponder-slice 1 at the far end. For more details, see Restrictions for Port Group Mapping.
To configure the OTN-XP card in the 3x100GE-MXP-DD muxponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 300G
client-port-rate client-port-number client-type 100GE
commit
Example
The following is a sample in which the OTN-XP card is configured with 300G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#configure 
Tue Jun 15 20:20:17.227 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 300G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 4 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 5 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type 100GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Tue Jun 15 20:20:57.532 UTC
Verifying the Supported Client Rates for each Trunk Rate
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 0.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 xponder-capabilities mxponder-slice 0
Fri Jul 23 15:35:43.059 UTC

Location: 0/0

Trunk-Port(s): 11

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          1, 6, 7, 10

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     1                             100GE
     6                             100GE
     7                             100GE
     10                            100GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     6                             100GE
     7                             100GE
     10                            100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     7                             100GE
     10                            100GE
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 1.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 xponder-capabilities mxponder-slice 1
Wed Sep 15 00:30:47.433 UTC

Location: 0/0

Trunk-Port(s): 9

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          8, 0, 4, 5

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     8                             100GE
     0                             100GE
     4                             100GE
     5                             100GE

Trunk-bandwidth: 300G
Client-port                       Supported client rates
     8                             100GE
     4                             100GE
     5                             100GE

Trunk-bandwidth: 200G
Client-port                       Supported client rates
     4                             100GE
     5                             100GE
Verifying the Running Configuration
The following is a sample to verify the provisioned slice and client port information for 3x100GE-MXP-DD muxponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show running config
hw-module location 0/2
 mxponder-slice 0
  trunk-rate 300G
  client-port-rate 1 client-type 100GE
  client-port-rate 7 client-type 100GE
  client-port-rate 10 client-type 100GE
 !
hw-module location  0/1
 mxponder-slice 1
  trunk-rate 300G
  client-port-rate 4 client-type 100GE
  client-port-rate 5 client-type 100GE
  client-port-rate 8 client-type 100GE
 !
!
Verifying the Muxponder Configuration
The following is a sample to verify the 3x100GE-MXP-DD muxponder configuration in the OTN-XP card for mxponder-slice 0.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 0
Tue Jun 15 20:21:46.587 UTC

Location:             0/0
Slice ID:             0
Client Bitrate:       100GE
Trunk  Bitrate:       300G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/1                  -                            100
HundredGigECtrlr0/0/0/7                  -                            100
HundredGigECtrlr0/0/0/10                 -                            100
The following is a sample to verify the 3x100GE-MXP-DD muxponder configuration in the OTN-XP card for mxponder-slice 1.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 1
Tue Jun 15 20:21:46.587 UTC

Location:             0/0
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       300G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/8                  -                            100
HundredGigECtrlr0/0/0/4                  -                            100
HundredGigECtrlr0/0/0/5                  -                            100
Configuring the Transponder Mode for 400GE-TXP-DD
Table 27. Feature History
Feature Name
Release Information
Description
400GE TXP mode with QDD ZRP for OTN-XP Card
Cisco IOS XR Release 7.5.1
On the OTN-XP card, you can configure two 400GE payloads that are received over the client port as a 400GE signal over DWDM on the line side.
The 400GE-TXP-DD muxponder mode improves efficiency, performance, and flexibility for customer networks allowing 400GE client transport over 400GE WDM wavelength.
From Release 7.5.1 onwards, you can configure the 400GE-TXP-DD transponder mode on the OTN-XP card.

Note
The LC mode must be configured to 400GE-TXP-DD on the OTN-XP card before you perform this configuration.
Two slices of 400GE-TXP-DD can be configured with the same LC mode on the OTN-XP card.
Restrictions on the port group mapping exist when the mxponder-slice 0 is at the near end and is connected to the mxponder-slice 1 at the far end. For more details, see Restrictions for Port Group Mapping.
To configure the OTN-XP card in the 400GE-TXP-DD transponder mode, use the following commands:
configure
hw-module location location mxponder-slice mxponder-slice-number
trunk-rate 400G
client-port-rate client-port-number client-type 100GE
commit
Example
The following is a sample in which the OTN-XP card is configured with 400G trunk rate on the mxponder-slice 1 mode.
RP/0/RP0/CPU0:ios#configure 
Tue Jun 15 20:20:17.227 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 400G
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 8 client-type 400GE
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit
Tue Jun 15 20:20:57.532 UTC
Verifying the Supported Client Rates for each Trunk Rate
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 0.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 xponder-capabilities mxponder-slice 0
Wed Oct 27 16:14:35.693 UTC

Location: 0/0

Trunk-Port(s): 11

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          10

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     10                            100GE
The following is the sample output for verifying the supported client rates for each trunk rate configured in muxponder slice 1.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 xponder-capabilities mxponder-slice 1
Wed Oct 27 16:16:37.524 UTC

Location: 0/0

Trunk-Port(s): 9

Port Group Restrictions:
Shared-Client-Group-Bandwidth    Shared-Group-Client-Ports
     400G                          8

Trunk-bandwidth: 400G
Client-port                       Supported client rates
     8                             400GE
Verifying the Running Configuration
The following is a sample to verify the provisioned slice and client port information for 400GE-TXP-DD transponder configuration in the OTN-XP card.
RP/0/RP0/CPU0:ios#show running config
hw-module location 0/0
 mxponder-slice 0
  trunk-rate 400G
  client-port-rate 10 client-type 100GE
 !
hw-module location  0/0
 mxponder-slice 1
  trunk-rate 400G
  client-port-rate 8 client-type 100GE
 !
!
Verifying the Muxponder Configuration
The following is a sample to verify the 400GE-TXP-DD transponder configuration in the OTN-XP card for mxponder-slice 0.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 0
Fri Jul 23 16:04:42.279 UTC

Location:             0/0
Slice ID:             0
Client Bitrate:       400GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/11  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/1                  -                            100
HundredGigECtrlr0/0/0/6                  -                            100
HundredGigECtrlr0/0/0/7                  -                            100
HundredGigECtrlr0/0/0/10                 -                            100
The following is a sample to verify the 400GE-TXP-DD transponder configuration in the OTN-XP card for mxponder-slice 1.
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder-slice 1
Tue Jun 15 20:21:46.587 UTC

Location:             0/0
Slice ID:             1
Client Bitrate:       400GE
Trunk  Bitrate:       400G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/0/0/9  
                                Traffic Split Percentage

HundredGigECtrlr0/0/0/8                  -                            100
HundredGigECtrlr0/0/0/0                  -                            100
HundredGigECtrlr0/0/0/4                  -                            100
HundredGigECtrlr0/0/0/5                  -                            100
Verifying the Client Ethernet Controller Status
The following is a sample to verify the Client Ethernet Controller Status of the 400GE-TXP-DD transponder configuration in the OTN-XP card.
P/0/RP0/CPU0:ios#show controller hundredGigECtrlr 0/0/0/1
Fri Jul 23 16:07:11.541 UTC
Operational data for interface HundredGigECtrlr0/0/0/1:


State:
    Administrative state: enabled
    Operational state: Up
    LED state: Green On
    Maintenance: Disabled
    AINS Soak: None
      Total Duration: 0 hour(s) 0 minute(s)
      Remaining Duration: 0 hour(s) 0 minute(s) 0 second(s)
    Laser Squelch: Disabled


Phy:
    Media type: Not known


Autonegotiation disabled.


Operational values:
    Speed: 100Gbps
    Duplex: Full Duplex
    Flowcontrol: None
    Loopback: None (or external)
    BER monitoring:
        Not supported
    Holdoff Time: 0ms
Configuring Inverse Muxponder on OTN-XP Card for 400GE Client
Table 28. Feature History
Feature Name
Release Information
Feature Description
Inverse Muxponder Configuration on OTN-XP Card
Cisco IOS XR Release 7.3.2
The OTN-XP card supports inverse multiplexing for 400GE client over 2x200G CFP2 trunk ports. This feature allows you to split the 400GE client signal and carry it over 2x200G trunks thereby increasing the ease of signal reachability.
Commands modified:
hw-module (OTN-XP Card)
controller coherentDSP
You can configure the OTN-XP card to support inverse multiplexing for 400GE client over 2x200G CFP2 trunk ports. To configure the inverse muxponder datapath, use the following commands:
configure
hw-module location location
mxponder
trunk-rate 200G
client-port-rate client-port-number client-type 400GE
commit
end
The following sample configures inverse muxponder for 400G:
RP/0/RP0/CPU0:ios #Configure
RP/0/RP0/CPU0:ios(config)#hw-module location 0/0 mxponder
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#trunk-rate 200G 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#client-port-rate 10 client-type 400GE 
RP/0/RP0/CPU0:ios(config-hwmod-mxp)#commit 
The following sample verifies the inverse muxponder configuration:
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder
Wed Jun  9 23:16:59.478 UTC

Location:             0/0
Client Bitrate:       400GE
Trunk  Bitrate:       200G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                   Mapper/Trunk Port         CoherentDSP0/0/0/12   CoherentDSP0/0/0/13     
                              Traffic Split Percentage

FourHundredGigECtrlr0/0/0/10  ODU-FLEX0/0/0/12/10          50                  50
Alarm Correlation in Inverse Muxponder
When any service-affecting alarm is raised on the trunk port 12 or 13, the alarms are reported on the ports as follows:
Port 12―Flexo alarms (FLEXO_LOS, FLEXO_LOL, FLEXO_GIDM, FLEXO_FMM, FLEXO_LOF, and FLEXO_LOM) and OTU alarms (LOD, AIS, LOS, LOM, LOD, and TIM)
Port 13―Flexo alarms except Flexo MM and GIDM.
Both ports 12 and 13 go down when any service-affecting alarm is raised.
Example:
Shut down the trunk port 12:
RP/0/RP0/CPU0:ios(config)#controller coherentDSP 0/3/0/12 
RP/0/RP0/CPU0:ios(config-CoDSP)#shutdown 
RP/0/RP0/CPU0:ios(config-CoDSP)#commit
Thu Sep 30 14:12:48.416 UTC
The following sample verifies that when trunk port 12 is shut down, LOS alarm is raised and the trunk port 13 also goes down.
RP/0/RP0/CPU0:ios#show controllers coherentDSP 0/2/0/12 
Thu Sep 30 14:12:54.604 UTC

Port                                            : CoherentDSP 0/2/0/12
Controller State                                : Down
Inherited Secondary State                       : Normal
Configured Secondary State                      : Normal
Derived State                                   : In Service
Loopback mode                                   : None
BER Thresholds                                  : SF = 1.0E-5  SD = 1.0E-7
Performance Monitoring                          : Enable
Bandwidth                                       : 200.0Gb/s

Alarm Information:
LOS = 2 LOF = 0 LOM = 0
OOF = 1 OOM = 0 AIS = 1
IAE = 0 BIAE = 0        SF_BER = 0
SD_BER = 0      BDI = 0 TIM = 0
FECMISMATCH = 0 FEC-UNC = 0     FLEXO_GIDM = 0
FLEXO-MM = 0    FLEXO-LOM = 0   FLEXO-RDI = 1
FLEXO-LOF = 0   
Detected Alarms                                 : LOS 

Bit Error Rate Information
PREFEC  BER                                     : 0.00E+00 
POSTFEC BER                                     : 0.00E+00 
Q-Factor                                        : 0.00 dB 

Q-Margin                                        : 0.00dB 

TTI :
        Remote IP addr                          : 0.0.0.0

FEC mode                                        : O_FEC

Flexo-Mode                                      : Enable
Flexo Details:
        Tx GID                                  : 1
        TX IID                                  : 1, 2, 
        Rx GID                                  : 0
        RX IID                                  : 0, 0, 

Flexo Peers Information:
        Controller                              : CoherentDSP0_2_0_13 
        OTUCn rate                              : OTUC2


AINS Soak                                       : None
AINS Timer                                      : 0h, 0m
AINS remaining time                             : 0 seconds


RP/0/RP0/CPU0:ios#show controllers coherentDSP 0/2/0/13 
Thu Sep 30 14:12:59.330 UTC

Port                                            : CoherentDSP 0/2/0/13
Controller State                                : Down
Inherited Secondary State                       : Normal
Configured Secondary State                      : Normal
Derived State                                   : In Service
Loopback mode                                   : None
BER Thresholds                                  : SF = 1.0E-5  SD = 1.0E-7
Performance Monitoring                          : Enable
Bandwidth                                       : 200.0Gb/s

Alarm Information:
LOS = 1 LOF = 0 LOM = 0
OOF = 0 OOM = 0 AIS = 0
IAE = 0 BIAE = 0        SF_BER = 0
SD_BER = 0      BDI = 0 TIM = 0
FECMISMATCH = 0 FEC-UNC = 0     FLEXO_GIDM = 0
FLEXO-MM = 0    FLEXO-LOM = 0   FLEXO-RDI = 1
FLEXO-LOF = 0   
Detected Alarms                                 : None

Bit Error Rate Information
PREFEC  BER                                     : 0.00E+00 
POSTFEC BER                                     : 0.00E+00 
Q-Factor                                        : 15.80 dB 

Q-Margin                                        : 9.50dB 

TTI :
        Remote IP addr                          : 0.0.0.0

FEC mode                                        : O_FEC

Flexo-Mode                                      : Enable
Flexo Details:
        Tx GID                                  : 1
        TX IID                                  : 3, 4, 
        Rx GID                                  : 1
        RX IID                                  : 3, 4, 

Flexo Peers Information:
        Controller                              : CoherentDSP0_2_0_12 
        OTUCn rate                              : OTUC2


AINS Soak                                       : None
AINS Timer                                      : 0h, 0m
AINS remaining time                             : 0 seconds
You can perform the following configurations on the DSPcontroller ports:
Flexo Parameter Update on Inverse Muxponder Configuration on the OTN-XP Card
Configure TTI on Inverse Muxponder Configuration on the OTN-XP Card
Configure Loopback on Inverse Muxponder Configured on the OTN-XP Card
2-QDD-C Line Card
Table 29. Feature History
Feature Name
Release Information
Description
NCS1K4-2-QDD-C-K9 C-Band Line Card
Cisco IOS XR Release 7.3.1
NCS 1004 supports the NCS1K4-2-QDD-C-K9 C-Band line card. The card has eight client ports (QSFP28 and QSFP-DD) and two DWDM dual sub-channel module trunk ports. Each trunk port is capable of 200, 300, and 400 Gbps line rate with fine control of modulation format, baud-rate, and forward error correction. The trunk ports are software configurable. The line card supports module and slice configurations.
Command added:
controller fourHundredGigECtrlr
The following section describes the supported configurations and procedures to configure the card modes on the 2-QDD-C line card.
Limitations for 2-QDD-C
2-QDD-C Card Modes
Sub 50G Configuration
Supported Data Rates for 2-QDD-C Card
Configuring the Card Mode for 2-QDD-C Card
Limitations for 2-QDD-C
The 2-QDD-C card does not support mixed clients, for example you can use either 100GE or 400GE at a time.
Flex Ethernet is not supported.
A single 400GE cannot be split and use as 4x 100GE due to hardware limitaions.
Unsupported Features for 2-QDD-C in R731
Unsupported Features for 2-QDD-C in R731
The following features are not supported in R7.3.1 for 2-QDD-C card:
OTU4 client
Layer 1 encryption
GCC remote node management
Line rates of 50G, 100G, 150G, 250G, and 350G
2-QDD-C Card Modes
The 2-QDD-C line cards support module and slice configurations.
The line cards have two trunk ports (0 and 1) and 8 client ports (2 through 9) each. You can configure the line card in two modes:
Muxponder—In this mode, both trunk ports are configured with the same trunk rate. The client-to-trunk mapping is in a sequence in vertical order.
Muxponder slice—In this mode, each trunk port is configured independent of the other with different trunk rates. The client-to-trunk mapping is fixed in vertical order. For Trunk 0, the client ports are 2 through 5. For Trunk 1, the client ports are 6 through 9.
Sub 50G Configuration
Table 30. Feature History
Feature Name
Release Information
Description
Support for n x 50G Rate
Cisco IOS XR Release 7.5.1
You can now configure sub 50G muxponder mode in a combination of trunk and client rates for 2-QDD-C cards.
You can configure sub 50G muxponder mode in the following combination of trunk and client rates:
100GE Muxponder mode:
1x100GE and 2x50G
3x100GE and 2x150G
5x100GE and 2x250G
7x100GE and 2x350G
OTU4 Muxponder mode:
1xOTU4 and 2x50G
3xOTU4 and 2x150G
5xOTU4 and 2x250G
7xOTU4 and 2x350G
The following table displays the port configuration for the supported data rates.
Trunk Data Rate (per trunk)
Total Configured Data rate
Trunk Ports
Client Ports for Trunk 0 (100G)
Shared Client Port (50G per trunk)
Client Ports for Trunk 1 (100G)
50G
100G
0, 1
-
2
-
150G
300G
0, 1
2
3
4
250G
500G
0, 1
2, 3
4
5, 6
350G
700G
0, 1
2, 3, 4
5
6, 7, 8
From Release 7.5.2, 2-QDD-C cards support an alternate port configuration for Sub 50G (split client port mapping) that you configure using CLI. The following table displays the port configuration for the supported data rates.
Trunk Data Rate (per trunk)
Total Configured Data rate
Trunk Ports
Client Ports for Trunk 0 (100G)
Shared Client Port (50G per trunk)
Client Ports for Trunk 1 (100G)
50G
100G
0, 1
-
5
-
150G
300G
0, 1
2
5
6
250G
500G
0, 1
2, 3
5
6, 7
350G
700G
0, 1
2, 3, 4
5
6, 7, 8
For information on how to configure split client port mapping, see Configure Split Client Port Mapping
Coupled Mode Restrictions
The following restrictions apply to the coupled mode configuration:
Both trunk ports must be configured with the same bits-per-symbol or baud rate and must be sent over same fiber and direction.
The chromatic dispersion must be configured to the same value for both trunk ports.
When trunk internal loopback is configured, it must be done for both trunk ports. Configuring internal loopback on only one trunk results in traffic loss.
Fault on a trunk port of a coupled pair may cause errors on all clients including those running only on the unaffected trunk port.
Supported Data Rates for 2-QDD-C Card
The following table displays the client and trunk ports that are enabled for the muxponder configuration.
Trunk Data Rate
Card Support
Client Data Rate
Client Optics
Trunk Ports
Client Ports
200
2-QDD-C
100GE, OTU4
QSFP-28
0, 1
2, 3, 4, 5
300
2-QDD-C
100GE, OTU4
QSFP-28
0, 1
2, 3, 4, 5, 6, 7
400
2-QDD-C
100GE, OTU4
QSFP-28
0, 1
2, 3, 4, 5, 6, 7, 8, 9
200
2-QDD-C
400GE
QSFP-DD
0, 1
4
400
2-QDD-C
400GE
QSFP-DD
0, 1
4,8
The following table displays the client and trunk ports that are enabled for the muxponder slice 0 configuration.
Trunk Data Rate
Card Support
Client Data Rate
Trunk Ports
Client Ports
200
2-QDD-C
100GE, OTU4
0
2, 3
300
2-QDD-C
100GE, OTU4
0
2, 3, 4
400
2-QDD-C
100GE, OTU4
0
2, 3, 4, 5
400
2-QDD-C
400GE
0
4
The following table displays the client and trunk ports that are enabled for the muxponder slice 1 configuration.
Trunk Data Rate
Card Support
Client Data Rate
Trunk Ports
Client Ports
200
2-QDD-C
100GE, OTU4
1
6, 7
300
2-QDD-C
100GE, OTU4
1
6, 7, 8
400
2-QDD-C
100GE, OTU4
1
6, 7, 8, 9
400
2-QDD-C
100GE, OTU4
1
8

Note
Due to hardware limitation, 400GE and 100 GE cannot coexist on the same line card.
The following table displays the trunk parameter ranges for the 2-QDD-C card.
Trunk Payload
FEC
Min BPS
Max BPS
Min GBd
Max GBd
150G
27%
1.453125
4.335938
24.02079
71.67494
200G
27%
2
4.40625
31.51
69.43
250G
27%
2.414063
6
28.93129
71.9069
300G
27%
2.8984375
6
34.7175497
71.8681352
350G
27%
3.382813
6
40.5038
71.84047
400G
27%
3.8671875
6
46.2900663
71.8197392
150G
15%
1.320313
3.9375
24.02079
71.67494
200G
15%
1.7578125
5.25
24.02079115
71.74209625
250G
15%
2.195313
6
26.27274
71.80592
300G
15%
3.8203125
6
31.52728839
49.51525048
350G
15%
3.070313
6
36.78184
71.87901
400G
15%
3.8671875
6
42.03638452
71.9018782

Note
The recommended value for 6 BPS for corresponding line rates are listed below:
Trunk Payload
FEC
BPS
GBd
300G
27%
6
34.7175
350G
27%
6
40.5038
400G
15%
6
42.0364
Configuring the Card Mode for 2-QDD-C Card
From R7.3.1, you can configure the 2-QDD-C line card in the module (muxponder) or slice configuration (muxponder slice).
To configure the card in the muxponder mode, use the following commands:
configure
hw-module location location mxponder client-rate {100GE | OTU4 }
hw-module location location mxponder trunk-rate {100G | 150G | 200G | 250G | 300G | 350G | 400G }
commit
configure
hw-module location location mxponder client-rate { 400GE}
hw-module location location mxponder trunk-rate { 200G | 400G }
commit
To configure the card in the muxponder slice mode, use the following commands.
configure
hw-module location location mxponder-slice mxponder-slice-number client-rate { 100GE | 400GE}
hw-module location location mxponder-slice mxponder-slice-number trunk-rate { 100G | 200G | 300G | 400G}
commit
Examples
The following is a sample in which the card is configured in the muxponder mode with a 400G trunk rate.
RP/0/RP0/CPU0:ios#config
Tue Oct 15 01:24:56.355 UTC
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder client-rate 100GE
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder trunk-rate 400G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured in the muxponder slice 0 mode with a 400G trunk rate.
RP/0/RP0/CPU0:ios#config
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0 client-rate 100GE
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 0 trunk-rate 400G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured in the muxponder slice 1 mode with a 400G trunk rate.
RP/0/RP0/CPU0:ios#config
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1 client-rate 100GE
RP/0/RP0/CPU0:ios(config)#hw-module location 0/1 mxponder-slice 1 trunk-rate 400G
RP/0/RP0/CPU0:ios(config)#commit
The following is a sample in which the card is configured in the muxponder mode with a 400GE trunk rate.
RP/0/RP0/CPU0:west#configure   
Thu Oct  7 11:43:01.914 IST
RP/0/RP0/CPU0:west(config)#hw-module location 0/2 mxponder trunk-rate 4
400G  450G  
RP/0/RP0/CPU0:west(config)#hw-module location 0/2 mxponder trunk-rate 400G    
RP/0/RP0/CPU0:west(config)#hw-module location 0/2 mxponder client-rate 400GE 
RP/0/RP0/CPU0:west(config)#commit
Configuring Mixed Client Traffic Mode
Configuring Mixed Client Traffic Mode
Table 31. Feature History
Feature Name
Release Information
Description
Mixed Client Traffic Mode Configuration
Cisco IOS XR Release 7.5.1
You can now configure the client traffic mode on each trunk port of the 2-QDD-C card independently. This feature provides flexibility to carry both OTN and Ethernet client traffic on the 2-QDD-C card at the same time across two slices.
You can configure the client traffic mode on each trunk in a line card independently. This provides flexibility for the same card to carry both OTN and ethernet client traffic at the same time across 2 slices.
100G, 200G, and 300G trunk rates are supported on both the slices (slice 0 and slice 1) with different client modes (100GE/OTU4).
Configuration
To configure the card in mixed client traffic mode, use the following commands:
hw-module location R/S
mxponder-slice 0
  trunk-rate [100G|200G|300G|400G]
  client-rate [100GE|OTU4]
!        
 mxponder-slice 1
  trunk-rate [100G|200G|300G|400G]
  client-rate [OTU4|100GE]
!
!
The following configuration is a sample of the mixed client traffic mode.
Example 1:
hw-module location 0/0
 mxponder-slice 0
  trunk-rate 400G
  client-rate OTU4
 !
 mxponder-slice 1
  trunk-rate 400G
  client-rate 100GE
 !
!
Verifying Card Configuration
RP/0/RP0/CPU0:ios#show hw-module location 0/0 mxponder
Location:             0/0
Slice ID:             0
Client Bitrate:       OTU4
Trunk  Bitrate:       400G
Status:               Provisioned
Client Port                     Peer/Trunk Port            CoherentDSP0/0/0/0   
                                Traffic Split Percentage

OTU40/0/0/2                     ODU40/0/0/0/1                      100
OTU40/0/0/3                     ODU40/0/0/0/2                      100
OTU40/0/0/4                     ODU40/0/0/0/3                      100
OTU40/0/0/5                     ODU40/0/0/0/4                      100


Location:             0/0
Slice ID:             1
Client Bitrate:       100GE
Trunk  Bitrate:       400G
Status:               Provisioned
Client Port                     Peer/Trunk Port            CoherentDSP0/0/0/1   
                                Traffic Split Percentage
HundredGigECtrlr0/0/0/6         ODU40/0/0/1/1                         100
HundredGigECtrlr0/0/0/7         ODU40/0/0/1/2                         100
HundredGigECtrlr0/0/0/8         ODU40/0/0/1/3                         100
HundredGigECtrlr0/0/0/9         ODU40/0/0/1/4                         100
The following configuration is a sample in which both the slices use the same client mode.
Example 2:
hw-module location 0/3
 mxponder
  trunk-rate 350G
  client-rate 100GE
 !
!
Verifying Card Configuration
RP/0/RP0/CPU0:ios#show hw-module location 0/3 mxponder
Fri Nov 26 12:21:16.174 UTC

Location:             0/3
Client Bitrate:       100GE
Trunk  Bitrate:       350G
Status:               Provisioned
LLDP Drop Enabled:    FALSE
ARP Snoop Enabled:    FALSE
Client Port                     Mapper/Trunk Port          CoherentDSP0/3/0/0   CoherentDSP0/3/0/1      
                                Traffic Split Percentage

HundredGigECtrlr0/3/0/2         ODU40/3/0/0/1                         100                        0
HundredGigECtrlr0/3/0/3         ODU40/3/0/0/2                         100                        0
HundredGigECtrlr0/3/0/4         ODU40/3/0/0/3                         100                        0
HundredGigECtrlr0/3/0/5         ODU40/3/0/0/4                          50                       50
HundredGigECtrlr0/3/0/6         ODU40/3/0/1/1                           0                      100
HundredGigECtrlr0/3/0/7         ODU40/3/0/1/2                           0                      100
HundredGigECtrlr0/3/0/8         ODU40/3/0/1/3                           0                      100
QXP Card
The NCS1K4-QXP-K9 3.2T QSFP-DD DCO Transponder Line Card has eight client ports (QSFP-DD) and eight trunk ports (QSFP-DD ZR+). Each line card supports up to 3.2 Tbps traffic. The client rates that are supported are 400GE, 4x100GE, and 100GE Ethernet only. The modulation formats supported are 16 QAM for 400GE Txp/4x100GE Mxp and QPSK for 100GE Txp.
The QXP line card provides up to 16 QSFP-DD ports (eight QSFP-DD client ports and eight QSFP-DD trunk ports). The supported operating modes are:
400GE-TXP
4X100GE MXP
100GE TXP [without client FEC]
The QXP card has 8 slices. Each slice consists of one client and one trunk port with a slice capacity of 400G. The total capacity is 3.2T.

Restriction
The QXP card uses only the first 6 client and trunk ports when installed in a NCS1004 chassis.
Supported Data Rates for QXP Card
The following table displays the client and trunk ports that are enabled for transponder and muxponder modes.
Operating mode
Card Support
Client Data Rate
Client Optics
Trunk Ports
Client Ports
400GE-TXP QXP Card 400G
QDD-400G-DR4-S, QDD-400G-FR4-S, QDD-AOCxM
0,2,4,6,8,10,12,14 1,3,5,7,9,11,13,15
4X100GE MXP QXP Card 4X100G Break out QDD-400G-DR4-S, QDD-4X100G-LR-S 0,2,4,6,8,10,12,14 1,3,5,7,9,11,13,15
100GE TXP QXP Card 100G QSFP28-100G-LR4, QSFP28-100G-LR-S, QSFP28-100G-DR-S, QSFP28-100G-FR-S 0,2,4,6,8,10,12,14 1,3,5,7,9,11,13,15
Was this Document Helpful?
Yes No
Feedback
Customers Also Viewed
Configuration Guide for Cisco NCS 1004, IOS XR Release 7.9.x --- Configuring the Card Mode
OpenROADM Configuration Guide for Cisco NCS 1004 --- OpenROADM YANG Models
Configuration Guide for Cisco NCS 1004, IOS XR Release 7.5.x --- Configuring the Card Mode
+ Show 3 More
Contact Cisco
Open a Support Case
(Requires a Cisco Service Contract)